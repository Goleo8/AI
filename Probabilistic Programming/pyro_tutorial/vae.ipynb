{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'visdom'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-059f5c19a8aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mvisdom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'visdom'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import visdom\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI\n",
    "from pyro.optim import Adam\n",
    "from pyro.util import ng_zeros, ng_ones\n",
    "from utils.vae_plots import plot_llk, mnist_test_tsne, plot_vae_samples\n",
    "from utils.mnist_cached import MNISTCached as MNIST\n",
    "from utils.mnist_cached import setup_data_loaders\n",
    "\n",
    "\n",
    "fudge = 1e-7\n",
    "\n",
    "\n",
    "# define the PyTorch module that parameterizes the\n",
    "# diagonal gaussian distribution q(z|x)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        # setup the three linear transformations used\n",
    "        self.fc1 = nn.Linear(784, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, z_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim, z_dim)\n",
    "        # setup the non-linearity\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # define the forward computation on the image x\n",
    "        # first shape the mini-batch to have pixels in the rightmost dimension\n",
    "        x = x.view(-1, 784)\n",
    "        # then compute the hidden units\n",
    "        hidden = self.softplus(self.fc1(x))\n",
    "        # then return a mean vector and a (positive) square root covariance\n",
    "        # each of size batch_size x z_dim\n",
    "        z_mu = self.fc21(hidden)\n",
    "        z_sigma = torch.exp(self.fc22(hidden))\n",
    "        return z_mu, z_sigma\n",
    "\n",
    "\n",
    "# define the PyTorch module that parameterizes the\n",
    "# observation likelihood p(x|z)\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        # setup the three linear transformations used\n",
    "        self.fc1 = nn.Linear(z_dim, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, 784)\n",
    "        # setup the non-linearity\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, z):\n",
    "        # define the forward computation on the latent z\n",
    "        # first compute the hidden units\n",
    "        hidden = self.softplus(self.fc1(z))\n",
    "        # return the parameter for the output Bernoulli\n",
    "        # each is of size batch_size x 784\n",
    "        # fixing numerical instabilities of sigmoid with a fudge\n",
    "        mu_img = (self.sigmoid(self.fc21(hidden))+fudge) * (1-2*fudge)\n",
    "        return mu_img\n",
    "\n",
    "\n",
    "# define a PyTorch module for the VAE\n",
    "class VAE(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, z_dim=50, hidden_dim=400, use_cuda=False):\n",
    "        super(VAE, self).__init__()\n",
    "        # create the encoder and decoder networks\n",
    "        self.encoder = Encoder(z_dim, hidden_dim)\n",
    "        self.decoder = Decoder(z_dim, hidden_dim)\n",
    "\n",
    "        if use_cuda:\n",
    "            # calling cuda() here will put all the parameters of\n",
    "            # the encoder and decoder networks into gpu memory\n",
    "            self.cuda()\n",
    "        self.use_cuda = use_cuda\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "    # define the model p(x|z)p(z)\n",
    "    def model(self, x):\n",
    "        # register PyTorch module `decoder` with Pyro\n",
    "        pyro.module(\"decoder\", self.decoder)\n",
    "        # setup hyperparameters for prior p(z)\n",
    "        # the type_as ensures we get cuda Tensors if x is on gpu\n",
    "        z_mu = ng_zeros([x.size(0), self.z_dim], type_as=x.data)\n",
    "        z_sigma = ng_ones([x.size(0), self.z_dim], type_as=x.data)\n",
    "        # sample from prior (value will be sampled by guide when computing the ELBO)\n",
    "        z = pyro.sample(\"latent\", dist.Normal(z_mu, z_sigma))\n",
    "        # decode the latent code z\n",
    "        mu_img = self.decoder.forward(z)\n",
    "        # score against actual images\n",
    "        pyro.sample(\"obs\", dist.Bernoulli(mu_img), obs=x.view(-1, 784))\n",
    "\n",
    "    # define the guide (i.e. variational distribution) q(z|x)\n",
    "    def guide(self, x):\n",
    "        # register PyTorch module `encoder` with Pyro\n",
    "        pyro.module(\"encoder\", self.encoder)\n",
    "        # use the encoder to get the parameters used to define q(z|x)\n",
    "        z_mu, z_sigma = self.encoder.forward(x)\n",
    "        # sample the latent code z\n",
    "        pyro.sample(\"latent\", dist.Normal(z_mu, z_sigma))\n",
    "\n",
    "    # define a helper function for reconstructing images\n",
    "    def reconstruct_img(self, x):\n",
    "        # encode image x\n",
    "        z_mu, z_sigma = self.encoder(x)\n",
    "        # sample in latent space\n",
    "        z = dist.Normal(z_mu, z_sigma).sample()\n",
    "        # decode the image (note we don't sample in image space)\n",
    "        mu_img = self.decoder(z)\n",
    "        return mu_img\n",
    "\n",
    "    def model_sample(self, batch_size=1):\n",
    "        # sample the handwriting style from the constant prior distribution\n",
    "        prior_mu = Variable(torch.zeros([batch_size, self.z_dim]))\n",
    "        prior_sigma = Variable(torch.ones([batch_size, self.z_dim]))\n",
    "        zs = pyro.sample(\"z\", dist.Normal(prior_mu, prior_sigma))\n",
    "        mu = self.decoder.forward(zs)\n",
    "        xs = pyro.sample(\"sample\", dist.Bernoulli(mu))\n",
    "        return xs, mu\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    # setup MNIST data loaders\n",
    "    # train_loader, test_loader\n",
    "    train_loader, test_loader = setup_data_loaders(MNIST, use_cuda=args.cuda, batch_size=256)\n",
    "\n",
    "    # setup the VAE\n",
    "    vae = VAE(use_cuda=args.cuda)\n",
    "\n",
    "    # setup the optimizer\n",
    "    adam_args = {\"lr\": args.learning_rate}\n",
    "    optimizer = Adam(adam_args)\n",
    "\n",
    "    # setup the inference algorithm\n",
    "    svi = SVI(vae.model, vae.guide, optimizer, loss=\"ELBO\")\n",
    "\n",
    "    # setup visdom for visualization\n",
    "    if args.visdom_flag:\n",
    "        vis = visdom.Visdom()\n",
    "\n",
    "    train_elbo = []\n",
    "    test_elbo = []\n",
    "    # training loop\n",
    "    for epoch in range(args.num_epochs):\n",
    "        # initialize loss accumulator\n",
    "        epoch_loss = 0.\n",
    "        # do a training epoch over each mini-batch x returned\n",
    "        # by the data loader\n",
    "        for _, (x, _) in enumerate(train_loader):\n",
    "            # if on GPU put mini-batch into CUDA memory\n",
    "            if args.cuda:\n",
    "                x = x.cuda()\n",
    "            # wrap the mini-batch in a PyTorch Variable\n",
    "            x = Variable(x)\n",
    "            # do ELBO gradient and accumulate loss\n",
    "            epoch_loss += svi.step(x)\n",
    "\n",
    "        # report training diagnostics\n",
    "        normalizer_train = len(train_loader.dataset)\n",
    "        total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "        train_elbo.append(total_epoch_loss_train)\n",
    "        print(\"[epoch %03d]  average training loss: %.4f\" % (epoch, total_epoch_loss_train))\n",
    "\n",
    "        if epoch % args.test_frequency == 0:\n",
    "            # initialize loss accumulator\n",
    "            test_loss = 0.\n",
    "            # compute the loss over the entire test set\n",
    "            for i, (x, _) in enumerate(test_loader):\n",
    "                # if on GPU put mini-batch into CUDA memory\n",
    "                if args.cuda:\n",
    "                    x = x.cuda()\n",
    "                # wrap the mini-batch in a PyTorch Variable\n",
    "                x = Variable(x)\n",
    "                # compute ELBO estimate and accumulate loss\n",
    "                test_loss += svi.evaluate_loss(x)\n",
    "\n",
    "                # pick three random test images from the first mini-batch and\n",
    "                # visualize how well we're reconstructing them\n",
    "                if i == 0:\n",
    "                    if args.visdom_flag:\n",
    "                        plot_vae_samples(vae, vis)\n",
    "                        reco_indices = np.random.randint(0, x.size(0), 3)\n",
    "                        for index in reco_indices:\n",
    "                            test_img = x[index, :]\n",
    "                            reco_img = vae.reconstruct_img(test_img)\n",
    "                            vis.image(test_img.contiguous().view(28, 28).data.cpu().numpy(),\n",
    "                                      opts={'caption': 'test image'})\n",
    "                            vis.image(reco_img.contiguous().view(28, 28).data.cpu().numpy(),\n",
    "                                      opts={'caption': 'reconstructed image'})\n",
    "\n",
    "            # report test diagnostics\n",
    "            normalizer_test = len(test_loader.dataset)\n",
    "            total_epoch_loss_test = test_loss / normalizer_test\n",
    "            test_elbo.append(total_epoch_loss_test)\n",
    "            print(\"[epoch %03d]  average test loss: %.4f\" % (epoch, total_epoch_loss_test))\n",
    "\n",
    "        if epoch == args.tsne_iter:\n",
    "            mnist_test_tsne(vae=vae, test_loader=test_loader)\n",
    "            plot_llk(np.array(train_elbo), np.array(test_elbo))\n",
    "\n",
    "    return vae\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # parse command line arguments\n",
    "    parser = argparse.ArgumentParser(description=\"parse args\")\n",
    "    parser.add_argument('-n', '--num-epochs', default=101, type=int, help='number of training epochs')\n",
    "    parser.add_argument('-tf', '--test-frequency', default=5, type=int, help='how often we evaluate the test set')\n",
    "    parser.add_argument('-lr', '--learning-rate', default=1.0e-3, type=float, help='learning rate')\n",
    "    parser.add_argument('-b1', '--beta1', default=0.95, type=float, help='beta1 adam hyperparameter')\n",
    "    parser.add_argument('--cuda', action='store_true', default=False, help='whether to use cuda')\n",
    "    parser.add_argument('-visdom', '--visdom_flag', default=False, help='Whether plotting in visdom is desired')\n",
    "    parser.add_argument('-i-tsne', '--tsne_iter', default=100, type=int, help='epoch when tsne visualization runs')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    model = main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
