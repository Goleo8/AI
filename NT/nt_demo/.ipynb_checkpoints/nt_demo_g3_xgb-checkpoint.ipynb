{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score,precision_score, precision_recall_curve, recall_score, roc_curve, auc, confusion_matrix,classification_report\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_svmlight_file('data/demo-g3-v2.txt')\n",
    "X,y=data[0],data[1]\n",
    "X_s,y_s=resample(X,y,n_samples=30000,replace=False)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_s,y_s,test_size=.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_eva(model,X_test,y_test):\n",
    "    y_test_pred=model.predict(X_test)\n",
    "    print('precision_score:',precision_score(y_test,y_test_pred,average='macro'))\n",
    "    print(confusion_matrix(y_test,y_test_pred).T)\n",
    "    print(np.unique(y_test,return_counts=True))\n",
    "    print(np.unique(y_test_pred,return_counts=True))\n",
    "    print(classification_report(y_test,y_test_pred))\n",
    "    print(\"******************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca=PCA(n_components=100,svd_solver='randomized')\n",
    "X_train_array=X_train.toarray()\n",
    "pca.fit(X_train_array)\n",
    "X_train_pca=pca.transform(X_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.2, gamma=0.0, learning_rate=0.01,\n",
       "       max_delta_step=0, max_depth=8, min_child_weight=1.5, missing=None,\n",
       "       n_estimators=1000, n_jobs=1, nthread=None,\n",
       "       objective='multi:softprob', random_state=0, reg_alpha=0.9,\n",
       "       reg_lambda=0.6, scale_pos_weight=1, seed=42, silent=1,\n",
       "       subsample=0.2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf_raw = xgb.XGBClassifier(\n",
    "                 colsample_bytree=0.2,\n",
    "                 gamma=0.0,\n",
    "                 learning_rate=0.01,\n",
    "                 max_depth=8,\n",
    "                 min_child_weight=1.5,\n",
    "                 n_estimators=1000,                                                                  \n",
    "                 reg_alpha=0.9,\n",
    "                 reg_lambda=0.6,\n",
    "                 subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "xgb_clf_raw.fit(X_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.2, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=8, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=1,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgb_clf = xgb.XGBClassifier(\n",
    "#                  colsample_bytree=0.2,\n",
    "#                  gamma=0.0,\n",
    "#                  learning_rate=0.01,\n",
    "#                  max_depth=8,\n",
    "#                  min_child_weight=1.5,\n",
    "#                  n_estimators=1000,                                                                  \n",
    "#                  reg_alpha=0.9,\n",
    "#                  reg_lambda=0.6,\n",
    "#                  subsample=0.2,\n",
    "#                  seed=42,\n",
    "#                  silent=1)\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "                 colsample_bytree=0.2,\n",
    "#                  gamma=0.0,\n",
    "                 learning_rate=0.01,\n",
    "                 max_depth=8,\n",
    "#                  min_child_weight=1.5,\n",
    "                 n_estimators=1000,                                                                  \n",
    "#                  reg_alpha=0.9,\n",
    "#                  reg_lambda=0.6,\n",
    "#                  subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "xgb_clf.fit(X_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_array=X_test.toarray()\n",
    "X_test_pca=pca.transform(X_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model_eva(model,X_train_pca,y_train)\n",
    "    model_eva(model,X_test_pca,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.6495335349074474\n",
      "[[1462  336  320  320  303  219  185  134  103   78  105]\n",
      " [  48  532   46   48   42   38   26   20   13   12   15]\n",
      " [ 189  230 2253  281  260  240  211  172  131   92  140]\n",
      " [ 142  152  269 3421  279  283  281  246  205  145  158]\n",
      " [ 276  262  493  482 4574  473  541  481  397  351  343]\n",
      " [ 216  242  487  452  422 4513  436  501  405  412  343]\n",
      " [  50   59  114  109   97   84 2836  109   91   97   71]\n",
      " [  16   27   47   48   43   23   31 2086   30   31   14]\n",
      " [   8    4   19   21   23   26   24   23 1542   18   17]\n",
      " [   3    6   10   11   17   14   15   12   11 1391   17]\n",
      " [ 286  288  673  801  955 1058 1106 1137 1150 1174 6740]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([2696, 2138, 4731, 5994, 7015, 6971, 5692, 4921, 4078, 3801, 7963]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 3565,   840,  4199,  5581,  8673,  8429,  3717,  2396,  1725,\n",
      "        1507, 15368]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.41      0.54      0.47      2696\n",
      "         5.0       0.63      0.25      0.36      2138\n",
      "         6.0       0.54      0.48      0.50      4731\n",
      "         7.0       0.61      0.57      0.59      5994\n",
      "         8.0       0.53      0.65      0.58      7015\n",
      "         9.0       0.54      0.65      0.59      6971\n",
      "        10.0       0.76      0.50      0.60      5692\n",
      "        11.0       0.87      0.42      0.57      4921\n",
      "        12.0       0.89      0.38      0.53      4078\n",
      "        13.0       0.92      0.37      0.52      3801\n",
      "        14.0       0.44      0.85      0.58      7963\n",
      "\n",
      "   micro avg       0.56      0.56      0.56     56000\n",
      "   macro avg       0.65      0.51      0.54     56000\n",
      "weighted avg       0.63      0.56      0.56     56000\n",
      "\n",
      "******************************************************************\n",
      "precision_score: 0.1690032614347597\n",
      "[[ 352  216  213  159  174  126   92   72   48   38   61]\n",
      " [  41   37   30   37   32   18   10   13   11    4    7]\n",
      " [ 156  128  234  224  179  150   95   76   46   46   76]\n",
      " [ 105   89  317  434  350  286  213  142   97   79   88]\n",
      " [ 202  147  412  589  661  618  466  331  229  200  325]\n",
      " [ 151  126  325  495  630  574  498  374  300  250  383]\n",
      " [  21   26   84  119  156  179  156  135   97   80  117]\n",
      " [  15   16   34   47   81   75   71   61   50   38   68]\n",
      " [   2    8   18   21   26   34   20   30   28   22   42]\n",
      " [   2    1    8   15   17   14   16   23   12   31   35]\n",
      " [ 152  143  343  460  654  797  798  862  801  834 2318]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1199,  937, 2018, 2600, 2960, 2871, 2435, 2119, 1719, 1622, 3520]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1551,  240, 1410, 2200, 4180, 4106, 1170,  556,  251,  174, 8162]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.23      0.29      0.26      1199\n",
      "         5.0       0.15      0.04      0.06       937\n",
      "         6.0       0.17      0.12      0.14      2018\n",
      "         7.0       0.20      0.17      0.18      2600\n",
      "         8.0       0.16      0.22      0.19      2960\n",
      "         9.0       0.14      0.20      0.16      2871\n",
      "        10.0       0.13      0.06      0.09      2435\n",
      "        11.0       0.11      0.03      0.05      2119\n",
      "        12.0       0.11      0.02      0.03      1719\n",
      "        13.0       0.18      0.02      0.03      1622\n",
      "        14.0       0.28      0.66      0.40      3520\n",
      "\n",
      "   micro avg       0.20      0.20      0.20     24000\n",
      "   macro avg       0.17      0.17      0.14     24000\n",
      "weighted avg       0.17      0.20      0.16     24000\n",
      "\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "test(xgb_clf_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.7611078475149125\n",
      "[[1937  358  371  293  279  242  205  179  119   63  120]\n",
      " [  24 1074   25   21   22   21   22   20   11    9   11]\n",
      " [ 142  151 2876  154  172  174  163  111   85   69   90]\n",
      " [ 191  213  327 4387  353  355  337  270  201  132  158]\n",
      " [ 121  119  269  234 4920  258  357  329  232  197  169]\n",
      " [  82   97  216  207  183 4813  204  194  150  163  118]\n",
      " [  23   20   68   71   66   68 3662   65   49   49   36]\n",
      " [   8    3    8   20   28   17   15 2946   20   17   15]\n",
      " [   0    0    7   14    6   11    8   15 2499    8    9]\n",
      " [   4    0    9    8   10    8    8    9   12 2287    9]\n",
      " [ 161  152  526  618  790  845  855  863  773  714 7319]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([2693, 2187, 4702, 6027, 6829, 6812, 5836, 5001, 4151, 3708, 8054]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 4166,  1260,  4187,  6924,  7205,  6427,  4177,  3097,  2577,\n",
      "        2364, 13616]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.46      0.72      0.56      2693\n",
      "         5.0       0.85      0.49      0.62      2187\n",
      "         6.0       0.69      0.61      0.65      4702\n",
      "         7.0       0.63      0.73      0.68      6027\n",
      "         8.0       0.68      0.72      0.70      6829\n",
      "         9.0       0.75      0.71      0.73      6812\n",
      "        10.0       0.88      0.63      0.73      5836\n",
      "        11.0       0.95      0.59      0.73      5001\n",
      "        12.0       0.97      0.60      0.74      4151\n",
      "        13.0       0.97      0.62      0.75      3708\n",
      "        14.0       0.54      0.91      0.68      8054\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     56000\n",
      "   macro avg       0.76      0.67      0.69     56000\n",
      "weighted avg       0.75      0.69      0.70     56000\n",
      "\n",
      "******************************************************************\n",
      "precision_score: 0.15234335026273077\n",
      "[[ 362  251  211  177  178  147   88   80   54   39   71]\n",
      " [  27   19   33   19   21    9   12    5    9    5   10]\n",
      " [ 141  116  212  182  176  155  107   79   53   33   78]\n",
      " [ 147  139  372  462  514  396  265  187  126   90  130]\n",
      " [ 172  119  377  558  630  570  428  311  228  190  293]\n",
      " [ 123  104  275  413  522  502  455  300  254  185  299]\n",
      " [  28   31   97  127  189  199  152  146  123   92  143]\n",
      " [   8   13   23   52   84   74   64   71   56   34   72]\n",
      " [   3    3    9   22   27   32   34   29   16   22   29]\n",
      " [   3    4   19   16   20   33   22   17   16   25   37]\n",
      " [ 167  148  344  513  716  822  823  856  781  857 2362]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1181,  947, 1972, 2541, 3077, 2939, 2450, 2081, 1716, 1572, 3524]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1658,  169, 1332, 2828, 3876, 3432, 1327,  551,  226,  212, 8389]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.22      0.31      0.26      1181\n",
      "         5.0       0.11      0.02      0.03       947\n",
      "         6.0       0.16      0.11      0.13      1972\n",
      "         7.0       0.16      0.18      0.17      2541\n",
      "         8.0       0.16      0.20      0.18      3077\n",
      "         9.0       0.15      0.17      0.16      2939\n",
      "        10.0       0.11      0.06      0.08      2450\n",
      "        11.0       0.13      0.03      0.05      2081\n",
      "        12.0       0.07      0.01      0.02      1716\n",
      "        13.0       0.12      0.02      0.03      1572\n",
      "        14.0       0.28      0.67      0.40      3524\n",
      "\n",
      "   micro avg       0.20      0.20      0.20     24000\n",
      "   macro avg       0.15      0.16      0.14     24000\n",
      "weighted avg       0.16      0.20      0.16     24000\n",
      "\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "test(xgb_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.2, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=8, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=1,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf_1000_8_raw = xgb.XGBClassifier(\n",
    "                 colsample_bytree=0.2,\n",
    "#                  gamma=0.0,\n",
    "                 learning_rate=0.1,\n",
    "                 max_depth=8,\n",
    "#                  min_child_weight=1.5,\n",
    "                 n_estimators=1000,                                                                  \n",
    "#                  reg_alpha=0.9,\n",
    "#                  reg_lambda=0.6,\n",
    "#                  subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "xgb_clf_1000_8_raw.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.6104409877562791\n",
      "[[1681  412  446  358  340  256  197  143  123   91  148]\n",
      " [  60  778   62   63   64   50   40   34   14   11   15]\n",
      " [ 154  146 2126  286  263  260  201  128   97   86  106]\n",
      " [  93  123  344 3038  435  414  337  231  177  143  156]\n",
      " [ 288  265  660  812 4157  885  810  629  434  311  381]\n",
      " [ 138  136  372  479  539 3703  565  460  410  329  289]\n",
      " [  25   32   78  106  128  137 2250  114  105   92   86]\n",
      " [  21   18   32   58   76   66   68 1891   61   52   50]\n",
      " [  11   12   23   38   31   32   30   42 1477   41   45]\n",
      " [   4    6   16   24   29   36   32   30   38 1460   34]\n",
      " [ 221  210  572  732  953 1132 1162 1219 1142 1185 6653]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([2696, 2138, 4731, 5994, 7015, 6971, 5692, 4921, 4078, 3801, 7963]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 4195,  1191,  3853,  5491,  9632,  7420,  3153,  2393,  1782,\n",
      "        1709, 15181]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.40      0.62      0.49      2696\n",
      "         5.0       0.65      0.36      0.47      2138\n",
      "         6.0       0.55      0.45      0.50      4731\n",
      "         7.0       0.55      0.51      0.53      5994\n",
      "         8.0       0.43      0.59      0.50      7015\n",
      "         9.0       0.50      0.53      0.51      6971\n",
      "        10.0       0.71      0.40      0.51      5692\n",
      "        11.0       0.79      0.38      0.52      4921\n",
      "        12.0       0.83      0.36      0.50      4078\n",
      "        13.0       0.85      0.38      0.53      3801\n",
      "        14.0       0.44      0.84      0.57      7963\n",
      "\n",
      "   micro avg       0.52      0.52      0.52     56000\n",
      "   macro avg       0.61      0.49      0.51     56000\n",
      "weighted avg       0.59      0.52      0.52     56000\n",
      "\n",
      "******************************************************************\n",
      "precision_score: 0.16412102787994068\n",
      "[[ 390  260  250  189  192  152  104   78   59   54   64]\n",
      " [  88   47   55   51   42   40   31   18    8    8   29]\n",
      " [ 132  117  255  242  184  154  128   62   55   45   77]\n",
      " [  81   81  306  434  364  290  214  135   96   61  120]\n",
      " [ 203  150  439  617  735  683  495  369  225  201  252]\n",
      " [ 111  104  294  454  536  515  399  303  232  196  240]\n",
      " [  29   16   72  113  158  183  149  148  113   92  110]\n",
      " [  25   21   26   51  106  113  113  105   87   75   95]\n",
      " [   7    9   22   43   44   60   72   68   59   48   99]\n",
      " [   9   10   21   29   45   48   54   52   46   45   95]\n",
      " [ 124  122  278  377  554  633  676  781  739  797 2339]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1199,  937, 2018, 2600, 2960, 2871, 2435, 2119, 1719, 1622, 3520]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1792,  417, 1451, 2182, 4369, 3384, 1183,  817,  531,  454, 7420]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.22      0.33      0.26      1199\n",
      "         5.0       0.11      0.05      0.07       937\n",
      "         6.0       0.18      0.13      0.15      2018\n",
      "         7.0       0.20      0.17      0.18      2600\n",
      "         8.0       0.17      0.25      0.20      2960\n",
      "         9.0       0.15      0.18      0.16      2871\n",
      "        10.0       0.13      0.06      0.08      2435\n",
      "        11.0       0.13      0.05      0.07      2119\n",
      "        12.0       0.11      0.03      0.05      1719\n",
      "        13.0       0.10      0.03      0.04      1622\n",
      "        14.0       0.32      0.66      0.43      3520\n",
      "\n",
      "   micro avg       0.21      0.21      0.21     24000\n",
      "   macro avg       0.16      0.18      0.15     24000\n",
      "weighted avg       0.18      0.21      0.18     24000\n",
      "\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "model_eva(xgb_clf_1000_8_raw,X_train,y_train)\n",
    "model_eva(xgb_clf_1000_8_raw,X_test,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.5432161012671715\n",
      "[[ 2800   946   969   774   727   547   437   343   202   172   306]\n",
      " [   84   847    92    93    67    69    56    36    21    17    33]\n",
      " [  352   396  3020   570   549   515   355   235   208   139   222]\n",
      " [  314   352  1068  4836  1349  1239   887   585   387   280   352]\n",
      " [  649   644  1500  1914  6530  2182  1805  1385  1029   808   877]\n",
      " [  231   236   597   920  1017  5012  1085   826   720   575   572]\n",
      " [   59    50   150   229   294   270  3118   271   202   176   160]\n",
      " [   22    36    86    99   147   143   120  2535   123   123   106]\n",
      " [    8    14    34    41    44    48    55    51  1833    35    44]\n",
      " [    5    14    14    32    36    46    42    48    41  1849    41]\n",
      " [  619   518  1251  1752  2309  2716  2836  2965  2933  2912 12333]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 5143,  4053,  8781, 11260, 13069, 12787, 10796,  9280,  7699,\n",
      "        7086, 15046]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 8223,  1415,  6561, 11649, 19323, 11791,  4979,  3540,  2207,\n",
      "        2168, 33144]))\n",
      "******************************************************************\n",
      "precision_score: 0.16672562972397278\n",
      "[[ 789  522  528  385  336  300  215  147  112   70  134]\n",
      " [ 115   68   92   61   49   40   37   34   22   27   33]\n",
      " [ 242  229  475  367  366  312  204  147   94   74   92]\n",
      " [ 161  228  696  993  924  667  478  311  200  141  166]\n",
      " [ 365  283  842 1190 1373 1269  950  699  469  362  517]\n",
      " [ 133  117  379  614  818  863  702  520  429  297  397]\n",
      " [  32   40  117  199  263  304  306  236  180  120  181]\n",
      " [  18   32   61  129  142  187  184  170  146  142  167]\n",
      " [  10    8   29   47   68   71   90   89   62   73  100]\n",
      " [   4   15   24   33   49   62   79   67   71   62  120]\n",
      " [ 269  232  627  788 1147 1456 1378 1577 1503 1587 4576]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([2138, 1774, 3870, 4806, 5535, 5531, 4623, 3997, 3288, 2955, 6483]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 3538,   578,  2602,  4965,  8319,  5269,  1978,  1378,   647,\n",
      "         586, 15140]))\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "xgb_clf_1000_6_1 = xgb.XGBClassifier(\n",
    "#                  colsample_bytree=0.2,\n",
    "#                  gamma=0.0,\n",
    "                 learning_rate=0.1,\n",
    "                 max_depth=6,\n",
    "#                  min_child_weight=1.5,\n",
    "                 n_estimators=1000,                                                                  \n",
    "#                  reg_alpha=0.9,\n",
    "#                  reg_lambda=0.6,\n",
    "#                  subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "xgb_clf_1000_6_1.fit(X_train,y_train)\n",
    "test(xgb_clf_1000_6_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.46939975391103433\n",
      "[[ 2126  1189  1225   943   873   664   503   373   235   173   335]\n",
      " [   10   174    11    16    19    10     3     7     7     5     9]\n",
      " [  280   260  1197   386   343   293   199   151   130    77   125]\n",
      " [  426   391  1382  3161  1610  1412  1013   580   414   290   349]\n",
      " [ 1155  1034  2433  3084  5299  3305  2594  1940  1451  1179  1633]\n",
      " [  211   206   656  1084  1314  2917  1386  1049   813   676   758]\n",
      " [   19    29    53    98   121   141  1002   127   104    95    62]\n",
      " [    4     7    30    58    83    95    93   924    82    68    39]\n",
      " [    3     3     2     7     5    10    12     8   478     9     9]\n",
      " [    1     4     6     9     9    11    17    11     7   454    11]\n",
      " [  908   756  1786  2414  3393  3929  3974  4110  3978  4060 11716]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 5143,  4053,  8781, 11260, 13069, 12787, 10796,  9280,  7699,\n",
      "        7086, 15046]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 8639,   271,  3441, 11028, 25107, 11070,  1851,  1483,   546,\n",
      "         540, 41024]))\n",
      "******************************************************************\n",
      "precision_score: 0.16940962171425386\n",
      "[[ 822  516  550  405  370  306  216  152  114   79  140]\n",
      " [  18   13   19   12    9    8    6    7    2    9    6]\n",
      " [ 137  165  248  195  194  149  107   80   36   46   55]\n",
      " [ 161  174  681  991  882  639  413  294  163  131  131]\n",
      " [ 526  447 1170 1480 1676 1568 1220  866  669  492  754]\n",
      " [  87  102  328  539  736  816  696  521  385  266  376]\n",
      " [  19   13   45   64  101  117  133  108   61   42   49]\n",
      " [   6   11   17   57   69   91   82   90   73   57   67]\n",
      " [   1    1    3    8   11   14   17   23   14   18   24]\n",
      " [   0    2    5    8    5   15   21   14   13   13   22]\n",
      " [ 361  330  804 1047 1482 1808 1712 1842 1758 1802 4859]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([2138, 1774, 3870, 4806, 5535, 5531, 4623, 3997, 3288, 2955, 6483]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 3670,   109,  1412,  4660, 10868,  4852,   752,   620,   134,\n",
      "         118, 17805]))\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "xgb_clf_1000_6_01 = xgb.XGBClassifier(\n",
    "#                  colsample_bytree=0.2,\n",
    "#                  gamma=0.0,\n",
    "                 learning_rate=0.01,\n",
    "                 max_depth=6,\n",
    "#                  min_child_weight=1.5,\n",
    "                 n_estimators=1000,                                                                  \n",
    "#                  reg_alpha=0.9,\n",
    "#                  reg_lambda=0.6,\n",
    "#                  subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "xgb_clf_1000_6_01.fit(X_train,y_train)\n",
    "test(xgb_clf_1000_6_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=8, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=1,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(\n",
    "#                  colsample_bytree=0.2,\n",
    "#                  gamma=0.0,\n",
    "#                  learning_rate=0.01,\n",
    "                 max_depth=8,\n",
    "#                  min_child_weight=1.5,\n",
    "                 n_estimators=1000,                                                                  \n",
    "#                  reg_alpha=0.9,\n",
    "#                  reg_lambda=0.6,\n",
    "#                  subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "xgb_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.7323486066030511\n",
      "[[ 825  128  133  107  120   74   62   54   36   22   42]\n",
      " [  24  443   28   27   25   14   19   16    9    6   15]\n",
      " [  56   51 1159   92   99   95   63   45   34   30   40]\n",
      " [  24   33   69 1490   81   82   77   68   50   34   36]\n",
      " [  60   66  140  183 1936  211  175  148  103   72   94]\n",
      " [  28   28   67   83   83 1689   96   79   57   60   51]\n",
      " [   9   15   30   38   33   47 1302   30   36   20   31]\n",
      " [   5    6   22   26   25   26   20 1101   23   17   18]\n",
      " [   1    1    6    9    9   14   12   12  936   13    8]\n",
      " [   3    4    8    5   11    8   13    9    3  843    9]\n",
      " [  60   48  135  189  217  252  257  271  208  204 2796]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1095,  823, 1797, 2249, 2639, 2512, 2096, 1833, 1495, 1321, 3140]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1603,  626, 1764, 2044, 3188, 2321, 1591, 1289, 1021,  916, 4637]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.51      0.75      0.61      1095\n",
      "         5.0       0.71      0.54      0.61       823\n",
      "         6.0       0.66      0.64      0.65      1797\n",
      "         7.0       0.73      0.66      0.69      2249\n",
      "         8.0       0.61      0.73      0.66      2639\n",
      "         9.0       0.73      0.67      0.70      2512\n",
      "        10.0       0.82      0.62      0.71      2096\n",
      "        11.0       0.85      0.60      0.71      1833\n",
      "        12.0       0.92      0.63      0.74      1495\n",
      "        13.0       0.92      0.64      0.75      1321\n",
      "        14.0       0.60      0.89      0.72      3140\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     21000\n",
      "   macro avg       0.73      0.67      0.69     21000\n",
      "weighted avg       0.72      0.69      0.69     21000\n",
      "\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "model_eva(xgb_clf,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.15792409323327827\n",
      "[[149  95 123  86  68  48  49  29  23  20  27]\n",
      " [ 30  15  21  18  21  25  12  14   6   9   8]\n",
      " [ 59  42 101 106 113  88  61  52  29  20  36]\n",
      " [ 30  25  99 140 124 111  90  70  46  27  41]\n",
      " [ 56  55 161 233 229 217 193 117  73  63  94]\n",
      " [ 31  33  86 135 173 181 114  97  75  78  65]\n",
      " [ 13  12  40  67  99 110  97  70  47  42  62]\n",
      " [  8  12  27  38  49  81  65  67  48  36  69]\n",
      " [ 11   9  14  30  31  47  35  29  36  29  51]\n",
      " [  9   2  11  16  18  26  21  20  12  20  46]\n",
      " [ 37  34  88 118 166 185 237 253 246 253 736]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 433,  334,  771,  987, 1091, 1119,  974,  818,  641,  597, 1235]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 717,  179,  707,  803, 1491, 1068,  659,  500,  322,  201, 2353]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.21      0.34      0.26       433\n",
      "         5.0       0.08      0.04      0.06       334\n",
      "         6.0       0.14      0.13      0.14       771\n",
      "         7.0       0.17      0.14      0.16       987\n",
      "         8.0       0.15      0.21      0.18      1091\n",
      "         9.0       0.17      0.16      0.17      1119\n",
      "        10.0       0.15      0.10      0.12       974\n",
      "        11.0       0.13      0.08      0.10       818\n",
      "        12.0       0.11      0.06      0.07       641\n",
      "        13.0       0.10      0.03      0.05       597\n",
      "        14.0       0.31      0.60      0.41      1235\n",
      "\n",
      "   micro avg       0.20      0.20      0.20      9000\n",
      "   macro avg       0.16      0.17      0.16      9000\n",
      "weighted avg       0.17      0.20      0.17      9000\n",
      "\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "model_eva(xgb_clf,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, dtarget,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "#         xgb_param['num_class']=len(np.unique(dtarget))\n",
    "        xgtrain = xgb.DMatrix(dtrain, label=dtarget)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='mlogloss', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain, dtarget,eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain)\n",
    "    dtrain_predprob = alg.predict_proba(dtrain)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % accuracy_score(dtarget, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % classification_report(dtarget, dtrain_predictions))\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  1, 10, ...,  2, 10,  4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train_encoded=le.fit_transform(y_train)\n",
    "y_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.3778\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be real number, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-24d5457b6527>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m  \u001b[0mscale_pos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m  seed=27)\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodelfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-5b3df0ae76ec>\u001b[0m in \u001b[0;36mmodelfit\u001b[0;34m(alg, dtrain, dtarget, useTrainCV, cv_folds, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nModel Report\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy : %.4g\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AUC Score (Train): %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mfeat_imp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be real number, not str"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " num_class = len(np.unique(y_train_encoded)),\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'multi:softprob',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, X_train,y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
