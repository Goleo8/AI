{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score,precision_score, precision_recall_curve, recall_score, roc_curve, auc, confusion_matrix,classification_report\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_svmlight_file('data/demo-g3-v2.txt')\n",
    "X,y=data[0],data[1]\n",
    "X_s,y_s=resample(X,y,n_samples=100000,replace=False)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_s,y_s,test_size=.3,random_state=42)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train_encoded=le.fit_transform(y_train)\n",
    "y_train_encoded\n",
    "y_test_encoded = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_eva(model,X_test,y_test):\n",
    "    y_test_pred=model.predict(X_test)\n",
    "    print('precision_score:',precision_score(y_test,y_test_pred,average='macro'))\n",
    "    print(confusion_matrix(y_test,y_test_pred).T)\n",
    "    print(np.unique(y_test,return_counts=True))\n",
    "    print(np.unique(y_test_pred,return_counts=True))\n",
    "    print(classification_report(y_test,y_test_pred))\n",
    "    print(\"******************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca=PCA(n_components=100,svd_solver='randomized')\n",
    "X_train_array=X_train.toarray()\n",
    "pca.fit(X_train_array)\n",
    "X_train_pca=pca.transform(X_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.2, gamma=0.0, learning_rate=0.01,\n",
       "       max_delta_step=0, max_depth=8, min_child_weight=1.5, missing=None,\n",
       "       n_estimators=1000, n_jobs=1, nthread=None,\n",
       "       objective='multi:softprob', random_state=0, reg_alpha=0.9,\n",
       "       reg_lambda=0.6, scale_pos_weight=1, seed=42, silent=1,\n",
       "       subsample=0.2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf_raw = xgb.XGBClassifier(\n",
    "                 colsample_bytree=0.2,\n",
    "                 gamma=0.0,\n",
    "                 learning_rate=0.01,\n",
    "                 max_depth=8,\n",
    "                 min_child_weight=1.5,\n",
    "                 n_estimators=1000,                                                                  \n",
    "                 reg_alpha=0.9,\n",
    "                 reg_lambda=0.6,\n",
    "                 subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "xgb_clf_raw.fit(X_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.2, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=8, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=1,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgb_clf = xgb.XGBClassifier(\n",
    "#                  colsample_bytree=0.2,\n",
    "#                  gamma=0.0,\n",
    "#                  learning_rate=0.01,\n",
    "#                  max_depth=8,\n",
    "#                  min_child_weight=1.5,\n",
    "#                  n_estimators=1000,                                                                  \n",
    "#                  reg_alpha=0.9,\n",
    "#                  reg_lambda=0.6,\n",
    "#                  subsample=0.2,\n",
    "#                  seed=42,\n",
    "#                  silent=1)\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "                 colsample_bytree=0.2,\n",
    "#                  gamma=0.0,\n",
    "                 learning_rate=0.01,\n",
    "                 max_depth=8,\n",
    "#                  min_child_weight=1.5,\n",
    "                 n_estimators=1000,                                                                  \n",
    "#                  reg_alpha=0.9,\n",
    "#                  reg_lambda=0.6,\n",
    "#                  subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "xgb_clf.fit(X_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_array=X_test.toarray()\n",
    "X_test_pca=pca.transform(X_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model_eva(model,X_train_pca,y_train)\n",
    "    model_eva(model,X_test_pca,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.6495335349074474\n",
      "[[1462  336  320  320  303  219  185  134  103   78  105]\n",
      " [  48  532   46   48   42   38   26   20   13   12   15]\n",
      " [ 189  230 2253  281  260  240  211  172  131   92  140]\n",
      " [ 142  152  269 3421  279  283  281  246  205  145  158]\n",
      " [ 276  262  493  482 4574  473  541  481  397  351  343]\n",
      " [ 216  242  487  452  422 4513  436  501  405  412  343]\n",
      " [  50   59  114  109   97   84 2836  109   91   97   71]\n",
      " [  16   27   47   48   43   23   31 2086   30   31   14]\n",
      " [   8    4   19   21   23   26   24   23 1542   18   17]\n",
      " [   3    6   10   11   17   14   15   12   11 1391   17]\n",
      " [ 286  288  673  801  955 1058 1106 1137 1150 1174 6740]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([2696, 2138, 4731, 5994, 7015, 6971, 5692, 4921, 4078, 3801, 7963]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 3565,   840,  4199,  5581,  8673,  8429,  3717,  2396,  1725,\n",
      "        1507, 15368]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.41      0.54      0.47      2696\n",
      "         5.0       0.63      0.25      0.36      2138\n",
      "         6.0       0.54      0.48      0.50      4731\n",
      "         7.0       0.61      0.57      0.59      5994\n",
      "         8.0       0.53      0.65      0.58      7015\n",
      "         9.0       0.54      0.65      0.59      6971\n",
      "        10.0       0.76      0.50      0.60      5692\n",
      "        11.0       0.87      0.42      0.57      4921\n",
      "        12.0       0.89      0.38      0.53      4078\n",
      "        13.0       0.92      0.37      0.52      3801\n",
      "        14.0       0.44      0.85      0.58      7963\n",
      "\n",
      "   micro avg       0.56      0.56      0.56     56000\n",
      "   macro avg       0.65      0.51      0.54     56000\n",
      "weighted avg       0.63      0.56      0.56     56000\n",
      "\n",
      "******************************************************************\n",
      "precision_score: 0.1690032614347597\n",
      "[[ 352  216  213  159  174  126   92   72   48   38   61]\n",
      " [  41   37   30   37   32   18   10   13   11    4    7]\n",
      " [ 156  128  234  224  179  150   95   76   46   46   76]\n",
      " [ 105   89  317  434  350  286  213  142   97   79   88]\n",
      " [ 202  147  412  589  661  618  466  331  229  200  325]\n",
      " [ 151  126  325  495  630  574  498  374  300  250  383]\n",
      " [  21   26   84  119  156  179  156  135   97   80  117]\n",
      " [  15   16   34   47   81   75   71   61   50   38   68]\n",
      " [   2    8   18   21   26   34   20   30   28   22   42]\n",
      " [   2    1    8   15   17   14   16   23   12   31   35]\n",
      " [ 152  143  343  460  654  797  798  862  801  834 2318]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1199,  937, 2018, 2600, 2960, 2871, 2435, 2119, 1719, 1622, 3520]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1551,  240, 1410, 2200, 4180, 4106, 1170,  556,  251,  174, 8162]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.23      0.29      0.26      1199\n",
      "         5.0       0.15      0.04      0.06       937\n",
      "         6.0       0.17      0.12      0.14      2018\n",
      "         7.0       0.20      0.17      0.18      2600\n",
      "         8.0       0.16      0.22      0.19      2960\n",
      "         9.0       0.14      0.20      0.16      2871\n",
      "        10.0       0.13      0.06      0.09      2435\n",
      "        11.0       0.11      0.03      0.05      2119\n",
      "        12.0       0.11      0.02      0.03      1719\n",
      "        13.0       0.18      0.02      0.03      1622\n",
      "        14.0       0.28      0.66      0.40      3520\n",
      "\n",
      "   micro avg       0.20      0.20      0.20     24000\n",
      "   macro avg       0.17      0.17      0.14     24000\n",
      "weighted avg       0.17      0.20      0.16     24000\n",
      "\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "test(xgb_clf_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.7611078475149125\n",
      "[[1937  358  371  293  279  242  205  179  119   63  120]\n",
      " [  24 1074   25   21   22   21   22   20   11    9   11]\n",
      " [ 142  151 2876  154  172  174  163  111   85   69   90]\n",
      " [ 191  213  327 4387  353  355  337  270  201  132  158]\n",
      " [ 121  119  269  234 4920  258  357  329  232  197  169]\n",
      " [  82   97  216  207  183 4813  204  194  150  163  118]\n",
      " [  23   20   68   71   66   68 3662   65   49   49   36]\n",
      " [   8    3    8   20   28   17   15 2946   20   17   15]\n",
      " [   0    0    7   14    6   11    8   15 2499    8    9]\n",
      " [   4    0    9    8   10    8    8    9   12 2287    9]\n",
      " [ 161  152  526  618  790  845  855  863  773  714 7319]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([2693, 2187, 4702, 6027, 6829, 6812, 5836, 5001, 4151, 3708, 8054]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 4166,  1260,  4187,  6924,  7205,  6427,  4177,  3097,  2577,\n",
      "        2364, 13616]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.46      0.72      0.56      2693\n",
      "         5.0       0.85      0.49      0.62      2187\n",
      "         6.0       0.69      0.61      0.65      4702\n",
      "         7.0       0.63      0.73      0.68      6027\n",
      "         8.0       0.68      0.72      0.70      6829\n",
      "         9.0       0.75      0.71      0.73      6812\n",
      "        10.0       0.88      0.63      0.73      5836\n",
      "        11.0       0.95      0.59      0.73      5001\n",
      "        12.0       0.97      0.60      0.74      4151\n",
      "        13.0       0.97      0.62      0.75      3708\n",
      "        14.0       0.54      0.91      0.68      8054\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     56000\n",
      "   macro avg       0.76      0.67      0.69     56000\n",
      "weighted avg       0.75      0.69      0.70     56000\n",
      "\n",
      "******************************************************************\n",
      "precision_score: 0.15234335026273077\n",
      "[[ 362  251  211  177  178  147   88   80   54   39   71]\n",
      " [  27   19   33   19   21    9   12    5    9    5   10]\n",
      " [ 141  116  212  182  176  155  107   79   53   33   78]\n",
      " [ 147  139  372  462  514  396  265  187  126   90  130]\n",
      " [ 172  119  377  558  630  570  428  311  228  190  293]\n",
      " [ 123  104  275  413  522  502  455  300  254  185  299]\n",
      " [  28   31   97  127  189  199  152  146  123   92  143]\n",
      " [   8   13   23   52   84   74   64   71   56   34   72]\n",
      " [   3    3    9   22   27   32   34   29   16   22   29]\n",
      " [   3    4   19   16   20   33   22   17   16   25   37]\n",
      " [ 167  148  344  513  716  822  823  856  781  857 2362]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1181,  947, 1972, 2541, 3077, 2939, 2450, 2081, 1716, 1572, 3524]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1658,  169, 1332, 2828, 3876, 3432, 1327,  551,  226,  212, 8389]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.22      0.31      0.26      1181\n",
      "         5.0       0.11      0.02      0.03       947\n",
      "         6.0       0.16      0.11      0.13      1972\n",
      "         7.0       0.16      0.18      0.17      2541\n",
      "         8.0       0.16      0.20      0.18      3077\n",
      "         9.0       0.15      0.17      0.16      2939\n",
      "        10.0       0.11      0.06      0.08      2450\n",
      "        11.0       0.13      0.03      0.05      2081\n",
      "        12.0       0.07      0.01      0.02      1716\n",
      "        13.0       0.12      0.02      0.03      1572\n",
      "        14.0       0.28      0.67      0.40      3524\n",
      "\n",
      "   micro avg       0.20      0.20      0.20     24000\n",
      "   macro avg       0.15      0.16      0.14     24000\n",
      "weighted avg       0.16      0.20      0.16     24000\n",
      "\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "test(xgb_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.2, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=8, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=1,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf_1000_8_raw = xgb.XGBClassifier(\n",
    "                 colsample_bytree=0.2,\n",
    "#                  gamma=0.0,\n",
    "                 learning_rate=0.1,\n",
    "                 max_depth=8,\n",
    "#                  min_child_weight=1.5,\n",
    "                 n_estimators=1000,                                                                  \n",
    "#                  reg_alpha=0.9,\n",
    "#                  reg_lambda=0.6,\n",
    "#                  subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "xgb_clf_1000_8_raw.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.6104409877562791\n",
      "[[1681  412  446  358  340  256  197  143  123   91  148]\n",
      " [  60  778   62   63   64   50   40   34   14   11   15]\n",
      " [ 154  146 2126  286  263  260  201  128   97   86  106]\n",
      " [  93  123  344 3038  435  414  337  231  177  143  156]\n",
      " [ 288  265  660  812 4157  885  810  629  434  311  381]\n",
      " [ 138  136  372  479  539 3703  565  460  410  329  289]\n",
      " [  25   32   78  106  128  137 2250  114  105   92   86]\n",
      " [  21   18   32   58   76   66   68 1891   61   52   50]\n",
      " [  11   12   23   38   31   32   30   42 1477   41   45]\n",
      " [   4    6   16   24   29   36   32   30   38 1460   34]\n",
      " [ 221  210  572  732  953 1132 1162 1219 1142 1185 6653]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([2696, 2138, 4731, 5994, 7015, 6971, 5692, 4921, 4078, 3801, 7963]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 4195,  1191,  3853,  5491,  9632,  7420,  3153,  2393,  1782,\n",
      "        1709, 15181]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.40      0.62      0.49      2696\n",
      "         5.0       0.65      0.36      0.47      2138\n",
      "         6.0       0.55      0.45      0.50      4731\n",
      "         7.0       0.55      0.51      0.53      5994\n",
      "         8.0       0.43      0.59      0.50      7015\n",
      "         9.0       0.50      0.53      0.51      6971\n",
      "        10.0       0.71      0.40      0.51      5692\n",
      "        11.0       0.79      0.38      0.52      4921\n",
      "        12.0       0.83      0.36      0.50      4078\n",
      "        13.0       0.85      0.38      0.53      3801\n",
      "        14.0       0.44      0.84      0.57      7963\n",
      "\n",
      "   micro avg       0.52      0.52      0.52     56000\n",
      "   macro avg       0.61      0.49      0.51     56000\n",
      "weighted avg       0.59      0.52      0.52     56000\n",
      "\n",
      "******************************************************************\n",
      "precision_score: 0.16412102787994068\n",
      "[[ 390  260  250  189  192  152  104   78   59   54   64]\n",
      " [  88   47   55   51   42   40   31   18    8    8   29]\n",
      " [ 132  117  255  242  184  154  128   62   55   45   77]\n",
      " [  81   81  306  434  364  290  214  135   96   61  120]\n",
      " [ 203  150  439  617  735  683  495  369  225  201  252]\n",
      " [ 111  104  294  454  536  515  399  303  232  196  240]\n",
      " [  29   16   72  113  158  183  149  148  113   92  110]\n",
      " [  25   21   26   51  106  113  113  105   87   75   95]\n",
      " [   7    9   22   43   44   60   72   68   59   48   99]\n",
      " [   9   10   21   29   45   48   54   52   46   45   95]\n",
      " [ 124  122  278  377  554  633  676  781  739  797 2339]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1199,  937, 2018, 2600, 2960, 2871, 2435, 2119, 1719, 1622, 3520]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1792,  417, 1451, 2182, 4369, 3384, 1183,  817,  531,  454, 7420]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.22      0.33      0.26      1199\n",
      "         5.0       0.11      0.05      0.07       937\n",
      "         6.0       0.18      0.13      0.15      2018\n",
      "         7.0       0.20      0.17      0.18      2600\n",
      "         8.0       0.17      0.25      0.20      2960\n",
      "         9.0       0.15      0.18      0.16      2871\n",
      "        10.0       0.13      0.06      0.08      2435\n",
      "        11.0       0.13      0.05      0.07      2119\n",
      "        12.0       0.11      0.03      0.05      1719\n",
      "        13.0       0.10      0.03      0.04      1622\n",
      "        14.0       0.32      0.66      0.43      3520\n",
      "\n",
      "   micro avg       0.21      0.21      0.21     24000\n",
      "   macro avg       0.16      0.18      0.15     24000\n",
      "weighted avg       0.18      0.21      0.18     24000\n",
      "\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "model_eva(xgb_clf_1000_8_raw,X_train,y_train)\n",
    "model_eva(xgb_clf_1000_8_raw,X_test,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.5432161012671715\n",
      "[[ 2800   946   969   774   727   547   437   343   202   172   306]\n",
      " [   84   847    92    93    67    69    56    36    21    17    33]\n",
      " [  352   396  3020   570   549   515   355   235   208   139   222]\n",
      " [  314   352  1068  4836  1349  1239   887   585   387   280   352]\n",
      " [  649   644  1500  1914  6530  2182  1805  1385  1029   808   877]\n",
      " [  231   236   597   920  1017  5012  1085   826   720   575   572]\n",
      " [   59    50   150   229   294   270  3118   271   202   176   160]\n",
      " [   22    36    86    99   147   143   120  2535   123   123   106]\n",
      " [    8    14    34    41    44    48    55    51  1833    35    44]\n",
      " [    5    14    14    32    36    46    42    48    41  1849    41]\n",
      " [  619   518  1251  1752  2309  2716  2836  2965  2933  2912 12333]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 5143,  4053,  8781, 11260, 13069, 12787, 10796,  9280,  7699,\n",
      "        7086, 15046]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 8223,  1415,  6561, 11649, 19323, 11791,  4979,  3540,  2207,\n",
      "        2168, 33144]))\n",
      "******************************************************************\n",
      "precision_score: 0.16672562972397278\n",
      "[[ 789  522  528  385  336  300  215  147  112   70  134]\n",
      " [ 115   68   92   61   49   40   37   34   22   27   33]\n",
      " [ 242  229  475  367  366  312  204  147   94   74   92]\n",
      " [ 161  228  696  993  924  667  478  311  200  141  166]\n",
      " [ 365  283  842 1190 1373 1269  950  699  469  362  517]\n",
      " [ 133  117  379  614  818  863  702  520  429  297  397]\n",
      " [  32   40  117  199  263  304  306  236  180  120  181]\n",
      " [  18   32   61  129  142  187  184  170  146  142  167]\n",
      " [  10    8   29   47   68   71   90   89   62   73  100]\n",
      " [   4   15   24   33   49   62   79   67   71   62  120]\n",
      " [ 269  232  627  788 1147 1456 1378 1577 1503 1587 4576]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([2138, 1774, 3870, 4806, 5535, 5531, 4623, 3997, 3288, 2955, 6483]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 3538,   578,  2602,  4965,  8319,  5269,  1978,  1378,   647,\n",
      "         586, 15140]))\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "xgb_clf_1000_6_1 = xgb.XGBClassifier(\n",
    "#                  colsample_bytree=0.2,\n",
    "#                  gamma=0.0,\n",
    "                 learning_rate=0.1,\n",
    "                 max_depth=6,\n",
    "#                  min_child_weight=1.5,\n",
    "                 n_estimators=1000,                                                                  \n",
    "#                  reg_alpha=0.9,\n",
    "#                  reg_lambda=0.6,\n",
    "#                  subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "xgb_clf_1000_6_1.fit(X_train,y_train)\n",
    "test(xgb_clf_1000_6_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.46939975391103433\n",
      "[[ 2126  1189  1225   943   873   664   503   373   235   173   335]\n",
      " [   10   174    11    16    19    10     3     7     7     5     9]\n",
      " [  280   260  1197   386   343   293   199   151   130    77   125]\n",
      " [  426   391  1382  3161  1610  1412  1013   580   414   290   349]\n",
      " [ 1155  1034  2433  3084  5299  3305  2594  1940  1451  1179  1633]\n",
      " [  211   206   656  1084  1314  2917  1386  1049   813   676   758]\n",
      " [   19    29    53    98   121   141  1002   127   104    95    62]\n",
      " [    4     7    30    58    83    95    93   924    82    68    39]\n",
      " [    3     3     2     7     5    10    12     8   478     9     9]\n",
      " [    1     4     6     9     9    11    17    11     7   454    11]\n",
      " [  908   756  1786  2414  3393  3929  3974  4110  3978  4060 11716]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 5143,  4053,  8781, 11260, 13069, 12787, 10796,  9280,  7699,\n",
      "        7086, 15046]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 8639,   271,  3441, 11028, 25107, 11070,  1851,  1483,   546,\n",
      "         540, 41024]))\n",
      "******************************************************************\n",
      "precision_score: 0.16940962171425386\n",
      "[[ 822  516  550  405  370  306  216  152  114   79  140]\n",
      " [  18   13   19   12    9    8    6    7    2    9    6]\n",
      " [ 137  165  248  195  194  149  107   80   36   46   55]\n",
      " [ 161  174  681  991  882  639  413  294  163  131  131]\n",
      " [ 526  447 1170 1480 1676 1568 1220  866  669  492  754]\n",
      " [  87  102  328  539  736  816  696  521  385  266  376]\n",
      " [  19   13   45   64  101  117  133  108   61   42   49]\n",
      " [   6   11   17   57   69   91   82   90   73   57   67]\n",
      " [   1    1    3    8   11   14   17   23   14   18   24]\n",
      " [   0    2    5    8    5   15   21   14   13   13   22]\n",
      " [ 361  330  804 1047 1482 1808 1712 1842 1758 1802 4859]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([2138, 1774, 3870, 4806, 5535, 5531, 4623, 3997, 3288, 2955, 6483]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 3670,   109,  1412,  4660, 10868,  4852,   752,   620,   134,\n",
      "         118, 17805]))\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "xgb_clf_1000_6_01 = xgb.XGBClassifier(\n",
    "#                  colsample_bytree=0.2,\n",
    "#                  gamma=0.0,\n",
    "                 learning_rate=0.01,\n",
    "                 max_depth=6,\n",
    "#                  min_child_weight=1.5,\n",
    "                 n_estimators=1000,                                                                  \n",
    "#                  reg_alpha=0.9,\n",
    "#                  reg_lambda=0.6,\n",
    "#                  subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "xgb_clf_1000_6_01.fit(X_train,y_train)\n",
    "test(xgb_clf_1000_6_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=8, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=1,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(\n",
    "#                  colsample_bytree=0.2,\n",
    "#                  gamma=0.0,\n",
    "#                  learning_rate=0.01,\n",
    "                 max_depth=8,\n",
    "#                  min_child_weight=1.5,\n",
    "                 n_estimators=1000,                                                                  \n",
    "#                  reg_alpha=0.9,\n",
    "#                  reg_lambda=0.6,\n",
    "#                  subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "xgb_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.7323486066030511\n",
      "[[ 825  128  133  107  120   74   62   54   36   22   42]\n",
      " [  24  443   28   27   25   14   19   16    9    6   15]\n",
      " [  56   51 1159   92   99   95   63   45   34   30   40]\n",
      " [  24   33   69 1490   81   82   77   68   50   34   36]\n",
      " [  60   66  140  183 1936  211  175  148  103   72   94]\n",
      " [  28   28   67   83   83 1689   96   79   57   60   51]\n",
      " [   9   15   30   38   33   47 1302   30   36   20   31]\n",
      " [   5    6   22   26   25   26   20 1101   23   17   18]\n",
      " [   1    1    6    9    9   14   12   12  936   13    8]\n",
      " [   3    4    8    5   11    8   13    9    3  843    9]\n",
      " [  60   48  135  189  217  252  257  271  208  204 2796]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1095,  823, 1797, 2249, 2639, 2512, 2096, 1833, 1495, 1321, 3140]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1603,  626, 1764, 2044, 3188, 2321, 1591, 1289, 1021,  916, 4637]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.51      0.75      0.61      1095\n",
      "         5.0       0.71      0.54      0.61       823\n",
      "         6.0       0.66      0.64      0.65      1797\n",
      "         7.0       0.73      0.66      0.69      2249\n",
      "         8.0       0.61      0.73      0.66      2639\n",
      "         9.0       0.73      0.67      0.70      2512\n",
      "        10.0       0.82      0.62      0.71      2096\n",
      "        11.0       0.85      0.60      0.71      1833\n",
      "        12.0       0.92      0.63      0.74      1495\n",
      "        13.0       0.92      0.64      0.75      1321\n",
      "        14.0       0.60      0.89      0.72      3140\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     21000\n",
      "   macro avg       0.73      0.67      0.69     21000\n",
      "weighted avg       0.72      0.69      0.69     21000\n",
      "\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "model_eva(xgb_clf,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.15792409323327827\n",
      "[[149  95 123  86  68  48  49  29  23  20  27]\n",
      " [ 30  15  21  18  21  25  12  14   6   9   8]\n",
      " [ 59  42 101 106 113  88  61  52  29  20  36]\n",
      " [ 30  25  99 140 124 111  90  70  46  27  41]\n",
      " [ 56  55 161 233 229 217 193 117  73  63  94]\n",
      " [ 31  33  86 135 173 181 114  97  75  78  65]\n",
      " [ 13  12  40  67  99 110  97  70  47  42  62]\n",
      " [  8  12  27  38  49  81  65  67  48  36  69]\n",
      " [ 11   9  14  30  31  47  35  29  36  29  51]\n",
      " [  9   2  11  16  18  26  21  20  12  20  46]\n",
      " [ 37  34  88 118 166 185 237 253 246 253 736]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 433,  334,  771,  987, 1091, 1119,  974,  818,  641,  597, 1235]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 717,  179,  707,  803, 1491, 1068,  659,  500,  322,  201, 2353]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.21      0.34      0.26       433\n",
      "         5.0       0.08      0.04      0.06       334\n",
      "         6.0       0.14      0.13      0.14       771\n",
      "         7.0       0.17      0.14      0.16       987\n",
      "         8.0       0.15      0.21      0.18      1091\n",
      "         9.0       0.17      0.16      0.17      1119\n",
      "        10.0       0.15      0.10      0.12       974\n",
      "        11.0       0.13      0.08      0.10       818\n",
      "        12.0       0.11      0.06      0.07       641\n",
      "        13.0       0.10      0.03      0.05       597\n",
      "        14.0       0.31      0.60      0.41      1235\n",
      "\n",
      "   micro avg       0.20      0.20      0.20      9000\n",
      "   macro avg       0.16      0.17      0.16      9000\n",
      "weighted avg       0.17      0.20      0.17      9000\n",
      "\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "model_eva(xgb_clf,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, dtarget,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "#         xgb_param['num_class']=len(np.unique(dtarget))\n",
    "        xgtrain = xgb.DMatrix(dtrain, label=dtarget)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='mlogloss', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain, dtarget,eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain)\n",
    "    dtrain_predprob = alg.predict_proba(dtrain)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % accuracy_score(dtarget, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): \" , classification_report(dtarget, dtrain_predictions))\n",
    "\n",
    "    feat_imp = pd.Series(alg.feature_importances_).sort_values(ascending=False)[:100]\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelfit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-24d5457b6527>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m  \u001b[0mscale_pos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m  seed=27)\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodelfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'modelfit' is not defined"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " num_class = len(np.unique(y_train_encoded)),\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'multi:softprob',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, X_train,y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(xgb1.n_estimators)\n",
    "print(xgb1.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test1={'max_depth':range(3,10,2),'min_child_weight':range(1,6,2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "gridsearch = GridSearchCV(XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=123,\n",
    " num_class = len(np.unique(y_train_encoded)),\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'multi:softprob',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27),param_grid=param_test1,cv=5,iid=False,scoring='f1_micro',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=123,\n",
       "       n_jobs=1, nthread=4, num_class=11, objective='multi:softprob',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=27, silent=True, subsample=0.8),\n",
       "       fit_params=None, iid=False, n_jobs=-1,\n",
       "       param_grid={'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.fit(X_train,y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid scores on development set:\n",
      "0.211 (+/-0.009) for {'max_depth': 3, 'min_child_weight': 1}\n",
      "0.210 (+/-0.006) for {'max_depth': 3, 'min_child_weight': 3}\n",
      "0.209 (+/-0.007) for {'max_depth': 3, 'min_child_weight': 5}\n",
      "0.210 (+/-0.007) for {'max_depth': 5, 'min_child_weight': 1}\n",
      "0.212 (+/-0.006) for {'max_depth': 5, 'min_child_weight': 3}\n",
      "0.211 (+/-0.006) for {'max_depth': 5, 'min_child_weight': 5}\n",
      "0.212 (+/-0.005) for {'max_depth': 7, 'min_child_weight': 1}\n",
      "0.211 (+/-0.009) for {'max_depth': 7, 'min_child_weight': 3}\n",
      "0.213 (+/-0.005) for {'max_depth': 7, 'min_child_weight': 5}\n",
      "0.211 (+/-0.006) for {'max_depth': 9, 'min_child_weight': 1}\n",
      "0.211 (+/-0.006) for {'max_depth': 9, 'min_child_weight': 3}\n",
      "0.211 (+/-0.007) for {'max_depth': 9, 'min_child_weight': 5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.21319021040929725, {'max_depth': 7, 'min_child_weight': 5})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Grid scores on development set:\")\n",
    "means = gridsearch.cv_results_['mean_test_score']\n",
    "stds = gridsearch.cv_results_['std_test_score']\n",
    "\n",
    "#THIS IS WHAT YOU WANT\n",
    "for mean, std, params in zip(means, stds, gridsearch.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "gridsearch.best_score_,gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test1={'max_depth':[6,7,8],'min_child_weight':[4,5,6,7]}\n",
    "gsearch2=GridSearchCV(XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=123,\n",
    " num_class = len(np.unique(y_train_encoded)),\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'multi:softprob',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27),param_grid=param_test1,cv=5,iid=False,scoring='f1_micro',n_jobs=-1)\n",
    "gridsearch.fit(X_train,y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7, 'min_child_weight': 5}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'grid_scores_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-53e82ee44d7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m  seed=27),param_grid=param_test3,cv=5,iid=False,scoring='f1_micro',n_jobs=-1)\n\u001b[1;32m     14\u001b[0m \u001b[0mgsearch3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mgsearch3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgsearch3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgsearch3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'grid_scores_'"
     ]
    }
   ],
   "source": [
    "gsearch3 = GridSearchCV(XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=123,\n",
    " num_class = len(np.unique(y_train_encoded)),\n",
    " max_depth=7,\n",
    " min_child_weight=6,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'multi:softprob',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27),param_grid=param_test3,cv=5,iid=False,scoring='f1_micro',n_jobs=-1)\n",
    "gsearch3.fit(X_train,y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid scores on development set:\n",
      "0.203 (+/-0.011) for {'gamma': 0.0}\n",
      "0.201 (+/-0.021) for {'gamma': 0.1}\n",
      "0.203 (+/-0.014) for {'gamma': 0.2}\n",
      "0.202 (+/-0.023) for {'gamma': 0.3}\n",
      "0.201 (+/-0.017) for {'gamma': 0.4}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2031325862734225, {'gamma': 0.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Grid scores on development set:\")\n",
    "means = gsearch3.cv_results_['mean_test_score']\n",
    "stds = gsearch3.cv_results_['std_test_score']\n",
    "\n",
    "#THIS IS WHAT YOU WANT\n",
    "for mean, std, params in zip(means, stds, gsearch3.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "gsearch3.best_score_,gsearch3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=7, min_child_weight=6, missing=None, n_estimators=123,\n",
       "       n_jobs=1, nthread=4, num_class=11, objective='multi:softprob',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=27, silent=True, subsample=0.8),\n",
       "       fit_params=None, iid=False, n_jobs=-1,\n",
       "       param_grid={'subsample': [0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.6, 0.7, 0.8, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "\n",
    "gsearch4 = GridSearchCV(XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=123,\n",
    " num_class = len(np.unique(y_train_encoded)),\n",
    " max_depth=7,\n",
    " min_child_weight=6,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'multi:softprob',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27),param_grid=param_test4,cv=5,iid=False,scoring='f1_micro',n_jobs=-1)\n",
    "gsearch4.fit(X_train,y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid scores on development set:\n",
      "0.193 (+/-0.014) for {'colsample_bytree': 0.6, 'subsample': 0.6}\n",
      "0.197 (+/-0.012) for {'colsample_bytree': 0.6, 'subsample': 0.7}\n",
      "0.202 (+/-0.021) for {'colsample_bytree': 0.6, 'subsample': 0.8}\n",
      "0.201 (+/-0.017) for {'colsample_bytree': 0.6, 'subsample': 0.9}\n",
      "0.197 (+/-0.012) for {'colsample_bytree': 0.7, 'subsample': 0.6}\n",
      "0.200 (+/-0.016) for {'colsample_bytree': 0.7, 'subsample': 0.7}\n",
      "0.202 (+/-0.016) for {'colsample_bytree': 0.7, 'subsample': 0.8}\n",
      "0.198 (+/-0.017) for {'colsample_bytree': 0.7, 'subsample': 0.9}\n",
      "0.193 (+/-0.014) for {'colsample_bytree': 0.8, 'subsample': 0.6}\n",
      "0.197 (+/-0.016) for {'colsample_bytree': 0.8, 'subsample': 0.7}\n",
      "0.203 (+/-0.011) for {'colsample_bytree': 0.8, 'subsample': 0.8}\n",
      "0.201 (+/-0.021) for {'colsample_bytree': 0.8, 'subsample': 0.9}\n",
      "0.197 (+/-0.017) for {'colsample_bytree': 0.9, 'subsample': 0.6}\n",
      "0.200 (+/-0.019) for {'colsample_bytree': 0.9, 'subsample': 0.7}\n",
      "0.200 (+/-0.013) for {'colsample_bytree': 0.9, 'subsample': 0.8}\n",
      "0.203 (+/-0.018) for {'colsample_bytree': 0.9, 'subsample': 0.9}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2031325862734225, {'colsample_bytree': 0.8, 'subsample': 0.8})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Grid scores on development set:\")\n",
    "means = gsearch4.cv_results_['mean_test_score']\n",
    "stds = gsearch4.cv_results_['std_test_score']\n",
    "\n",
    "#THIS IS WHAT YOU WANT\n",
    "for mean, std, params in zip(means, stds, gsearch4.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "gsearch4.best_score_,gsearch4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.3384\n",
      "AUC Score (Train):                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.47      0.34      3345\n",
      "           1       0.41      0.11      0.17      2742\n",
      "           2       0.35      0.24      0.28      5941\n",
      "           3       0.33      0.36      0.35      7498\n",
      "           4       0.29      0.40      0.33      8642\n",
      "           5       0.32      0.32      0.32      8502\n",
      "           6       0.45      0.20      0.28      7297\n",
      "           7       0.57      0.16      0.25      6189\n",
      "           8       0.69      0.11      0.20      5002\n",
      "           9       0.75      0.12      0.21      4754\n",
      "          10       0.33      0.78      0.46     10088\n",
      "\n",
      "   micro avg       0.34      0.34      0.34     70000\n",
      "   macro avg       0.43      0.30      0.29     70000\n",
      "weighted avg       0.41      0.34      0.31     70000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb2=XGBClassifier(\n",
    " learning_rate =0.01,\n",
    " n_estimators=5000,\n",
    " num_class = len(np.unique(y_train_encoded)),\n",
    " max_depth=7,\n",
    " min_child_weight=6,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'multi:softprob',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb2, X_train,y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred=xgb2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16849108756696016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.36      0.27      1431\n",
      "           1       0.11      0.03      0.04      1194\n",
      "           2       0.17      0.12      0.14      2469\n",
      "           3       0.19      0.21      0.20      3148\n",
      "           4       0.16      0.22      0.18      3817\n",
      "           5       0.16      0.16      0.16      3705\n",
      "           6       0.15      0.07      0.09      3133\n",
      "           7       0.16      0.03      0.06      2633\n",
      "           8       0.13      0.01      0.03      2208\n",
      "           9       0.14      0.01      0.03      2022\n",
      "          10       0.29      0.72      0.41      4240\n",
      "\n",
      "   micro avg       0.21      0.21      0.21     30000\n",
      "   macro avg       0.17      0.18      0.15     30000\n",
      "weighted avg       0.18      0.21      0.17     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(y_test_encoded,y_test_pred,average='macro'))\n",
    "print(classification_report(y_test_encoded,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method XGBModel.get_params of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=7, min_child_weight=6, missing=None, n_estimators=2251,\n",
       "       n_jobs=1, nthread=4, num_class=11, objective='multi:softprob',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=27, silent=True, subsample=0.8)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb2.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       " array([ 2414,   280,  1754,  3421,  5350,  3766,  1344,   585,   262,\n",
       "          202, 10622]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test_pred,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       " array([1431, 1194, 2469, 3148, 3817, 3705, 3133, 2633, 2208, 2022, 4240]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test_encoded,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
