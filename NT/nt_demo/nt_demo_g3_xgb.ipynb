{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, precision_recall_curve, recall_score, roc_curve, auc, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168575, 7672)\n"
     ]
    }
   ],
   "source": [
    "data = load_svmlight_file('data/demo-g3-v2.txt')\n",
    "X,y=data[0],data[1]\n",
    "print(X.shape)\n",
    "# X_s,y_s=resample(X,y,n_samples=150000,replace=False)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_s,y_s,test_size=.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eva(model,X_test,y_test):\n",
    "    y_test_pred=model.predict(X_test)\n",
    "    print('precision_score:',precision_score(y_test,y_test_pred,average='macro'))\n",
    "    print(confusion_matrix(y_test,y_test_pred).T)\n",
    "    print(np.unique(y_test,return_counts=True))\n",
    "    print(np.unique(y_test_pred,return_counts=True))\n",
    "    print(classification_report(y_test_pred,y_test))\n",
    "    print(\"******************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.2, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=8, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=1,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgb_clf = xgb.XGBClassifier(\n",
    "#                  colsample_bytree=0.2,\n",
    "#                  gamma=0.0,\n",
    "#                  learning_rate=0.01,\n",
    "#                  max_depth=8,\n",
    "#                  min_child_weight=1.5,\n",
    "#                  n_estimators=1000,                                                                  \n",
    "#                  reg_alpha=0.9,\n",
    "#                  reg_lambda=0.6,\n",
    "#                  subsample=0.2,\n",
    "#                  seed=42,\n",
    "#                  silent=1)\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "                 colsample_bytree=0.2,\n",
    "#                  gamma=0.0,\n",
    "                 learning_rate=0.01,\n",
    "                 max_depth=8,\n",
    "#                  min_child_weight=1.5,\n",
    "                 n_estimators=1000,                                                                  \n",
    "#                  reg_alpha=0.9,\n",
    "#                  reg_lambda=0.6,\n",
    "#                  subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "xgb_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.5306832862411817\n",
      "[[ 2303  1116  1126   825   750   615   437   332   213   149   292]\n",
      " [   18   280    19    22    14     7    10     7     3     3     6]\n",
      " [  247   274  1616   426   351   315   215   149   113    86   116]\n",
      " [  338   357  1112  3495  1269  1235   888   513   384   257   288]\n",
      " [ 1138  1076  2500  2956  6223  3171  2744  2067  1551  1247  1619]\n",
      " [  254   240   589  1004  1100  3501  1078   922   734   619   597]\n",
      " [   23    35    91   149   220   197  1762   156   162   118   119]\n",
      " [    3    11    22    43    45    39    42  1216    56    46    42]\n",
      " [    0     0     6    10    13     9    20    17   804     9     5]\n",
      " [    0     0     1     3     3     8     1     7     7   702     6]\n",
      " [  784   739  1708  2311  3104  3663  3707  3907  3723  3766 11839]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 5108,  4128,  8790, 11244, 13092, 12760, 10904,  9293,  7750,\n",
      "        7002, 14929]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 8158,   389,  3908, 10136, 26292, 10638,  3032,  1565,   893,\n",
      "         738, 39251]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.45      0.28      0.35      8158\n",
      "         5.0       0.07      0.72      0.12       389\n",
      "         6.0       0.18      0.41      0.25      3908\n",
      "         7.0       0.31      0.34      0.33     10136\n",
      "         8.0       0.48      0.24      0.32     26292\n",
      "         9.0       0.27      0.33      0.30     10638\n",
      "        10.0       0.16      0.58      0.25      3032\n",
      "        11.0       0.13      0.78      0.22      1565\n",
      "        12.0       0.10      0.90      0.19       893\n",
      "        13.0       0.10      0.95      0.18       738\n",
      "        14.0       0.79      0.30      0.44     39251\n",
      "\n",
      "   micro avg       0.32      0.32      0.32    105000\n",
      "   macro avg       0.28      0.53      0.27    105000\n",
      "weighted avg       0.52      0.32      0.35    105000\n",
      "\n",
      "******************************************************************\n",
      "precision_score: 0.17258678533048707\n",
      "[[ 790  487  511  339  354  270  195  149  101   71  126]\n",
      " [  24   15   18    9    7    9    7    3    2    2    2]\n",
      " [ 167  135  308  230  223  159   98   71   55   39   54]\n",
      " [ 183  174  662  910  812  626  420  246  166  123  132]\n",
      " [ 556  469 1188 1600 1873 1791 1208  888  657  538  727]\n",
      " [ 122  100  322  479  700  779  631  534  359  255  322]\n",
      " [  25   21   48  101  150  200  184  177   92   89   98]\n",
      " [   4    9   18   42   49   52   61   65   53   49   50]\n",
      " [   1    2    4   16   19   27   27   42   19   16   23]\n",
      " [   0    1    6    4    5    6    8    8   13    7   15]\n",
      " [ 371  281  765 1039 1441 1699 1630 1762 1681 1869 4974]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([2243, 1694, 3850, 4769, 5633, 5618, 4469, 3945, 3198, 3058, 6523]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 3393,    98,  1539,  4454, 11495,  4603,  1185,   452,   196,\n",
      "          73, 17512]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.35      0.23      0.28      3393\n",
      "         5.0       0.01      0.15      0.02        98\n",
      "         6.0       0.08      0.20      0.11      1539\n",
      "         7.0       0.19      0.20      0.20      4454\n",
      "         8.0       0.33      0.16      0.22     11495\n",
      "         9.0       0.14      0.17      0.15      4603\n",
      "        10.0       0.04      0.16      0.07      1185\n",
      "        11.0       0.02      0.14      0.03       452\n",
      "        12.0       0.01      0.10      0.01       196\n",
      "        13.0       0.00      0.10      0.00        73\n",
      "        14.0       0.76      0.28      0.41     17512\n",
      "\n",
      "   micro avg       0.22      0.22      0.22     45000\n",
      "   macro avg       0.18      0.17      0.14     45000\n",
      "weighted avg       0.45      0.22      0.28     45000\n",
      "\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "model_eva(xgb_clf,X_train,y_train)\n",
    "model_eva(xgb_clf,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model_eva(model,X_train,y_train)\n",
    "    model_eva(model,X_test,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.4394426811031533\n",
      "[[ 1868  1107  1100   817   738   570   418   338   194   147   282]\n",
      " [    5    27     3     1     4     4     3     0     1     0     2]\n",
      " [  447   379  1144   538   480   393   272   172   143   103   158]\n",
      " [  330   327  1249  2780  1323  1227   825   526   351   249   275]\n",
      " [ 1247  1122  2568  3180  5528  3262  2793  2023  1474  1189  1552]\n",
      " [  305   270   804  1308  1383  3212  1487  1174   992   786   839]\n",
      " [   21    26    73   120   187   177   950   205   161   131   111]\n",
      " [   12    10    31    76    74    68    70   630    99    66    60]\n",
      " [    3     0     4     3     7     5     6     5   247     5     6]\n",
      " [    0     0     1     0     5     1     3     4     2   193     2]\n",
      " [  905   785  1804  2437  3340  3868  3969  4203  4035  4217 11759]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 5143,  4053,  8781, 11260, 13069, 12787, 10796,  9280,  7699,\n",
      "        7086, 15046]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 7579,    50,  4229,  9462, 25938, 12560,  2162,  1196,   291,\n",
      "         211, 41322]))\n",
      "******************************************************************\n",
      "precision_score: 0.19661148446628263\n",
      "[[ 753  471  489  359  306  272  189  128   95   68  116]\n",
      " [   2    3    1    4    1    0    1    0    0    0    0]\n",
      " [ 199  208  352  254  247  199  107   80   45   45   55]\n",
      " [ 121  159  601  887  807  561  390  250  155   99  113]\n",
      " [ 553  488 1189 1534 1717 1572 1220  879  647  503  707]\n",
      " [ 135  110  395  608  822  908  747  573  459  297  443]\n",
      " [  12    6   36   84  119  134  148  113   80   59   63]\n",
      " [   2    3   14   31   54   62   76   71   52   38   49]\n",
      " [   1    0    0    4    7    4   10    6    6    4    6]\n",
      " [   0    0    1    2    1    3    5    3    3    7    7]\n",
      " [ 360  326  792 1039 1454 1816 1730 1894 1746 1835 4924]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([2138, 1774, 3870, 4806, 5535, 5531, 4623, 3997, 3288, 2955, 6483]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 3246,    12,  1791,  4143, 11009,  5497,   854,   452,    48,\n",
      "          32, 17916]))\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "xgb_clf_100_6_1 = xgb.XGBClassifier(\n",
    "#                  colsample_bytree=0.2,\n",
    "#                  gamma=0.0,\n",
    "                 learning_rate=0.1,\n",
    "                 max_depth=6,\n",
    "#                  min_child_weight=1.5,\n",
    "                 n_estimators=100,                                                                  \n",
    "#                  reg_alpha=0.9,\n",
    "#                  reg_lambda=0.6,\n",
    "#                  subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "xgb_clf_100_6_1.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.4691320458454525\n",
      "[[ 2163  1209  1244   941   877   664   506   372   236   179   339]\n",
      " [   13   184    10    11    14     5     3     3     6     5     8]\n",
      " [  259   247  1206   393   337   305   204   151   126    70   128]\n",
      " [  401   360  1326  3158  1607  1360   927   567   390   266   299]\n",
      " [ 1156  1035  2432  3080  5282  3274  2606  1902  1444  1137  1634]\n",
      " [  223   217   685  1104  1358  3001  1368  1077   839   706   786]\n",
      " [   22    29    56   114   153   173  1116   167   111   105    76]\n",
      " [    6    10    34    61    81   102   106   939    88    78    47]\n",
      " [    3     4     3     7     7    13    15    12   488    12    14]\n",
      " [    2     5     6     7    14    13    17    12    12   469    12]\n",
      " [  895   753  1779  2384  3339  3877  3928  4078  3959  4059 11703]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 5143,  4053,  8781, 11260, 13069, 12787, 10796,  9280,  7699,\n",
      "        7086, 15046]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 8730,   262,  3426, 10661, 24982, 11364,  2122,  1552,   578,\n",
      "         569, 40754]))\n",
      "******************************************************************\n",
      "precision_score: 0.1663364693964647\n",
      "[[ 833  527  560  411  368  303  217  155  116   76  140]\n",
      " [  24   15   17    9    6    9    5    6    1    8    7]\n",
      " [ 132  150  243  195  195  150  106   81   43   47   52]\n",
      " [ 149  182  673  954  855  632  405  284  165  117  123]\n",
      " [ 524  448 1169 1482 1677 1566 1198  868  656  486  732]\n",
      " [  94  104  347  566  754  800  698  524  395  279  385]\n",
      " [  16   10   45   78  114  136  138  118   59   49   68]\n",
      " [   5   13   19   64   73   88   97   90   73   58   75]\n",
      " [   2    1    5    9   11   17   23   23    9   22   25]\n",
      " [   1    2    6    8    9   15   16   18   20   17   24]\n",
      " [ 358  322  786 1030 1473 1815 1720 1830 1751 1796 4852]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([2138, 1774, 3870, 4806, 5535, 5531, 4623, 3997, 3288, 2955, 6483]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 3706,   107,  1394,  4539, 10806,  4946,   831,   655,   147,\n",
      "         136, 17733]))\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "test(xgb_clf_100_6_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.5432161012671715\n",
      "[[ 2800   946   969   774   727   547   437   343   202   172   306]\n",
      " [   84   847    92    93    67    69    56    36    21    17    33]\n",
      " [  352   396  3020   570   549   515   355   235   208   139   222]\n",
      " [  314   352  1068  4836  1349  1239   887   585   387   280   352]\n",
      " [  649   644  1500  1914  6530  2182  1805  1385  1029   808   877]\n",
      " [  231   236   597   920  1017  5012  1085   826   720   575   572]\n",
      " [   59    50   150   229   294   270  3118   271   202   176   160]\n",
      " [   22    36    86    99   147   143   120  2535   123   123   106]\n",
      " [    8    14    34    41    44    48    55    51  1833    35    44]\n",
      " [    5    14    14    32    36    46    42    48    41  1849    41]\n",
      " [  619   518  1251  1752  2309  2716  2836  2965  2933  2912 12333]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 5143,  4053,  8781, 11260, 13069, 12787, 10796,  9280,  7699,\n",
      "        7086, 15046]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 8223,  1415,  6561, 11649, 19323, 11791,  4979,  3540,  2207,\n",
      "        2168, 33144]))\n",
      "******************************************************************\n",
      "precision_score: 0.16672562972397278\n",
      "[[ 789  522  528  385  336  300  215  147  112   70  134]\n",
      " [ 115   68   92   61   49   40   37   34   22   27   33]\n",
      " [ 242  229  475  367  366  312  204  147   94   74   92]\n",
      " [ 161  228  696  993  924  667  478  311  200  141  166]\n",
      " [ 365  283  842 1190 1373 1269  950  699  469  362  517]\n",
      " [ 133  117  379  614  818  863  702  520  429  297  397]\n",
      " [  32   40  117  199  263  304  306  236  180  120  181]\n",
      " [  18   32   61  129  142  187  184  170  146  142  167]\n",
      " [  10    8   29   47   68   71   90   89   62   73  100]\n",
      " [   4   15   24   33   49   62   79   67   71   62  120]\n",
      " [ 269  232  627  788 1147 1456 1378 1577 1503 1587 4576]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([2138, 1774, 3870, 4806, 5535, 5531, 4623, 3997, 3288, 2955, 6483]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 3538,   578,  2602,  4965,  8319,  5269,  1978,  1378,   647,\n",
      "         586, 15140]))\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "xgb_clf_1000_6_1 = xgb.XGBClassifier(\n",
    "#                  colsample_bytree=0.2,\n",
    "#                  gamma=0.0,\n",
    "                 learning_rate=0.1,\n",
    "                 max_depth=6,\n",
    "#                  min_child_weight=1.5,\n",
    "                 n_estimators=1000,                                                                  \n",
    "#                  reg_alpha=0.9,\n",
    "#                  reg_lambda=0.6,\n",
    "#                  subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "xgb_clf_1000_6_1.fit(X_train,y_train)\n",
    "test(xgb_clf_1000_6_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.46939975391103433\n",
      "[[ 2126  1189  1225   943   873   664   503   373   235   173   335]\n",
      " [   10   174    11    16    19    10     3     7     7     5     9]\n",
      " [  280   260  1197   386   343   293   199   151   130    77   125]\n",
      " [  426   391  1382  3161  1610  1412  1013   580   414   290   349]\n",
      " [ 1155  1034  2433  3084  5299  3305  2594  1940  1451  1179  1633]\n",
      " [  211   206   656  1084  1314  2917  1386  1049   813   676   758]\n",
      " [   19    29    53    98   121   141  1002   127   104    95    62]\n",
      " [    4     7    30    58    83    95    93   924    82    68    39]\n",
      " [    3     3     2     7     5    10    12     8   478     9     9]\n",
      " [    1     4     6     9     9    11    17    11     7   454    11]\n",
      " [  908   756  1786  2414  3393  3929  3974  4110  3978  4060 11716]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 5143,  4053,  8781, 11260, 13069, 12787, 10796,  9280,  7699,\n",
      "        7086, 15046]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 8639,   271,  3441, 11028, 25107, 11070,  1851,  1483,   546,\n",
      "         540, 41024]))\n",
      "******************************************************************\n",
      "precision_score: 0.16940962171425386\n",
      "[[ 822  516  550  405  370  306  216  152  114   79  140]\n",
      " [  18   13   19   12    9    8    6    7    2    9    6]\n",
      " [ 137  165  248  195  194  149  107   80   36   46   55]\n",
      " [ 161  174  681  991  882  639  413  294  163  131  131]\n",
      " [ 526  447 1170 1480 1676 1568 1220  866  669  492  754]\n",
      " [  87  102  328  539  736  816  696  521  385  266  376]\n",
      " [  19   13   45   64  101  117  133  108   61   42   49]\n",
      " [   6   11   17   57   69   91   82   90   73   57   67]\n",
      " [   1    1    3    8   11   14   17   23   14   18   24]\n",
      " [   0    2    5    8    5   15   21   14   13   13   22]\n",
      " [ 361  330  804 1047 1482 1808 1712 1842 1758 1802 4859]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([2138, 1774, 3870, 4806, 5535, 5531, 4623, 3997, 3288, 2955, 6483]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 3670,   109,  1412,  4660, 10868,  4852,   752,   620,   134,\n",
      "         118, 17805]))\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "xgb_clf_1000_6_01 = xgb.XGBClassifier(\n",
    "#                  colsample_bytree=0.2,\n",
    "#                  gamma=0.0,\n",
    "                 learning_rate=0.01,\n",
    "                 max_depth=6,\n",
    "#                  min_child_weight=1.5,\n",
    "                 n_estimators=1000,                                                                  \n",
    "#                  reg_alpha=0.9,\n",
    "#                  reg_lambda=0.6,\n",
    "#                  subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "xgb_clf_1000_6_01.fit(X_train,y_train)\n",
    "test(xgb_clf_1000_6_01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
