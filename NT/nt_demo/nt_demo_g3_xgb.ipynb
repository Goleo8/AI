{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score,precision_score, precision_recall_curve, recall_score, roc_curve, auc, confusion_matrix,classification_report\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_svmlight_file('data/demo-g3-v2.txt')\n",
    "X,y=data[0],data[1]\n",
    "X_s,y_s=resample(X,y,n_samples=30000,replace=False)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_s,y_s,test_size=.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_eva(model,X_test,y_test):\n",
    "    y_test_pred=model.predict(X_test)\n",
    "    print('precision_score:',precision_score(y_test,y_test_pred,average='macro'))\n",
    "    print(confusion_matrix(y_test,y_test_pred).T)\n",
    "    print(np.unique(y_test,return_counts=True))\n",
    "    print(np.unique(y_test_pred,return_counts=True))\n",
    "    print(classification_report(y_test,y_test_pred))\n",
    "    print(\"******************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca=PCA(n_components=100,svd_solver='randomized')\n",
    "X_train_array=X_train.toarray()\n",
    "pca.fit(X_train_array)\n",
    "X_train_pca=pca.transform(X_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.2, gamma=0.0, learning_rate=0.01,\n",
       "       max_delta_step=0, max_depth=8, min_child_weight=1.5, missing=None,\n",
       "       n_estimators=1000, n_jobs=1, nthread=None,\n",
       "       objective='multi:softprob', random_state=0, reg_alpha=0.9,\n",
       "       reg_lambda=0.6, scale_pos_weight=1, seed=42, silent=1,\n",
       "       subsample=0.2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf_raw = xgb.XGBClassifier(\n",
    "                 colsample_bytree=0.2,\n",
    "                 gamma=0.0,\n",
    "                 learning_rate=0.01,\n",
    "                 max_depth=8,\n",
    "                 min_child_weight=1.5,\n",
    "                 n_estimators=1000,                                                                  \n",
    "                 reg_alpha=0.9,\n",
    "                 reg_lambda=0.6,\n",
    "                 subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "xgb_clf_raw.fit(X_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.2, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=8, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=1,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgb_clf = xgb.XGBClassifier(\n",
    "#                  colsample_bytree=0.2,\n",
    "#                  gamma=0.0,\n",
    "#                  learning_rate=0.01,\n",
    "#                  max_depth=8,\n",
    "#                  min_child_weight=1.5,\n",
    "#                  n_estimators=1000,                                                                  \n",
    "#                  reg_alpha=0.9,\n",
    "#                  reg_lambda=0.6,\n",
    "#                  subsample=0.2,\n",
    "#                  seed=42,\n",
    "#                  silent=1)\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "                 colsample_bytree=0.2,\n",
    "#                  gamma=0.0,\n",
    "                 learning_rate=0.01,\n",
    "                 max_depth=8,\n",
    "#                  min_child_weight=1.5,\n",
    "                 n_estimators=1000,                                                                  \n",
    "#                  reg_alpha=0.9,\n",
    "#                  reg_lambda=0.6,\n",
    "#                  subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "xgb_clf.fit(X_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_array=X_test.toarray()\n",
    "X_test_pca=pca.transform(X_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model_eva(model,X_train_pca,y_train)\n",
    "    model_eva(model,X_test_pca,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.6495335349074474\n",
      "[[1462  336  320  320  303  219  185  134  103   78  105]\n",
      " [  48  532   46   48   42   38   26   20   13   12   15]\n",
      " [ 189  230 2253  281  260  240  211  172  131   92  140]\n",
      " [ 142  152  269 3421  279  283  281  246  205  145  158]\n",
      " [ 276  262  493  482 4574  473  541  481  397  351  343]\n",
      " [ 216  242  487  452  422 4513  436  501  405  412  343]\n",
      " [  50   59  114  109   97   84 2836  109   91   97   71]\n",
      " [  16   27   47   48   43   23   31 2086   30   31   14]\n",
      " [   8    4   19   21   23   26   24   23 1542   18   17]\n",
      " [   3    6   10   11   17   14   15   12   11 1391   17]\n",
      " [ 286  288  673  801  955 1058 1106 1137 1150 1174 6740]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([2696, 2138, 4731, 5994, 7015, 6971, 5692, 4921, 4078, 3801, 7963]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 3565,   840,  4199,  5581,  8673,  8429,  3717,  2396,  1725,\n",
      "        1507, 15368]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.41      0.54      0.47      2696\n",
      "         5.0       0.63      0.25      0.36      2138\n",
      "         6.0       0.54      0.48      0.50      4731\n",
      "         7.0       0.61      0.57      0.59      5994\n",
      "         8.0       0.53      0.65      0.58      7015\n",
      "         9.0       0.54      0.65      0.59      6971\n",
      "        10.0       0.76      0.50      0.60      5692\n",
      "        11.0       0.87      0.42      0.57      4921\n",
      "        12.0       0.89      0.38      0.53      4078\n",
      "        13.0       0.92      0.37      0.52      3801\n",
      "        14.0       0.44      0.85      0.58      7963\n",
      "\n",
      "   micro avg       0.56      0.56      0.56     56000\n",
      "   macro avg       0.65      0.51      0.54     56000\n",
      "weighted avg       0.63      0.56      0.56     56000\n",
      "\n",
      "******************************************************************\n",
      "precision_score: 0.1690032614347597\n",
      "[[ 352  216  213  159  174  126   92   72   48   38   61]\n",
      " [  41   37   30   37   32   18   10   13   11    4    7]\n",
      " [ 156  128  234  224  179  150   95   76   46   46   76]\n",
      " [ 105   89  317  434  350  286  213  142   97   79   88]\n",
      " [ 202  147  412  589  661  618  466  331  229  200  325]\n",
      " [ 151  126  325  495  630  574  498  374  300  250  383]\n",
      " [  21   26   84  119  156  179  156  135   97   80  117]\n",
      " [  15   16   34   47   81   75   71   61   50   38   68]\n",
      " [   2    8   18   21   26   34   20   30   28   22   42]\n",
      " [   2    1    8   15   17   14   16   23   12   31   35]\n",
      " [ 152  143  343  460  654  797  798  862  801  834 2318]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1199,  937, 2018, 2600, 2960, 2871, 2435, 2119, 1719, 1622, 3520]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1551,  240, 1410, 2200, 4180, 4106, 1170,  556,  251,  174, 8162]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.23      0.29      0.26      1199\n",
      "         5.0       0.15      0.04      0.06       937\n",
      "         6.0       0.17      0.12      0.14      2018\n",
      "         7.0       0.20      0.17      0.18      2600\n",
      "         8.0       0.16      0.22      0.19      2960\n",
      "         9.0       0.14      0.20      0.16      2871\n",
      "        10.0       0.13      0.06      0.09      2435\n",
      "        11.0       0.11      0.03      0.05      2119\n",
      "        12.0       0.11      0.02      0.03      1719\n",
      "        13.0       0.18      0.02      0.03      1622\n",
      "        14.0       0.28      0.66      0.40      3520\n",
      "\n",
      "   micro avg       0.20      0.20      0.20     24000\n",
      "   macro avg       0.17      0.17      0.14     24000\n",
      "weighted avg       0.17      0.20      0.16     24000\n",
      "\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "test(xgb_clf_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.7611078475149125\n",
      "[[1937  358  371  293  279  242  205  179  119   63  120]\n",
      " [  24 1074   25   21   22   21   22   20   11    9   11]\n",
      " [ 142  151 2876  154  172  174  163  111   85   69   90]\n",
      " [ 191  213  327 4387  353  355  337  270  201  132  158]\n",
      " [ 121  119  269  234 4920  258  357  329  232  197  169]\n",
      " [  82   97  216  207  183 4813  204  194  150  163  118]\n",
      " [  23   20   68   71   66   68 3662   65   49   49   36]\n",
      " [   8    3    8   20   28   17   15 2946   20   17   15]\n",
      " [   0    0    7   14    6   11    8   15 2499    8    9]\n",
      " [   4    0    9    8   10    8    8    9   12 2287    9]\n",
      " [ 161  152  526  618  790  845  855  863  773  714 7319]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([2693, 2187, 4702, 6027, 6829, 6812, 5836, 5001, 4151, 3708, 8054]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 4166,  1260,  4187,  6924,  7205,  6427,  4177,  3097,  2577,\n",
      "        2364, 13616]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.46      0.72      0.56      2693\n",
      "         5.0       0.85      0.49      0.62      2187\n",
      "         6.0       0.69      0.61      0.65      4702\n",
      "         7.0       0.63      0.73      0.68      6027\n",
      "         8.0       0.68      0.72      0.70      6829\n",
      "         9.0       0.75      0.71      0.73      6812\n",
      "        10.0       0.88      0.63      0.73      5836\n",
      "        11.0       0.95      0.59      0.73      5001\n",
      "        12.0       0.97      0.60      0.74      4151\n",
      "        13.0       0.97      0.62      0.75      3708\n",
      "        14.0       0.54      0.91      0.68      8054\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     56000\n",
      "   macro avg       0.76      0.67      0.69     56000\n",
      "weighted avg       0.75      0.69      0.70     56000\n",
      "\n",
      "******************************************************************\n",
      "precision_score: 0.15234335026273077\n",
      "[[ 362  251  211  177  178  147   88   80   54   39   71]\n",
      " [  27   19   33   19   21    9   12    5    9    5   10]\n",
      " [ 141  116  212  182  176  155  107   79   53   33   78]\n",
      " [ 147  139  372  462  514  396  265  187  126   90  130]\n",
      " [ 172  119  377  558  630  570  428  311  228  190  293]\n",
      " [ 123  104  275  413  522  502  455  300  254  185  299]\n",
      " [  28   31   97  127  189  199  152  146  123   92  143]\n",
      " [   8   13   23   52   84   74   64   71   56   34   72]\n",
      " [   3    3    9   22   27   32   34   29   16   22   29]\n",
      " [   3    4   19   16   20   33   22   17   16   25   37]\n",
      " [ 167  148  344  513  716  822  823  856  781  857 2362]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1181,  947, 1972, 2541, 3077, 2939, 2450, 2081, 1716, 1572, 3524]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1658,  169, 1332, 2828, 3876, 3432, 1327,  551,  226,  212, 8389]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.22      0.31      0.26      1181\n",
      "         5.0       0.11      0.02      0.03       947\n",
      "         6.0       0.16      0.11      0.13      1972\n",
      "         7.0       0.16      0.18      0.17      2541\n",
      "         8.0       0.16      0.20      0.18      3077\n",
      "         9.0       0.15      0.17      0.16      2939\n",
      "        10.0       0.11      0.06      0.08      2450\n",
      "        11.0       0.13      0.03      0.05      2081\n",
      "        12.0       0.07      0.01      0.02      1716\n",
      "        13.0       0.12      0.02      0.03      1572\n",
      "        14.0       0.28      0.67      0.40      3524\n",
      "\n",
      "   micro avg       0.20      0.20      0.20     24000\n",
      "   macro avg       0.15      0.16      0.14     24000\n",
      "weighted avg       0.16      0.20      0.16     24000\n",
      "\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "test(xgb_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.2, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=8, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=1,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf_1000_8_raw = xgb.XGBClassifier(\n",
    "                 colsample_bytree=0.2,\n",
    "#                  gamma=0.0,\n",
    "                 learning_rate=0.1,\n",
    "                 max_depth=8,\n",
    "#                  min_child_weight=1.5,\n",
    "                 n_estimators=1000,                                                                  \n",
    "#                  reg_alpha=0.9,\n",
    "#                  reg_lambda=0.6,\n",
    "#                  subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "xgb_clf_1000_8_raw.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.6104409877562791\n",
      "[[1681  412  446  358  340  256  197  143  123   91  148]\n",
      " [  60  778   62   63   64   50   40   34   14   11   15]\n",
      " [ 154  146 2126  286  263  260  201  128   97   86  106]\n",
      " [  93  123  344 3038  435  414  337  231  177  143  156]\n",
      " [ 288  265  660  812 4157  885  810  629  434  311  381]\n",
      " [ 138  136  372  479  539 3703  565  460  410  329  289]\n",
      " [  25   32   78  106  128  137 2250  114  105   92   86]\n",
      " [  21   18   32   58   76   66   68 1891   61   52   50]\n",
      " [  11   12   23   38   31   32   30   42 1477   41   45]\n",
      " [   4    6   16   24   29   36   32   30   38 1460   34]\n",
      " [ 221  210  572  732  953 1132 1162 1219 1142 1185 6653]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([2696, 2138, 4731, 5994, 7015, 6971, 5692, 4921, 4078, 3801, 7963]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 4195,  1191,  3853,  5491,  9632,  7420,  3153,  2393,  1782,\n",
      "        1709, 15181]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.40      0.62      0.49      2696\n",
      "         5.0       0.65      0.36      0.47      2138\n",
      "         6.0       0.55      0.45      0.50      4731\n",
      "         7.0       0.55      0.51      0.53      5994\n",
      "         8.0       0.43      0.59      0.50      7015\n",
      "         9.0       0.50      0.53      0.51      6971\n",
      "        10.0       0.71      0.40      0.51      5692\n",
      "        11.0       0.79      0.38      0.52      4921\n",
      "        12.0       0.83      0.36      0.50      4078\n",
      "        13.0       0.85      0.38      0.53      3801\n",
      "        14.0       0.44      0.84      0.57      7963\n",
      "\n",
      "   micro avg       0.52      0.52      0.52     56000\n",
      "   macro avg       0.61      0.49      0.51     56000\n",
      "weighted avg       0.59      0.52      0.52     56000\n",
      "\n",
      "******************************************************************\n",
      "precision_score: 0.16412102787994068\n",
      "[[ 390  260  250  189  192  152  104   78   59   54   64]\n",
      " [  88   47   55   51   42   40   31   18    8    8   29]\n",
      " [ 132  117  255  242  184  154  128   62   55   45   77]\n",
      " [  81   81  306  434  364  290  214  135   96   61  120]\n",
      " [ 203  150  439  617  735  683  495  369  225  201  252]\n",
      " [ 111  104  294  454  536  515  399  303  232  196  240]\n",
      " [  29   16   72  113  158  183  149  148  113   92  110]\n",
      " [  25   21   26   51  106  113  113  105   87   75   95]\n",
      " [   7    9   22   43   44   60   72   68   59   48   99]\n",
      " [   9   10   21   29   45   48   54   52   46   45   95]\n",
      " [ 124  122  278  377  554  633  676  781  739  797 2339]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1199,  937, 2018, 2600, 2960, 2871, 2435, 2119, 1719, 1622, 3520]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1792,  417, 1451, 2182, 4369, 3384, 1183,  817,  531,  454, 7420]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.22      0.33      0.26      1199\n",
      "         5.0       0.11      0.05      0.07       937\n",
      "         6.0       0.18      0.13      0.15      2018\n",
      "         7.0       0.20      0.17      0.18      2600\n",
      "         8.0       0.17      0.25      0.20      2960\n",
      "         9.0       0.15      0.18      0.16      2871\n",
      "        10.0       0.13      0.06      0.08      2435\n",
      "        11.0       0.13      0.05      0.07      2119\n",
      "        12.0       0.11      0.03      0.05      1719\n",
      "        13.0       0.10      0.03      0.04      1622\n",
      "        14.0       0.32      0.66      0.43      3520\n",
      "\n",
      "   micro avg       0.21      0.21      0.21     24000\n",
      "   macro avg       0.16      0.18      0.15     24000\n",
      "weighted avg       0.18      0.21      0.18     24000\n",
      "\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "model_eva(xgb_clf_1000_8_raw,X_train,y_train)\n",
    "model_eva(xgb_clf_1000_8_raw,X_test,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.5432161012671715\n",
      "[[ 2800   946   969   774   727   547   437   343   202   172   306]\n",
      " [   84   847    92    93    67    69    56    36    21    17    33]\n",
      " [  352   396  3020   570   549   515   355   235   208   139   222]\n",
      " [  314   352  1068  4836  1349  1239   887   585   387   280   352]\n",
      " [  649   644  1500  1914  6530  2182  1805  1385  1029   808   877]\n",
      " [  231   236   597   920  1017  5012  1085   826   720   575   572]\n",
      " [   59    50   150   229   294   270  3118   271   202   176   160]\n",
      " [   22    36    86    99   147   143   120  2535   123   123   106]\n",
      " [    8    14    34    41    44    48    55    51  1833    35    44]\n",
      " [    5    14    14    32    36    46    42    48    41  1849    41]\n",
      " [  619   518  1251  1752  2309  2716  2836  2965  2933  2912 12333]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 5143,  4053,  8781, 11260, 13069, 12787, 10796,  9280,  7699,\n",
      "        7086, 15046]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 8223,  1415,  6561, 11649, 19323, 11791,  4979,  3540,  2207,\n",
      "        2168, 33144]))\n",
      "******************************************************************\n",
      "precision_score: 0.16672562972397278\n",
      "[[ 789  522  528  385  336  300  215  147  112   70  134]\n",
      " [ 115   68   92   61   49   40   37   34   22   27   33]\n",
      " [ 242  229  475  367  366  312  204  147   94   74   92]\n",
      " [ 161  228  696  993  924  667  478  311  200  141  166]\n",
      " [ 365  283  842 1190 1373 1269  950  699  469  362  517]\n",
      " [ 133  117  379  614  818  863  702  520  429  297  397]\n",
      " [  32   40  117  199  263  304  306  236  180  120  181]\n",
      " [  18   32   61  129  142  187  184  170  146  142  167]\n",
      " [  10    8   29   47   68   71   90   89   62   73  100]\n",
      " [   4   15   24   33   49   62   79   67   71   62  120]\n",
      " [ 269  232  627  788 1147 1456 1378 1577 1503 1587 4576]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([2138, 1774, 3870, 4806, 5535, 5531, 4623, 3997, 3288, 2955, 6483]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 3538,   578,  2602,  4965,  8319,  5269,  1978,  1378,   647,\n",
      "         586, 15140]))\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "xgb_clf_1000_6_1 = xgb.XGBClassifier(\n",
    "#                  colsample_bytree=0.2,\n",
    "#                  gamma=0.0,\n",
    "                 learning_rate=0.1,\n",
    "                 max_depth=6,\n",
    "#                  min_child_weight=1.5,\n",
    "                 n_estimators=1000,                                                                  \n",
    "#                  reg_alpha=0.9,\n",
    "#                  reg_lambda=0.6,\n",
    "#                  subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "xgb_clf_1000_6_1.fit(X_train,y_train)\n",
    "test(xgb_clf_1000_6_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.46939975391103433\n",
      "[[ 2126  1189  1225   943   873   664   503   373   235   173   335]\n",
      " [   10   174    11    16    19    10     3     7     7     5     9]\n",
      " [  280   260  1197   386   343   293   199   151   130    77   125]\n",
      " [  426   391  1382  3161  1610  1412  1013   580   414   290   349]\n",
      " [ 1155  1034  2433  3084  5299  3305  2594  1940  1451  1179  1633]\n",
      " [  211   206   656  1084  1314  2917  1386  1049   813   676   758]\n",
      " [   19    29    53    98   121   141  1002   127   104    95    62]\n",
      " [    4     7    30    58    83    95    93   924    82    68    39]\n",
      " [    3     3     2     7     5    10    12     8   478     9     9]\n",
      " [    1     4     6     9     9    11    17    11     7   454    11]\n",
      " [  908   756  1786  2414  3393  3929  3974  4110  3978  4060 11716]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 5143,  4053,  8781, 11260, 13069, 12787, 10796,  9280,  7699,\n",
      "        7086, 15046]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 8639,   271,  3441, 11028, 25107, 11070,  1851,  1483,   546,\n",
      "         540, 41024]))\n",
      "******************************************************************\n",
      "precision_score: 0.16940962171425386\n",
      "[[ 822  516  550  405  370  306  216  152  114   79  140]\n",
      " [  18   13   19   12    9    8    6    7    2    9    6]\n",
      " [ 137  165  248  195  194  149  107   80   36   46   55]\n",
      " [ 161  174  681  991  882  639  413  294  163  131  131]\n",
      " [ 526  447 1170 1480 1676 1568 1220  866  669  492  754]\n",
      " [  87  102  328  539  736  816  696  521  385  266  376]\n",
      " [  19   13   45   64  101  117  133  108   61   42   49]\n",
      " [   6   11   17   57   69   91   82   90   73   57   67]\n",
      " [   1    1    3    8   11   14   17   23   14   18   24]\n",
      " [   0    2    5    8    5   15   21   14   13   13   22]\n",
      " [ 361  330  804 1047 1482 1808 1712 1842 1758 1802 4859]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([2138, 1774, 3870, 4806, 5535, 5531, 4623, 3997, 3288, 2955, 6483]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 3670,   109,  1412,  4660, 10868,  4852,   752,   620,   134,\n",
      "         118, 17805]))\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "xgb_clf_1000_6_01 = xgb.XGBClassifier(\n",
    "#                  colsample_bytree=0.2,\n",
    "#                  gamma=0.0,\n",
    "                 learning_rate=0.01,\n",
    "                 max_depth=6,\n",
    "#                  min_child_weight=1.5,\n",
    "                 n_estimators=1000,                                                                  \n",
    "#                  reg_alpha=0.9,\n",
    "#                  reg_lambda=0.6,\n",
    "#                  subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "xgb_clf_1000_6_01.fit(X_train,y_train)\n",
    "test(xgb_clf_1000_6_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=8, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=1,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(\n",
    "#                  colsample_bytree=0.2,\n",
    "#                  gamma=0.0,\n",
    "#                  learning_rate=0.01,\n",
    "                 max_depth=8,\n",
    "#                  min_child_weight=1.5,\n",
    "                 n_estimators=1000,                                                                  \n",
    "#                  reg_alpha=0.9,\n",
    "#                  reg_lambda=0.6,\n",
    "#                  subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "xgb_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.7323486066030511\n",
      "[[ 825  128  133  107  120   74   62   54   36   22   42]\n",
      " [  24  443   28   27   25   14   19   16    9    6   15]\n",
      " [  56   51 1159   92   99   95   63   45   34   30   40]\n",
      " [  24   33   69 1490   81   82   77   68   50   34   36]\n",
      " [  60   66  140  183 1936  211  175  148  103   72   94]\n",
      " [  28   28   67   83   83 1689   96   79   57   60   51]\n",
      " [   9   15   30   38   33   47 1302   30   36   20   31]\n",
      " [   5    6   22   26   25   26   20 1101   23   17   18]\n",
      " [   1    1    6    9    9   14   12   12  936   13    8]\n",
      " [   3    4    8    5   11    8   13    9    3  843    9]\n",
      " [  60   48  135  189  217  252  257  271  208  204 2796]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1095,  823, 1797, 2249, 2639, 2512, 2096, 1833, 1495, 1321, 3140]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([1603,  626, 1764, 2044, 3188, 2321, 1591, 1289, 1021,  916, 4637]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.51      0.75      0.61      1095\n",
      "         5.0       0.71      0.54      0.61       823\n",
      "         6.0       0.66      0.64      0.65      1797\n",
      "         7.0       0.73      0.66      0.69      2249\n",
      "         8.0       0.61      0.73      0.66      2639\n",
      "         9.0       0.73      0.67      0.70      2512\n",
      "        10.0       0.82      0.62      0.71      2096\n",
      "        11.0       0.85      0.60      0.71      1833\n",
      "        12.0       0.92      0.63      0.74      1495\n",
      "        13.0       0.92      0.64      0.75      1321\n",
      "        14.0       0.60      0.89      0.72      3140\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     21000\n",
      "   macro avg       0.73      0.67      0.69     21000\n",
      "weighted avg       0.72      0.69      0.69     21000\n",
      "\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "model_eva(xgb_clf,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.15792409323327827\n",
      "[[149  95 123  86  68  48  49  29  23  20  27]\n",
      " [ 30  15  21  18  21  25  12  14   6   9   8]\n",
      " [ 59  42 101 106 113  88  61  52  29  20  36]\n",
      " [ 30  25  99 140 124 111  90  70  46  27  41]\n",
      " [ 56  55 161 233 229 217 193 117  73  63  94]\n",
      " [ 31  33  86 135 173 181 114  97  75  78  65]\n",
      " [ 13  12  40  67  99 110  97  70  47  42  62]\n",
      " [  8  12  27  38  49  81  65  67  48  36  69]\n",
      " [ 11   9  14  30  31  47  35  29  36  29  51]\n",
      " [  9   2  11  16  18  26  21  20  12  20  46]\n",
      " [ 37  34  88 118 166 185 237 253 246 253 736]]\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 433,  334,  771,  987, 1091, 1119,  974,  818,  641,  597, 1235]))\n",
      "(array([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.]), array([ 717,  179,  707,  803, 1491, 1068,  659,  500,  322,  201, 2353]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         4.0       0.21      0.34      0.26       433\n",
      "         5.0       0.08      0.04      0.06       334\n",
      "         6.0       0.14      0.13      0.14       771\n",
      "         7.0       0.17      0.14      0.16       987\n",
      "         8.0       0.15      0.21      0.18      1091\n",
      "         9.0       0.17      0.16      0.17      1119\n",
      "        10.0       0.15      0.10      0.12       974\n",
      "        11.0       0.13      0.08      0.10       818\n",
      "        12.0       0.11      0.06      0.07       641\n",
      "        13.0       0.10      0.03      0.05       597\n",
      "        14.0       0.31      0.60      0.41      1235\n",
      "\n",
      "   micro avg       0.20      0.20      0.20      9000\n",
      "   macro avg       0.16      0.17      0.16      9000\n",
      "weighted avg       0.17      0.20      0.17      9000\n",
      "\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "model_eva(xgb_clf,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, dtarget,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "#         xgb_param['num_class']=len(np.unique(dtarget))\n",
    "        xgtrain = xgb.DMatrix(dtrain, label=dtarget)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='mlogloss', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain, dtarget,eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain)\n",
    "    dtrain_predprob = alg.predict_proba(dtrain)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % accuracy_score(dtarget, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): \" , classification_report(dtarget, dtrain_predictions))\n",
    "\n",
    "    feat_imp = pd.Series(alg.feature_importances_).sort_values(ascending=False)[:100]\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  1, 10, ...,  2, 10,  4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train_encoded=le.fit_transform(y_train)\n",
    "y_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.3778\n",
      "AUC Score (Train):                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.50      0.39      1095\n",
      "           1       0.55      0.14      0.22       823\n",
      "           2       0.35      0.31      0.33      1797\n",
      "           3       0.47      0.33      0.39      2249\n",
      "           4       0.29      0.51      0.37      2639\n",
      "           5       0.46      0.29      0.36      2512\n",
      "           6       0.57      0.22      0.32      2096\n",
      "           7       0.68      0.23      0.34      1833\n",
      "           8       0.85      0.16      0.27      1495\n",
      "           9       0.84      0.16      0.27      1321\n",
      "          10       0.33      0.81      0.47      3140\n",
      "\n",
      "   micro avg       0.38      0.38      0.38     21000\n",
      "   macro avg       0.52      0.33      0.34     21000\n",
      "weighted avg       0.49      0.38      0.36     21000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " num_class = len(np.unique(y_train_encoded)),\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'multi:softprob',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, X_train,y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(xgb1.n_estimators)\n",
    "print(xgb1.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test1={'max_depth':range(3,10,2),'min_child_weight':range(1,6,2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "gridsearch = GridSearchCV(XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=123,\n",
    " num_class = len(np.unique(y_train_encoded)),\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'multi:softprob',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27),param_grid=param_test1,cv=5,iid=False,scoring='f1_micro',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=123,\n",
       "       n_jobs=1, nthread=4, num_class=11, objective='multi:softprob',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=27, silent=True, subsample=0.8),\n",
       "       fit_params=None, iid=False, n_jobs=-1,\n",
       "       param_grid={'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.fit(X_train,y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid scores on development set:\n",
      "0.211 (+/-0.009) for {'max_depth': 3, 'min_child_weight': 1}\n",
      "0.210 (+/-0.006) for {'max_depth': 3, 'min_child_weight': 3}\n",
      "0.209 (+/-0.007) for {'max_depth': 3, 'min_child_weight': 5}\n",
      "0.210 (+/-0.007) for {'max_depth': 5, 'min_child_weight': 1}\n",
      "0.212 (+/-0.006) for {'max_depth': 5, 'min_child_weight': 3}\n",
      "0.211 (+/-0.006) for {'max_depth': 5, 'min_child_weight': 5}\n",
      "0.212 (+/-0.005) for {'max_depth': 7, 'min_child_weight': 1}\n",
      "0.211 (+/-0.009) for {'max_depth': 7, 'min_child_weight': 3}\n",
      "0.213 (+/-0.005) for {'max_depth': 7, 'min_child_weight': 5}\n",
      "0.211 (+/-0.006) for {'max_depth': 9, 'min_child_weight': 1}\n",
      "0.211 (+/-0.006) for {'max_depth': 9, 'min_child_weight': 3}\n",
      "0.211 (+/-0.007) for {'max_depth': 9, 'min_child_weight': 5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.21319021040929725, {'max_depth': 7, 'min_child_weight': 5})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Grid scores on development set:\")\n",
    "means = gridsearch.cv_results_['mean_test_score']\n",
    "stds = gridsearch.cv_results_['std_test_score']\n",
    "\n",
    "#THIS IS WHAT YOU WANT\n",
    "for mean, std, params in zip(means, stds, gridsearch.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "gridsearch.best_score_,gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test1={'max_depth':[6,7,8],'min_child_weight':[4,5,6,7]}\n",
    "gsearch2=GridSearchCV(XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=123,\n",
    " num_class = len(np.unique(y_train_encoded)),\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'multi:softprob',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27),param_grid=param_test1,cv=5,iid=False,scoring='f1_micro',n_jobs=-1)\n",
    "gridsearch.fit(X_train,y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7, 'min_child_weight': 5}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
