{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Goleo8/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:116: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 34.5388\n",
      "[2]\ttraining's binary_logloss: 34.5388\n",
      "[3]\ttraining's binary_logloss: 34.5388\n",
      "[4]\ttraining's binary_logloss: 34.5388\n",
      "[5]\ttraining's binary_logloss: 34.5388\n",
      "[6]\ttraining's binary_logloss: 34.5388\n",
      "[7]\ttraining's binary_logloss: 34.5388\n",
      "[8]\ttraining's binary_logloss: 34.5388\n",
      "[9]\ttraining's binary_logloss: 34.5388\n",
      "[10]\ttraining's binary_logloss: 34.5388\n",
      "[11]\ttraining's binary_logloss: 34.5388\n",
      "[12]\ttraining's binary_logloss: 34.5388\n",
      "[13]\ttraining's binary_logloss: 34.5388\n",
      "[14]\ttraining's binary_logloss: 34.5388\n",
      "[15]\ttraining's binary_logloss: 34.5388\n",
      "[16]\ttraining's binary_logloss: 34.5388\n",
      "[17]\ttraining's binary_logloss: 34.5388\n",
      "[18]\ttraining's binary_logloss: 34.5388\n",
      "[19]\ttraining's binary_logloss: 34.5388\n",
      "[20]\ttraining's binary_logloss: 34.5388\n",
      "[21]\ttraining's binary_logloss: 34.5388\n",
      "[22]\ttraining's binary_logloss: 34.5388\n",
      "[23]\ttraining's binary_logloss: 34.5388\n",
      "[24]\ttraining's binary_logloss: 34.5388\n",
      "[25]\ttraining's binary_logloss: 34.5388\n",
      "[26]\ttraining's binary_logloss: 34.5388\n",
      "[27]\ttraining's binary_logloss: 34.5388\n",
      "[28]\ttraining's binary_logloss: 34.5388\n",
      "[29]\ttraining's binary_logloss: 34.5388\n",
      "[30]\ttraining's binary_logloss: 34.5388\n",
      "[31]\ttraining's binary_logloss: 34.5388\n",
      "[32]\ttraining's binary_logloss: 34.5388\n",
      "[33]\ttraining's binary_logloss: 34.5388\n",
      "[34]\ttraining's binary_logloss: 34.5388\n",
      "[35]\ttraining's binary_logloss: 34.5388\n",
      "[36]\ttraining's binary_logloss: 34.5388\n",
      "[37]\ttraining's binary_logloss: 34.5388\n",
      "[38]\ttraining's binary_logloss: 34.5388\n",
      "[39]\ttraining's binary_logloss: 34.5388\n",
      "[40]\ttraining's binary_logloss: 34.5388\n",
      "[41]\ttraining's binary_logloss: 34.5388\n",
      "[42]\ttraining's binary_logloss: 34.5388\n",
      "[43]\ttraining's binary_logloss: 34.5388\n",
      "[44]\ttraining's binary_logloss: 34.5388\n",
      "[45]\ttraining's binary_logloss: 34.5388\n",
      "[46]\ttraining's binary_logloss: 34.5388\n",
      "[47]\ttraining's binary_logloss: 34.5388\n",
      "[48]\ttraining's binary_logloss: 34.5388\n",
      "[49]\ttraining's binary_logloss: 34.5388\n",
      "[50]\ttraining's binary_logloss: 34.5388\n",
      "[51]\ttraining's binary_logloss: 34.5388\n",
      "[52]\ttraining's binary_logloss: 34.5388\n",
      "[53]\ttraining's binary_logloss: 34.5388\n",
      "[54]\ttraining's binary_logloss: 34.5388\n",
      "[55]\ttraining's binary_logloss: 34.5388\n",
      "[56]\ttraining's binary_logloss: 34.5388\n",
      "[57]\ttraining's binary_logloss: 34.5388\n",
      "[58]\ttraining's binary_logloss: 34.5388\n",
      "[59]\ttraining's binary_logloss: 34.5388\n",
      "[60]\ttraining's binary_logloss: 34.5388\n",
      "[61]\ttraining's binary_logloss: 34.5388\n",
      "[62]\ttraining's binary_logloss: 34.5388\n",
      "[63]\ttraining's binary_logloss: 34.5388\n",
      "[64]\ttraining's binary_logloss: 34.5388\n",
      "[65]\ttraining's binary_logloss: 34.5388\n",
      "[66]\ttraining's binary_logloss: 34.5388\n",
      "[67]\ttraining's binary_logloss: 34.5388\n",
      "[68]\ttraining's binary_logloss: 34.5388\n",
      "[69]\ttraining's binary_logloss: 34.5388\n",
      "[70]\ttraining's binary_logloss: 34.5388\n",
      "[71]\ttraining's binary_logloss: 34.5388\n",
      "[72]\ttraining's binary_logloss: 34.5388\n",
      "[73]\ttraining's binary_logloss: 34.5388\n",
      "[74]\ttraining's binary_logloss: 34.5388\n",
      "[75]\ttraining's binary_logloss: 34.5388\n",
      "[76]\ttraining's binary_logloss: 34.5388\n",
      "[77]\ttraining's binary_logloss: 34.5388\n",
      "[78]\ttraining's binary_logloss: 34.5388\n",
      "[79]\ttraining's binary_logloss: 34.5388\n",
      "[80]\ttraining's binary_logloss: 34.5388\n",
      "[81]\ttraining's binary_logloss: 34.5388\n",
      "[82]\ttraining's binary_logloss: 34.5388\n",
      "[83]\ttraining's binary_logloss: 34.5388\n",
      "[84]\ttraining's binary_logloss: 34.5388\n",
      "[85]\ttraining's binary_logloss: 34.5388\n",
      "[86]\ttraining's binary_logloss: 34.5388\n",
      "[87]\ttraining's binary_logloss: 34.5388\n",
      "[88]\ttraining's binary_logloss: 34.5388\n",
      "[89]\ttraining's binary_logloss: 34.5388\n",
      "[90]\ttraining's binary_logloss: 34.5388\n",
      "[91]\ttraining's binary_logloss: 34.5388\n",
      "[92]\ttraining's binary_logloss: 34.5388\n",
      "[93]\ttraining's binary_logloss: 34.5388\n",
      "[94]\ttraining's binary_logloss: 34.5388\n",
      "[95]\ttraining's binary_logloss: 34.5388\n",
      "[96]\ttraining's binary_logloss: 34.5388\n",
      "[97]\ttraining's binary_logloss: 34.5388\n",
      "[98]\ttraining's binary_logloss: 34.5388\n",
      "[99]\ttraining's binary_logloss: 34.5388\n",
      "[100]\ttraining's binary_logloss: 34.5388\n",
      "Save model...\n",
      "Start predicting...\n",
      "y_pred [0 0 0 ... 0 0 0]\n",
      "(314581,)\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Writing transformed training data\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.int32' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-930864658c7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m                                        dtype=np.int64)  # N * num_tress * num_leafs\n\u001b[1;32m     64\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_leaf\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mtransformed_training_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.int32' has no len()"
     ]
    }
   ],
   "source": [
    "# print('Load data...')\n",
    "# df_train = pd.read_csv('data/train.csv')\n",
    "# df_test = pd.read_csv('data/test.csv')\n",
    "\n",
    "# NUMERIC_COLS = [\n",
    "#     \"ps_reg_01\", \"ps_reg_02\", \"ps_reg_03\",\n",
    "#     \"ps_car_12\", \"ps_car_13\", \"ps_car_14\", \"ps_car_15\",\n",
    "# ]\n",
    "\n",
    "# print(df_test.head(10))\n",
    "\n",
    "data = load_svmlight_file('data/train.txt')\n",
    "\n",
    "X,y=data[0],data[1]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.3,random_state=42)\n",
    "\n",
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 64,\n",
    "    'num_trees': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# number of leaves,will be used in feature transformation\n",
    "num_leaf = 64\n",
    "\n",
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=100,\n",
    "                valid_sets=lgb_train)\n",
    "\n",
    "print('Save model...')\n",
    "# save model to file\n",
    "gbm.save_model('model.txt')\n",
    "\n",
    "print('Start predicting...')\n",
    "# predict and get data on leaves, training data\n",
    "y_pred = gbm.predict(X_train, pred_leaf=True)\n",
    "print(\"y_pred\",y_pred)\n",
    "\n",
    "print(np.array(y_pred).shape)\n",
    "print(y_pred[:10])\n",
    "\n",
    "print('Writing transformed training data')\n",
    "# transformed_training_matrix = np.zeros([len(y_pred), len(y_pred[0]) * num_leaf],\n",
    "#                                        dtype=np.int64)  # N * num_tress * num_leafs\n",
    "\n",
    "transformed_training_matrix = np.zeros([len(y_pred), num_leaf],\n",
    "                                       dtype=np.int64)  # N * num_tress * num_leafs\n",
    "for i in range(0, len(y_pred)):\n",
    "    temp = np.arange(len(y_pred[0])) * num_leaf + np.array(y_pred[i])\n",
    "    transformed_training_matrix[i][temp] += 1\n",
    "\n",
    "\n",
    "y_pred = gbm.predict(X_test, pred_leaf=True)\n",
    "print('Writing transformed testing data')\n",
    "transformed_testing_matrix = np.zeros([len(y_pred), len(y_pred[0]) * num_leaf], dtype=np.int64)\n",
    "for i in range(0, len(y_pred)):\n",
    "    temp = np.arange(len(y_pred[0])) * num_leaf + np.array(y_pred[i])\n",
    "    transformed_testing_matrix[i][temp] += 1\n",
    "\n",
    "\n",
    "lm = LogisticRegression(penalty='l2',C=0.05) # logestic model construction\n",
    "lm.fit(transformed_training_matrix,y_train)  # fitting the data\n",
    "y_pred_test = lm.predict_proba(transformed_testing_matrix)   # Give the probabilty on each label\n",
    "\n",
    "print(y_pred_test)\n",
    "\n",
    "NE = (-1) / len(y_pred_test) * sum(((1+y_test)/2 * np.log(y_pred_test[:,1]) +  (1-y_test)/2 * np.log(1 - y_pred_test[:,1])))\n",
    "print(\"Normalized Cross Entropy \" + str(NE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314581,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
