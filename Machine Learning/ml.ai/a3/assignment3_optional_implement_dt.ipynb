{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\" />\n",
    "    \n",
    "## [mlcourse.ai](mlcourse.ai) â€“ Open Machine Learning Course \n",
    "Author: [Yury Kashnitskiy](https://yorko.github.io) (@yorko). Edited by Anna Tarelina (@feuerengel). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Assignment #3. Optional part\n",
    "## <center> Implementation of the decision tree algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.datasets import make_classification, make_regression, load_digits, load_boston\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix `random_state` (a.k.a. random seed) beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Implement the class `DecisionTree`**\n",
    "**Specification:**\n",
    "- the class is inherited from `sklearn.BaseEstimator`;\n",
    "- class constructor has the following parameters: \n",
    "    `max_depth` - maximum depth of the tree (`numpy.inf` by default); \n",
    "    `min_samples_split` - the minimum number of instances in a node for a splitting to be done (2 by default); \n",
    "    `criterion` - split criterion ('gini' or 'entropy' for classification, 'variance' or 'mad_median' for regression; 'gini' by default);\n",
    "    \n",
    "    A functional to be maximized to find an optimal partition at a given node has the form\n",
    "    $$Q(X, j, t) = F(X) - \\dfrac{|X_l|}{|X|} F(X_l) - \\dfrac{|X_r|}{|X|} F(X_r),$$\n",
    "    where $X$ are samples at a given node, $X_l$ and $X_r$ are partitions of samples $X$ into two parts \n",
    "    with the following condition $[x_j < t]$, and $F(X)$ is a partition criterion.\n",
    "    \n",
    "    For classification: let $p_i$ be the fraction of the instances of the $i$-th class in the dataset $X$.\n",
    "    \n",
    "    'gini': Gini impurity $F(X) = 1 -\\sum_{i = 1}^K p_i^2$.\n",
    "    \n",
    "    'entropy': Entropy $F(X) = -\\sum_{i = 1}^K p_i \\log_2(p_i)$.\n",
    "    \n",
    "    For regression: $y_j = y(x_j)$ - is a target for an instance $x_j$, $y = (y_1, \\dots, y_{|X|})$ - is a target vector.\n",
    "    \n",
    "    'variance': Variance (mean quadratic deviation from average) $F(X) = \\dfrac{1}{|X|} \\sum_{x_j \\in X}(y_j - \\dfrac{1}{|X|}\\sum_{x_i \\in X}y_i)^2$\n",
    "    \n",
    "    'mad_median': Mean deviation from the median $F(X) = \\dfrac{1}{|X|} \\sum_{x_j \\in X}|y_j - \\mathrm{med}(y)|$\n",
    "    \n",
    "- the class has several methods: `fit`, `predict` and `predict_proba`;\n",
    "- the`fit` method takes the matrix of instances `X` and a target vector `y` (`numpy.ndarray` objects) and returns an instance of the class `DecisionTree` representing the decision tree trained on the dataset `(X, y)` according to parameters set in the constructor; \n",
    "- the `predict_proba` method takes the matrix of instances `X` and returns the matrix `P` of a size `X.shape[0] x K`, where `K` is the number of classes and $p_{ij}$ is the probability of an instance in $i$-th row of `X` to belong to class $j \\in \\{1, \\dots, K\\}$.\n",
    "- the `predict` method takes the matrix of instances `X` and returns a prediction vector; in case of classification, prediction for an instance $x_i$ falling into leaf $L$ will be the class, mostly represented among instances in $L$. In case of regression, it'll be the mean value of targets for all instances in leaf $L$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(y):    \n",
    "    classes, counts=np.unique(y,return_counts=True)\n",
    "    prob=counts/counts.sum()\n",
    "    return -np.sum(prob*np.log(prob))\n",
    "\n",
    "def gini(y):\n",
    "    classes, counts=np.unique(y,return_counts=True)\n",
    "    prob=counts/counts.sum()\n",
    "    return 1-np.sum(prob*prob)\n",
    "\n",
    "def variance(y):\n",
    "    return np.var(y)\n",
    "\n",
    "def mad_median(y):\n",
    "    return np.sum(np.abs(y-np.mean(y)))/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.asarray([1,1,2,2,3,3])\n",
    "# print(y.var())\n",
    "mad_median(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Node` class implements a node in the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node():\n",
    "    \n",
    "    def __init__(self, feature_idx=0, threshold=0, labels=None, left=None, right=None):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.threshold = threshold\n",
    "        self.labels = labels\n",
    "        self.left = left\n",
    "        self.right = right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's determine the function for calculating a prediction in a leaf. For regression, let's take the mean for all values in a leaf, for classification - the most popular class in leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecisionTree(BaseEstimator):\n",
    "    criterion_dict={'gini':gini,'entropy':entropy,'variance':variance,'mad_median':mad_median}\n",
    "    \n",
    "    def __init__(self, max_depth=np.inf, min_samples_split=2, \n",
    "                 criterion='gini', debug=False):\n",
    "        self.max_depth=max_depth\n",
    "        self.min_samples_split=min_samples_split\n",
    "        self.criterion=criterion\n",
    "    \n",
    "    def __split(self,X,y):\n",
    "        if len(y)<=self.min_samples_split or len(np.unique(y))==1:\n",
    "            return Node(labels=y)\n",
    "        crit=self.criterion_dict[self.criterion]\n",
    "        raw_gain=0\n",
    "        raw_index=None\n",
    "        raw_value=None\n",
    "        tmp_X_left=None\n",
    "        tmp_X_right=None\n",
    "        tmp_y_left=None\n",
    "        tmp_y_right=None\n",
    "        for index_id,i in enumerate(X.T):\n",
    "            u=np.unique(i)\n",
    "            if u[0].dtype=='O':\n",
    "                sign=lambda x,y:x==y\n",
    "            else:\n",
    "                sign=lambda x,y:x<=y\n",
    "            raw=crit(y)\n",
    "            for j in u:\n",
    "                index = sign(i,j)\n",
    "                X_left,y_left = X[index],y[index]\n",
    "                X_right,y_right = X[~index],y[~index]\n",
    "                new=len(y_left)/len(y)*crit(y_left)+len(y_right)/len(y)*crit(y_right)\n",
    "                gain=raw-new\n",
    "                if(gain>raw_gain):\n",
    "                    raw_gain=gain\n",
    "                    raw_index=index_id\n",
    "                    raw_value=j\n",
    "                    tmp_X_left=X_left\n",
    "                    tmp_X_right=X_right\n",
    "                    tmp_y_left=y_left\n",
    "                    tmp_y_right=y_right\n",
    "        left_node=self.__split(tmp_X_left,tmp_y_left)\n",
    "        right_node = self.__split(tmp_X_right,tmp_y_right)\n",
    "        return Node(feature_idx=raw_index,threshold=raw_value,left=left_node,right=right_node)\n",
    "    def fit(self, X, y):\n",
    "        self.root=self.__split(X,y)\n",
    "        return self\n",
    "    \n",
    "    def __get_labels(self,X):\n",
    "        l=[]\n",
    "        for i in X:\n",
    "            node = self.root\n",
    "            while node.labels is None:\n",
    "                index=node.feature_idx\n",
    "                if i[index].dtype=='O':\n",
    "                    sign=lambda x,y:x==y\n",
    "                else:\n",
    "                    sign=lambda x,y:x<=y\n",
    "                if sign(i[index],node.threshold):\n",
    "                    node=node.left\n",
    "                else:\n",
    "                    node=node.right\n",
    "            else:\n",
    "                l.append(node.labels)\n",
    "        return l\n",
    "    def predict(self, X):\n",
    "        l=self.__get_labels(X)\n",
    "        tmp=[]\n",
    "        for i in l:\n",
    "            uniq,counts=np.unique(i,return_counts=True)\n",
    "            result = uniq[np.argmax(counts)] if self.criterion in ('gini','entropy') else np.mean(i)\n",
    "            tmp.append()\n",
    "        return tmp\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        l=self.__get_labels(X)\n",
    "        tmp=[]\n",
    "        for i in l:\n",
    "            uniq,counts=np.unique(i,return_counts=True)\n",
    "            tmp.append(np.max(counts)/np.sum(counts))\n",
    "        return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the implemented algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset `digits` using the method `load_digits`. Split the data into train and test with the `train_test_split` method, use parameter values `test_size=0.2`, and `random_state=17`. Try to train shallow decision trees and make sure that gini and entropy criteria return different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits=load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=np.arange(10).reshape(-1,1)\n",
    "y=np.where(X>5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_idx: 0\n",
      "threshold: 5\n",
      "labels: None\n",
      "feature_idx: 0\n",
      "threshold: 0\n",
      "labels: [[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "feature_idx: 0\n",
      "threshold: 0\n",
      "labels: [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "tmp_node = tree.root\n",
    "\n",
    "def print_node(tmp_node):\n",
    "    if tmp_node is None:\n",
    "        return\n",
    "    print(\"feature_idx:\",tmp_node.feature_idx)\n",
    "    print(\"threshold:\",tmp_node.threshold)\n",
    "    print(\"labels:\",tmp_node.labels)\n",
    "    print_node(tmp_node.left)\n",
    "    print_node(tmp_node.right)\n",
    "print_node(tmp_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTree(criterion='gini', debug=None, max_depth=inf, min_samples_split=2)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree=DecisionTree()\n",
    "tree.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "y_pred=tree.predict(X)\n",
    "print(y_pred)\n",
    "print(precision_score(y,y_pred,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTree(criterion='gini', debug=None, max_depth=inf, min_samples_split=2)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y=digits['data'],digits['target']\n",
    "tree=DecisionTree()\n",
    "tree.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9906685394426482\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "y_pred=tree.predict(X)\n",
    "print(precision_score(y,y_pred,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8262238779425009\n"
     ]
    }
   ],
   "source": [
    "tree_gini=DecisionTree(criterion='gini')\n",
    "tree_gini.fit(X_train,y_train)\n",
    "from sklearn.metrics import precision_score\n",
    "y_test_pred=tree_gini.predict(X_test)\n",
    "print(precision_score(y_test,y_test_pred,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8870943391896118\n"
     ]
    }
   ],
   "source": [
    "tree_entro=DecisionTree(criterion='entropy')\n",
    "tree_entro.fit(X_train,y_train)\n",
    "from sklearn.metrics import precision_score\n",
    "y_test_pred_entro=tree_entro.predict(X_test)\n",
    "print(precision_score(y_test,y_test_pred_entro,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8346398252844527\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtD = DecisionTreeClassifier(min_samples_split=2)\n",
    "dtD.fit(X_train,y_train)\n",
    "y_test_pred_sk=dtD.predict(X_test)\n",
    "print(precision_score(y_test,y_test_pred_sk,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydotplus'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-c36ec85e88dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mipywidgets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdot_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydotplus'"
     ]
    }
   ],
   "source": [
    "from ipywidgets import Image\n",
    "import pydotplus\n",
    "from sklearn.tree import export_graphviz\n",
    "from io import StringIO\n",
    "dot_data=StringIO()\n",
    "export_graphviz(dtD,feature_names=['x{}'.format(i) for i in range(X.shape[1])],out_file=dot_data)\n",
    "graph=pydotplus.graph_from_dot_data(dot_data)\n",
    "Image(value=graph.create_pnd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 5-folds cross-validation (`GridSearchCV`) pick up the optimal values of the `max_depth` and `criterion` parameters. For the parameter `max_depth` use range(3, 11), for criterion use {'gini', 'entropy'}. Quality measure is `scoring`='accuracy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=DecisionTree(criterion='gini', debug=None, max_depth=inf, min_samples_split=2),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'max_depth': [3, 4, 5, 6, 7, 8, 9, 10], 'criterion': ['gini', 'entropy']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid=[{'max_depth':[i for i in range(3,11)],'criterion':['gini', 'entropy']}]\n",
    "tree=DecisionTree()\n",
    "gCV=GridSearchCV(tree,param_grid=param_grid,cv=5,scoring='accuracy')\n",
    "gCV.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8870943391896118\n"
     ]
    }
   ],
   "source": [
    "y_test_best_predict=gCV.best_estimator_.predict(X_test)\n",
    "print(precision_score(y_test,y_test_best_predict,average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the plot of the mean quality measure `accuracy` for criteria `gini` and `entropy` depending on `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'criterion': 'gini', 'max_depth': 3}, 0.8322894919972165), ({'criterion': 'gini', 'max_depth': 4}, 0.8322894919972165), ({'criterion': 'gini', 'max_depth': 5}, 0.8322894919972165), ({'criterion': 'gini', 'max_depth': 6}, 0.8322894919972165), ({'criterion': 'gini', 'max_depth': 7}, 0.8322894919972165), ({'criterion': 'gini', 'max_depth': 8}, 0.8322894919972165), ({'criterion': 'gini', 'max_depth': 9}, 0.8322894919972165), ({'criterion': 'gini', 'max_depth': 10}, 0.8322894919972165)]\n",
      "[({'criterion': 'entropy', 'max_depth': 3}, 0.8643006263048016), ({'criterion': 'entropy', 'max_depth': 4}, 0.8643006263048016), ({'criterion': 'entropy', 'max_depth': 5}, 0.8643006263048016), ({'criterion': 'entropy', 'max_depth': 6}, 0.8643006263048016), ({'criterion': 'entropy', 'max_depth': 7}, 0.8643006263048016), ({'criterion': 'entropy', 'max_depth': 8}, 0.8643006263048016), ({'criterion': 'entropy', 'max_depth': 9}, 0.8643006263048016), ({'criterion': 'entropy', 'max_depth': 10}, 0.8643006263048016)]\n"
     ]
    }
   ],
   "source": [
    "l=list(zip(gCV.cv_results_['params'],gCV.cv_results_['mean_test_score']))\n",
    "gini_l=l[:8]\n",
    "entro_l=l[8:]\n",
    "print(gini_l)\n",
    "print(entro_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83228949, 0.83228949, 0.83228949, 0.83228949, 0.83228949,\n",
       "       0.83228949, 0.83228949, 0.83228949, 0.86430063, 0.86430063,\n",
       "       0.86430063, 0.86430063, 0.86430063, 0.86430063, 0.86430063,\n",
       "       0.86430063])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gCV.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x111e1d8d0>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i[0]['max_depth'] for i in gini_l],[i[1] for i in gini_l],label='gini')\n",
    "plt.plot([i[0]['max_depth'] for i in entro_l],[i[1] for i in entro_l],label='entro')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Choose all correct statements:**\n",
    "1. Optimal value of the `max_depth` parameter is on the interval [4, 9] for both criteria.\n",
    "2. Created plots have no intersection on the interval [3, 10]\n",
    "3. Created plots intersect each other only once on the interval [3, 10].\n",
    "4. The best quality for `max_depth` on the interval [3, 10] is reached using `gini` criterion .\n",
    "5. Accuracy is strictly increasing at least for one of the criteria, when `max_depth` is also increasing on the interval [3, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. What are the optimal values for max_depth and criterion parameters?**\n",
    "1. max_depth = 7, criterion = 'gini';\n",
    "2. max_depth = 7, criterion = 'entropy';\n",
    "3. max_depth = 10, criterion = 'entropy';\n",
    "4. max_depth = 10, criterion = 'gini';\n",
    "5. max_depth = 9, criterion = 'entropy';\n",
    "6. max_depth = 9, criterion = 'gini';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train decision tree on `(X_train, y_train)` using the optimal values of `max_depth` and `criterion`. Compute class probabilities for `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the given matrix, compute the mean class probabilities for all instances in `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. What is the maximum probability in a resulted vector?**\n",
    "1. 0.127\n",
    "2. 0.118\n",
    "3. 1.0\n",
    "4. 0.09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset `boston` using the method `load_boston`. Split the data into train and test with the `train_test_split` method, use parameter values `test_size=0.2`, `random_state=17`. Try to train shallow regression decision trees and make sure that `variance` and `mad_median` criteria return different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston=load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X,y=boston['data'],boston['target']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3194: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n",
      "/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/core/_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "append() takes exactly one argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-d16ec41f4982>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtree_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my_test_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtree_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-136-c5583e24d7ca>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0muniq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muniq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'gini'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'entropy'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: append() takes exactly one argument (0 given)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "tree_var=DecisionTree(criterion='variance')\n",
    "tree_var.fit(X_train,y_train)\n",
    "from sklearn.metrics import precision_score\n",
    "y_test_pred=tree_var.predict(X_test)\n",
    "print(mean_absolute_error(y_test,y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 5-folds cross-validation (`GridSearchCV`) pick up the optimal values of the `max_depth` and `criterion` parameters. For the parameter `max_depth` use `range(2, 9)`, for `criterion` use {'variance', 'mad_median'}. Quality measure is `scoring`='neg_mean_squared_error'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the plot of the mean quality measure `neg_mean_squared_error` for criteria `variance` and `mad_median` depending on `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Choose all correct statements:**\n",
    "1. Created plots have no intersection on the interval [2, 8].\n",
    "2. Created plots intersect each other only once on the interval [2, 8].\n",
    "3. Optimal value of the `max_depth` for each of the criteria is on the border of the interval [2, 8].\n",
    "4. The best quality at `max_depth` on the interval [2, 8] is reached using `mad_median` criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. What are the optimal values for `max_depth` and `criterion` parameters?**\n",
    "1. max_depth = 9, criterion = 'variance';\n",
    "2. max_depth = 5, criterion = 'mad_median';\n",
    "3. max_depth = 4, criterion = 'variance';\n",
    "4. max_depth = 2, criterion = 'mad_median';\n",
    "5. max_depth = 4, criterion = 'mad_median';\n",
    "6. max_depth = 5, criterion = 'variance'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "name": "lesson4_part2_Decision_trees.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
