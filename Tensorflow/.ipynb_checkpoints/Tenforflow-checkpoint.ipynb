{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [TensorFlow-Examples](https://github.com/aymericdamien/TensorFlow-Examples.git)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.Variable(3,name='X')\n",
    "y=tf.Variable(4,name='Y')\n",
    "f=x*x*y+y+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result=f.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = fetch_california_housing()\n",
    "housing.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=housing.data,housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_s=np.c_[np.ones((X.shape[0],1)),scaler.fit_transform(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfX=tf.constant(X_s,dtype=tf.float64,name='X')\n",
    "tfY=tf.constant(y.reshape(-1,1),dtype=tf.float64,name='y')\n",
    "tfXT=tf.transpose(tfX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(tfXT,tfX)),tfXT),tfY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.06855817]\n",
      " [ 0.8296193 ]\n",
      " [ 0.11875165]\n",
      " [-0.26552688]\n",
      " [ 0.30569623]\n",
      " [-0.004503  ]\n",
      " [-0.03932627]\n",
      " [-0.89988565]\n",
      " [-0.870541  ]]\n"
     ]
    }
   ],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = w.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,MSE:5.855115\n",
      "Epoch:10,MSE:1.290942\n",
      "Epoch:20,MSE:0.719839\n",
      "Epoch:30,MSE:0.634301\n",
      "Epoch:40,MSE:0.610942\n",
      "Epoch:50,MSE:0.597323\n",
      "Epoch:60,MSE:0.586557\n",
      "Epoch:70,MSE:0.577502\n",
      "Epoch:80,MSE:0.569802\n",
      "Epoch:90,MSE:0.563240\n",
      "[[ 2.06850195]\n",
      " [ 0.80083104]\n",
      " [ 0.1804282 ]\n",
      " [-0.08538963]\n",
      " [ 0.10130749]\n",
      " [ 0.0181515 ]\n",
      " [-0.04389049]\n",
      " [-0.47535519]\n",
      " [-0.43656156]]\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.1\n",
    "tfX=tf.constant(X_s,dtype=tf.float64,name='X')\n",
    "tfY=tf.constant(y.reshape(-1,1),dtype=tf.float64,name='y')\n",
    "w=tf.Variable(tf.random_uniform([X_s.shape[1],1],minval=-0.1,maxval=0.1,dtype=tf.float64),name='w')\n",
    "f=tf.matmul(tfX,w,name='f')\n",
    "error = f-tfY\n",
    "mse = tf.reduce_mean(tf.square(error))\n",
    "grad = tf.matmul(tfXT,error)/X_s.shape[0]*learning_rate\n",
    "training=tf.assign(w,w-grad)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for i in range(100):\n",
    "        if i%10==0:\n",
    "            mse_result = mse.eval()\n",
    "            print('Epoch:%d,MSE:%f'%(i,mse_result))\n",
    "        sess.run(training)\n",
    "    result=w.eval()\n",
    "print(result)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]), TensorShape([Dimension(9), Dimension(1)]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse.shape,w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.grandients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,MSE:5.716550\n",
      "Epoch:10,MSE:0.679934\n",
      "Epoch:20,MSE:0.596443\n",
      "Epoch:30,MSE:0.576620\n",
      "Epoch:40,MSE:0.562718\n",
      "Epoch:50,MSE:0.552594\n",
      "Epoch:60,MSE:0.545202\n",
      "Epoch:70,MSE:0.539793\n",
      "Epoch:80,MSE:0.535826\n",
      "Epoch:90,MSE:0.532909\n",
      "[[ 2.06855817]\n",
      " [ 0.83914167]\n",
      " [ 0.14701503]\n",
      " [-0.2339941 ]\n",
      " [ 0.25784193]\n",
      " [ 0.00565514]\n",
      " [-0.04192016]\n",
      " [-0.68491155]\n",
      " [-0.65427939]]\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.1\n",
    "tfX=tf.constant(X_s,dtype=tf.float64,name='X')\n",
    "tfY=tf.constant(y.reshape(-1,1),dtype=tf.float64,name='y')\n",
    "w=tf.Variable(tf.random_uniform([X_s.shape[1],1],minval=-0.1,maxval=0.1,dtype=tf.float64),name='w')\n",
    "f=tf.matmul(tfX,w,name='f')\n",
    "error = f-tfY\n",
    "mse = tf.reduce_mean(tf.square(error))\n",
    "grad = tf.gradients(mse,[w],name='grad')[0]*learning_rate\n",
    "training=tf.assign(w,w-grad)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for i in range(100):\n",
    "        if i%10==0:\n",
    "            mse_result = mse.eval()\n",
    "            print('Epoch:%d,MSE:%f'%(i,mse_result))\n",
    "        sess.run(training)\n",
    "    result=w.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.train.GradientDescentOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,MSE:5.209789\n",
      "Epoch:10,MSE:0.686836\n",
      "Epoch:20,MSE:0.604870\n",
      "Epoch:30,MSE:0.582892\n",
      "Epoch:40,MSE:0.567412\n",
      "Epoch:50,MSE:0.556125\n",
      "Epoch:60,MSE:0.547871\n",
      "Epoch:70,MSE:0.541820\n",
      "Epoch:80,MSE:0.537373\n",
      "Epoch:90,MSE:0.534096\n",
      "[[ 2.06855817]\n",
      " [ 0.84273668]\n",
      " [ 0.14899907]\n",
      " [-0.23833605]\n",
      " [ 0.26035477]\n",
      " [ 0.00633022]\n",
      " [-0.04216464]\n",
      " [-0.66707234]\n",
      " [-0.63674006]]\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.1\n",
    "tfX=tf.constant(X_s,dtype=tf.float64,name='X')\n",
    "tfY=tf.constant(y.reshape(-1,1),dtype=tf.float64,name='y')\n",
    "w=tf.Variable(tf.random_uniform([X_s.shape[1],1],minval=-0.1,maxval=0.1,dtype=tf.float64),name='w')\n",
    "f=tf.matmul(tfX,w,name='f')\n",
    "error = f-tfY\n",
    "mse = tf.reduce_mean(tf.square(error))\n",
    "# grad = tf.gradients(mse,[w],name='grad')[0]*learning_rate\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training=optimizer.minimize(mse)\n",
    "# training=tf.assign(w,w-grad)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(100):\n",
    "        if i%10==0:\n",
    "            mse_result = mse.eval()\n",
    "            print('Epoch:%d,MSE:%f'%(i,mse_result))\n",
    "        sess.run(training)\n",
    "    result=w.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum and model load/save\n",
    "\n",
    "```tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=1)```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,MSE:5.386290\n",
      "Epoch:10,MSE:0.731156\n",
      "Epoch:20,MSE:0.601558\n",
      "Epoch:30,MSE:0.583461\n",
      "Epoch:40,MSE:0.570233\n",
      "Epoch:50,MSE:0.560031\n",
      "Epoch:60,MSE:0.552143\n",
      "Epoch:70,MSE:0.546036\n",
      "Epoch:80,MSE:0.541303\n",
      "Epoch:90,MSE:0.537629\n",
      "Epoch:100,MSE:0.534774\n",
      "Epoch:110,MSE:0.532551\n",
      "Epoch:120,MSE:0.530818\n",
      "Epoch:130,MSE:0.529464\n",
      "Epoch:140,MSE:0.528403\n",
      "Epoch:150,MSE:0.527572\n",
      "Epoch:160,MSE:0.526918\n",
      "Epoch:170,MSE:0.526402\n",
      "Epoch:180,MSE:0.525994\n",
      "Epoch:190,MSE:0.525671\n",
      "Epoch:200,MSE:0.525414\n",
      "Epoch:210,MSE:0.525209\n",
      "Epoch:220,MSE:0.525045\n",
      "Epoch:230,MSE:0.524914\n",
      "Epoch:240,MSE:0.524808\n",
      "Epoch:250,MSE:0.524722\n",
      "Epoch:260,MSE:0.524653\n",
      "Epoch:270,MSE:0.524596\n",
      "Epoch:280,MSE:0.524550\n",
      "Epoch:290,MSE:0.524512\n",
      "[[ 2.06855817]\n",
      " [ 0.83833158]\n",
      " [ 0.12283828]\n",
      " [-0.27739909]\n",
      " [ 0.31349571]\n",
      " [-0.00312943]\n",
      " [-0.03985773]\n",
      " [-0.86191417]\n",
      " [-0.83336156]]\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.04\n",
    "tfX=tf.constant(X_s,dtype=tf.float64,name='X')\n",
    "tfY=tf.constant(y.reshape(-1,1),dtype=tf.float64,name='y')\n",
    "w=tf.Variable(tf.random_uniform([X_s.shape[1],1],minval=-0.1,maxval=0.1,dtype=tf.float64),name='w')\n",
    "f=tf.matmul(tfX,w,name='f')\n",
    "error = f-tfY\n",
    "mse = tf.reduce_mean(tf.square(error))\n",
    "# grad = tf.gradients(mse,[w],name='grad')[0]*learning_rate\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=0.5)\n",
    "training=optimizer.minimize(mse)\n",
    "# training=tf.assign(w,w-grad)\n",
    "saver = tf.train.Saver()\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(300):\n",
    "        if i%10==0:\n",
    "            mse_result = mse.eval()\n",
    "            print('Epoch:%d,MSE:%f'%(i,mse_result))\n",
    "        sess.run(training)\n",
    "    result=w.eval()\n",
    "    saver.save(sess,\"data/moment.ckpt\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from data/moment.ckpt\n",
      "0.5244779040814854\n"
     ]
    }
   ],
   "source": [
    "loader = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    loader.restore(sess,'data/moment.ckpt')\n",
    "    sess.run(training)\n",
    "    print(mse.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholder\n",
    "\n",
    "```\n",
    "Y.eval(feed_dict={X:[[3,4,8],[8,16,2]]}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12 19 67]]\n",
      "[[ 12  19  67]\n",
      " [ 67 259   7]]\n"
     ]
    }
   ],
   "source": [
    "X=tf.placeholder(dtype=tf.int64,shape=(None,3),name='X')\n",
    "Y=X**2+tf.constant(3,dtype=tf.int64)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(Y.eval(feed_dict={X:[[3,4,8]]}))\n",
    "    print(Y.eval(feed_dict={X:[[3,4,8],[8,16,2]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:0,mse:6.193033\n",
      "index:100,mse:0.825462\n",
      "index:200,mse:1.143001\n",
      "index:300,mse:0.664882\n",
      "index:0,mse:0.740295\n",
      "index:100,mse:0.998736\n",
      "index:200,mse:0.485561\n",
      "index:300,mse:0.719115\n",
      "index:0,mse:0.617747\n",
      "index:100,mse:0.797923\n",
      "index:200,mse:0.427705\n",
      "index:300,mse:0.333508\n",
      "index:0,mse:0.348535\n",
      "index:100,mse:0.399791\n",
      "index:200,mse:0.426439\n",
      "index:300,mse:0.460142\n",
      "index:0,mse:0.464382\n",
      "index:100,mse:0.504077\n",
      "index:200,mse:0.445148\n",
      "index:300,mse:0.455720\n",
      "[[ 2.05346611]\n",
      " [ 0.87373668]\n",
      " [ 0.17409543]\n",
      " [-0.40950716]\n",
      " [ 0.40836091]\n",
      " [ 0.02019256]\n",
      " [-0.1455336 ]\n",
      " [-0.6505009 ]\n",
      " [-0.55374577]]\n"
     ]
    }
   ],
   "source": [
    "tfX=tf.placeholder(dtype=tf.float64,shape=(None,X_s.shape[1]))\n",
    "tfy=tf.placeholder(dtype=tf.float64,shape=(None,1))\n",
    "\n",
    "def fetch_data(data,label,index,length):\n",
    "    end = data.shape[0] if index+length>data.shape[0] else index+length\n",
    "    return (data[index:end,:],label[index:end,:])\n",
    "learning_rate=0.001\n",
    "momentum=0.9\n",
    "w=tf.Variable(tf.random_uniform([X_s.shape[1],1],dtype=tf.float64),name='w')\n",
    "error=tf.matmul(tfX,w)-tfy\n",
    "mse=tf.reduce_mean(tf.square(error))\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=momentum)\n",
    "training = optimizer.minimize(mse)\n",
    "epoch = 5\n",
    "loop=int(np.ceil(X_s.shape[0]/batch))\n",
    "batch_size=64\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for e in range(epoch):\n",
    "        tmp_index = np.random.permutation(np.arange(X_s.shape[0]))\n",
    "        tmp_X=X_s[tmp_index]\n",
    "        tmp_y=y[tmp_index].reshape(-1,1)\n",
    "        index = 0\n",
    "        for index in range(loop):\n",
    "            X1,y1=fetch_data(tmp_X,tmp_y,index,batch_size)\n",
    "\n",
    "            sess.run(training,feed_dict={tfX:X1,tfy:y1})\n",
    "            result = mse.eval(feed_dict={tfX:X1,tfy:y1})\n",
    "            if index % 100==0:\n",
    "                print('index:%d,mse:%f'%(index,result))\n",
    "            index+=batch_size\n",
    "    res=w.eval()\n",
    "    print(res)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,i:0,MSE:7.580889\n",
      "Epoch:0,i:100,MSE:0.889810\n",
      "Epoch:0,i:200,MSE:0.532188\n",
      "Epoch:0,i:300,MSE:0.415425\n",
      "Epoch:1,i:0,MSE:0.740444\n",
      "Epoch:1,i:100,MSE:0.825939\n",
      "Epoch:1,i:200,MSE:0.514026\n",
      "Epoch:1,i:300,MSE:0.315791\n",
      "Epoch:2,i:0,MSE:0.432092\n",
      "Epoch:2,i:100,MSE:0.477250\n",
      "Epoch:2,i:200,MSE:0.329317\n",
      "Epoch:2,i:300,MSE:0.777959\n",
      "Epoch:3,i:0,MSE:0.498997\n",
      "Epoch:3,i:100,MSE:0.503145\n",
      "Epoch:3,i:200,MSE:0.379669\n",
      "Epoch:3,i:300,MSE:0.441188\n",
      "Epoch:4,i:0,MSE:0.313797\n",
      "Epoch:4,i:100,MSE:0.470612\n",
      "Epoch:4,i:200,MSE:0.540176\n",
      "Epoch:4,i:300,MSE:0.463425\n",
      "[[ 2.0653908e+00]\n",
      " [ 8.3301979e-01]\n",
      " [ 1.2470519e-01]\n",
      " [-2.1489646e-01]\n",
      " [ 2.8438878e-01]\n",
      " [-1.8046575e-03]\n",
      " [-5.4344814e-02]\n",
      " [-8.4978980e-01]\n",
      " [-8.1136680e-01]]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now=datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir=\"tf_logs\"\n",
    "logdir=\"{}/run-{}\".format(root_logdir,now)\n",
    "\n",
    "batch=64\n",
    "epoch = 5\n",
    "loop=int(np.ceil(X_s.shape[0]/batch))\n",
    "learning_rate=0.01\n",
    "momentum=0.1\n",
    "\n",
    "tf.reset_default_graph()\n",
    "def fetch_data(index,delta,X,y):\n",
    "    start=index\n",
    "    end=np.min([start+delta,X.shape[0]-1])\n",
    "    return (X[start:end,:],y[start:end,:])\n",
    "\n",
    "tfX=tf.placeholder(tf.float32,shape=(None,X_s.shape[1]),name='X')\n",
    "tfY=tf.placeholder(tf.float32,shape=(None,1),name='y')\n",
    "tfTheta=tf.Variable(tf.random_uniform([X_s.shape[1],1],-1.0,1.0),name='theta')\n",
    "y_pred=tf.matmul(tfX,tfTheta,name='prediction')\n",
    "\n",
    "error=y_pred-tfY\n",
    "mse=tf.reduce_mean(tf.square(error),name='mse')\n",
    "\n",
    "\n",
    "optimizer=tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=momentum)\n",
    "training_obj=optimizer.minimize(mse)\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "mse_summary=tf.summary.scalar('MSE',mse)\n",
    "file_writer=tf.summary.FileWriter(logdir,tf.get_default_graph())\n",
    "\n",
    "\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for e in range(epoch):\n",
    "        tmp_index = np.random.permutation(np.arange(X_s.shape[0]))\n",
    "        tmp_X=X_s[tmp_index]\n",
    "        tmp_y=y[tmp_index].reshape(-1,1)\n",
    "        index = 0\n",
    "        for i in range(loop):\n",
    "            X_batch,y_batch=fetch_data(index,batch,tmp_X,tmp_y)\n",
    "            sess.run(training_obj,feed_dict={tfX:X_batch,tfY:y_batch})\n",
    "            if i%100==0:\n",
    "                mse_result=mse.eval(feed_dict={tfX:X_batch,tfY:y_batch})\n",
    "                print('Epoch:%d,i:%d,MSE:%f'%(e,i,mse_result))\n",
    "                saver.save(sess,'models/lm.ckpt')\n",
    "                summary_str=mse_summary.eval({tfX:X_batch,tfY:y_batch})\n",
    "                file_writer.add_summary(summary_str,i)\n",
    "            index+=batch\n",
    "    result=tfTheta.eval()\n",
    "    saver.save(sess,'models/lm_final.ckpt')\n",
    "    print(result)\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,i:0,MSE:3.948535\n",
      "Epoch:0,i:100,MSE:0.322487\n",
      "Epoch:0,i:200,MSE:0.791210\n",
      "Epoch:0,i:300,MSE:0.390781\n",
      "Epoch:1,i:0,MSE:0.477199\n",
      "Epoch:1,i:100,MSE:0.611855\n",
      "Epoch:1,i:200,MSE:0.488207\n",
      "Epoch:1,i:300,MSE:0.541656\n",
      "Epoch:2,i:0,MSE:0.605950\n",
      "Epoch:2,i:100,MSE:0.598016\n",
      "Epoch:2,i:200,MSE:0.616313\n",
      "Epoch:2,i:300,MSE:0.754215\n",
      "Epoch:3,i:0,MSE:0.592356\n",
      "Epoch:3,i:100,MSE:0.862843\n",
      "Epoch:3,i:200,MSE:0.535570\n",
      "Epoch:3,i:300,MSE:0.749535\n",
      "Epoch:4,i:0,MSE:0.472765\n",
      "Epoch:4,i:100,MSE:0.410003\n",
      "Epoch:4,i:200,MSE:0.288333\n",
      "Epoch:4,i:300,MSE:0.571181\n",
      "[[ 2.0730636 ]\n",
      " [ 0.8260067 ]\n",
      " [ 0.12336037]\n",
      " [-0.22693336]\n",
      " [ 0.29692972]\n",
      " [-0.008139  ]\n",
      " [-0.07386811]\n",
      " [-0.8867891 ]\n",
      " [-0.85331273]]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now=datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir=\"tf_logs\"\n",
    "logdir=\"{}/run-{}\".format(root_logdir,now)\n",
    "\n",
    "batch=64\n",
    "epoch = 5\n",
    "loop=int(np.ceil(X_s.shape[0]/batch))\n",
    "learning_rate=0.01\n",
    "\n",
    "tf.reset_default_graph()\n",
    "def fetch_data(index,delta,X,y):\n",
    "    start=index\n",
    "    end=np.min([start+delta,X.shape[0]-1])\n",
    "    return (X[start:end,:],y[start:end,:])\n",
    "\n",
    "tfX=tf.placeholder(tf.float32,shape=(None,X_s.shape[1]),name='X')\n",
    "tfY=tf.placeholder(tf.float32,shape=(None,1),name='y')\n",
    "tfTheta=tf.Variable(tf.random_uniform([X_s.shape[1],1],-1.0,1.0),name='theta')\n",
    "y_pred=tf.matmul(tfX,tfTheta,name='prediction')\n",
    "\n",
    "with tf.name_scope(\"loss\") as scope:\n",
    "    error=y_pred-tfY\n",
    "    mse=tf.reduce_mean(tf.square(error),name='mse')\n",
    "\n",
    "\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_obj=optimizer.minimize(mse)\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "mse_summary=tf.summary.scalar('MSE',mse)\n",
    "file_writer=tf.summary.FileWriter(logdir,tf.get_default_graph())\n",
    "\n",
    "\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for e in range(epoch):\n",
    "        tmp_index = np.random.permutation(np.arange(X_s.shape[0]))\n",
    "        tmp_X=X_s[tmp_index]\n",
    "        tmp_y=y[tmp_index].reshape(-1,1)\n",
    "        index = 0\n",
    "        for i in range(loop):\n",
    "            X_batch,y_batch=fetch_data(index,batch,tmp_X,tmp_y)\n",
    "            sess.run(training_obj,feed_dict={tfX:X_batch,tfY:y_batch})\n",
    "            if i%100==0:\n",
    "                mse_result=mse.eval(feed_dict={tfX:X_batch,tfY:y_batch})\n",
    "                print('Epoch:%d,i:%d,MSE:%f'%(e,i,mse_result))\n",
    "                saver.save(sess,'models/lm.ckpt')\n",
    "                summary_str=mse_summary.eval({tfX:X_batch,tfY:y_batch})\n",
    "                file_writer.add_summary(summary_str,i)\n",
    "            index+=batch\n",
    "    result=tfTheta.eval()\n",
    "    saver.save(sess,'models/lm_final.ckpt')\n",
    "    print(result)\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/mse\n"
     ]
    }
   ],
   "source": [
    "print(mse.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "minist_data = input_data.read_data_sets('/tmp/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers=2\n",
    "n_h1=200\n",
    "n_h2=100\n",
    "n_h3=10\n",
    "epoch=5\n",
    "batch=64\n",
    "loop = X_train.shape[0]//batch\n",
    "learning_rate=0.01\n",
    "momentum=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_layer(input_data, nc,activation=tf.nn.relu):\n",
    "    with tf.name_scope('construct_layer'):\n",
    "        import math\n",
    "        std=2/math.sqrt(input_data.get_shape()[1].value)\n",
    "        W=tf.truncated_normal([input_data.get_shape()[1].value,nc],stddev=std,name='W')\n",
    "        b=tf.zeros([1,nc],name='b')\n",
    "        Z=tf.matmul(input_data,W)+b\n",
    "        A=activation(Z)\n",
    "        return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=minist_data.train.images\n",
    "y_train=minist_data.train.labels.astype('int')\n",
    "X_test=minist_data.test.images\n",
    "y_test=minist_data.test.labels.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tf.placeholder(tf.float32,shape=[None,X_train.shape[1]],name='input')\n",
    "y=tf.placeholder(tf.int32,shape=[None,],name='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h1=construct_layer(X,n_h1)\n",
    "# h2=construct_layer(h1,n_h2)\n",
    "# logit=construct_layer(h2,n_h3)\n",
    "with tf.name_scope('nn'):\n",
    "    h1=tf.layers.dense(X,n_h1,activation=tf.nn.relu)\n",
    "    h2=tf.layers.dense(h1,n_h2,activation=tf.nn.relu)\n",
    "    logit=tf.layers.dense(h2,n_h3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:0.352064,acc_train:0.890625,acc_test:0.943600\n",
      "loss:0.227961,acc_train:0.937500,acc_test:0.960700\n",
      "loss:0.045267,acc_train:1.000000,acc_test:0.968300\n",
      "loss:0.111425,acc_train:0.953125,acc_test:0.969600\n",
      "loss:0.050803,acc_train:0.984375,acc_test:0.972900\n",
      "[[ 0.708971   -3.3985987   3.632009   ... 13.111327   -0.5090308\n",
      "   1.0946369 ]\n",
      " [-0.19601268  5.9160833  14.948705   ... -4.6791706   1.5025358\n",
      "  -9.915813  ]\n",
      " [-4.446296    7.7630053  -0.08045029 ...  1.4757982   0.48887318\n",
      "  -1.3756616 ]\n",
      " ...\n",
      " [-7.3821964  -3.0845904  -3.4176476  ...  3.1534896   2.8103209\n",
      "   2.286389  ]\n",
      " [ 0.2550475  -2.0151803  -2.7049353  ... -2.7041826   4.745435\n",
      "  -5.1604824 ]\n",
      " [ 2.5584257  -3.7157316  -0.35705438 ... -6.393081   -2.0213938\n",
      "  -1.155973  ]]\n",
      "Tensor(\"ArgMax:0\", shape=(10000,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('train'):\n",
    "    xentropy=tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logit))\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=momentum)\n",
    "    training=optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope('eval'):\n",
    "    corr=tf.nn.in_top_k(logit,y,1)\n",
    "    accuracy=tf.reduce_mean(tf.cast(corr,tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(epoch):\n",
    "        for j in range(loop):\n",
    "            X_batch,y_batch=minist_data.train.next_batch(batch)\n",
    "            sess.run(training,feed_dict={X:X_batch,y:y_batch})\n",
    "        print('loss:%f,acc_train:%f,acc_test:%f'%(loss.eval({X:X_batch,y:y_batch}),accuracy.eval({X:X_batch,y:y_batch}),accuracy.eval({X:minist_data.test.images,y:minist_data.test.labels})))\n",
    "    res=logit.eval({X:minist_data.test.images})\n",
    "    y_pred=np.argmax(res,axis=1)\n",
    "    print(res)\n",
    "    print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-238-d27a66d94912>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m       \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \"\"\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5164\u001b[0m     \u001b[0moperation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mOperation\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5165\u001b[0m     \u001b[0mfeed_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mmaps\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mobjects\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mto\u001b[0m \u001b[0mlists\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5166\u001b[0;31m       \u001b[0mnumpy\u001b[0m \u001b[0mndarrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorProtos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstrings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5167\u001b[0m     \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0;34m\"operation\"\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdefined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5168\u001b[0m     \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mA\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0msession\u001b[0m \u001b[0mto\u001b[0m \u001b[0muse\u001b[0m \u001b[0mto\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;34m\"operation\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`"
     ]
    }
   ],
   "source": [
    "y_pred.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
