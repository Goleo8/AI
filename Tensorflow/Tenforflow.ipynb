{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [TensorFlow-Examples](https://github.com/aymericdamien/TensorFlow-Examples.git)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Goleo8/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/Users/Goleo8/anaconda3/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.24.1) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.Variable(3,name='X')\n",
    "y=tf.Variable(4,name='Y')\n",
    "f=x*x*y+y+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result=f.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = fetch_california_housing()\n",
    "housing.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=housing.data,housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_s=np.c_[np.ones((X.shape[0],1)),scaler.fit_transform(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfX=tf.constant(X_s,dtype=tf.float64,name='X')\n",
    "tfY=tf.constant(y.reshape(-1,1),dtype=tf.float64,name='y')\n",
    "tfXT=tf.transpose(tfX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(tfXT,tfX)),tfXT),tfY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.06855817]\n",
      " [ 0.8296193 ]\n",
      " [ 0.11875165]\n",
      " [-0.26552688]\n",
      " [ 0.30569623]\n",
      " [-0.004503  ]\n",
      " [-0.03932627]\n",
      " [-0.89988565]\n",
      " [-0.870541  ]]\n"
     ]
    }
   ],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = w.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,MSE:5.855115\n",
      "Epoch:10,MSE:1.290942\n",
      "Epoch:20,MSE:0.719839\n",
      "Epoch:30,MSE:0.634301\n",
      "Epoch:40,MSE:0.610942\n",
      "Epoch:50,MSE:0.597323\n",
      "Epoch:60,MSE:0.586557\n",
      "Epoch:70,MSE:0.577502\n",
      "Epoch:80,MSE:0.569802\n",
      "Epoch:90,MSE:0.563240\n",
      "[[ 2.06850195]\n",
      " [ 0.80083104]\n",
      " [ 0.1804282 ]\n",
      " [-0.08538963]\n",
      " [ 0.10130749]\n",
      " [ 0.0181515 ]\n",
      " [-0.04389049]\n",
      " [-0.47535519]\n",
      " [-0.43656156]]\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.1\n",
    "tfX=tf.constant(X_s,dtype=tf.float64,name='X')\n",
    "tfY=tf.constant(y.reshape(-1,1),dtype=tf.float64,name='y')\n",
    "w=tf.Variable(tf.random_uniform([X_s.shape[1],1],minval=-0.1,maxval=0.1,dtype=tf.float64),name='w')\n",
    "f=tf.matmul(tfX,w,name='f')\n",
    "error = f-tfY\n",
    "mse = tf.reduce_mean(tf.square(error))\n",
    "grad = tf.matmul(tfXT,error)/X_s.shape[0]*learning_rate\n",
    "training=tf.assign(w,w-grad)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for i in range(100):\n",
    "        if i%10==0:\n",
    "            mse_result = mse.eval()\n",
    "            print('Epoch:%d,MSE:%f'%(i,mse_result))\n",
    "        sess.run(training)\n",
    "    result=w.eval()\n",
    "print(result)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]), TensorShape([Dimension(9), Dimension(1)]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse.shape,w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.grandients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,MSE:5.716550\n",
      "Epoch:10,MSE:0.679934\n",
      "Epoch:20,MSE:0.596443\n",
      "Epoch:30,MSE:0.576620\n",
      "Epoch:40,MSE:0.562718\n",
      "Epoch:50,MSE:0.552594\n",
      "Epoch:60,MSE:0.545202\n",
      "Epoch:70,MSE:0.539793\n",
      "Epoch:80,MSE:0.535826\n",
      "Epoch:90,MSE:0.532909\n",
      "[[ 2.06855817]\n",
      " [ 0.83914167]\n",
      " [ 0.14701503]\n",
      " [-0.2339941 ]\n",
      " [ 0.25784193]\n",
      " [ 0.00565514]\n",
      " [-0.04192016]\n",
      " [-0.68491155]\n",
      " [-0.65427939]]\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.1\n",
    "tfX=tf.constant(X_s,dtype=tf.float64,name='X')\n",
    "tfY=tf.constant(y.reshape(-1,1),dtype=tf.float64,name='y')\n",
    "w=tf.Variable(tf.random_uniform([X_s.shape[1],1],minval=-0.1,maxval=0.1,dtype=tf.float64),name='w')\n",
    "f=tf.matmul(tfX,w,name='f')\n",
    "error = f-tfY\n",
    "mse = tf.reduce_mean(tf.square(error))\n",
    "grad = tf.gradients(mse,[w],name='grad')[0]*learning_rate\n",
    "training=tf.assign(w,w-grad)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for i in range(100):\n",
    "        if i%10==0:\n",
    "            mse_result = mse.eval()\n",
    "            print('Epoch:%d,MSE:%f'%(i,mse_result))\n",
    "        sess.run(training)\n",
    "    result=w.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.train.GradientDescentOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,MSE:5.209789\n",
      "Epoch:10,MSE:0.686836\n",
      "Epoch:20,MSE:0.604870\n",
      "Epoch:30,MSE:0.582892\n",
      "Epoch:40,MSE:0.567412\n",
      "Epoch:50,MSE:0.556125\n",
      "Epoch:60,MSE:0.547871\n",
      "Epoch:70,MSE:0.541820\n",
      "Epoch:80,MSE:0.537373\n",
      "Epoch:90,MSE:0.534096\n",
      "[[ 2.06855817]\n",
      " [ 0.84273668]\n",
      " [ 0.14899907]\n",
      " [-0.23833605]\n",
      " [ 0.26035477]\n",
      " [ 0.00633022]\n",
      " [-0.04216464]\n",
      " [-0.66707234]\n",
      " [-0.63674006]]\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.1\n",
    "tfX=tf.constant(X_s,dtype=tf.float64,name='X')\n",
    "tfY=tf.constant(y.reshape(-1,1),dtype=tf.float64,name='y')\n",
    "w=tf.Variable(tf.random_uniform([X_s.shape[1],1],minval=-0.1,maxval=0.1,dtype=tf.float64),name='w')\n",
    "f=tf.matmul(tfX,w,name='f')\n",
    "error = f-tfY\n",
    "mse = tf.reduce_mean(tf.square(error))\n",
    "# grad = tf.gradients(mse,[w],name='grad')[0]*learning_rate\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training=optimizer.minimize(mse)\n",
    "# training=tf.assign(w,w-grad)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(100):\n",
    "        if i%10==0:\n",
    "            mse_result = mse.eval()\n",
    "            print('Epoch:%d,MSE:%f'%(i,mse_result))\n",
    "        sess.run(training)\n",
    "    result=w.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum and model load/save\n",
    "\n",
    "```tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=1)```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,MSE:5.386290\n",
      "Epoch:10,MSE:0.731156\n",
      "Epoch:20,MSE:0.601558\n",
      "Epoch:30,MSE:0.583461\n",
      "Epoch:40,MSE:0.570233\n",
      "Epoch:50,MSE:0.560031\n",
      "Epoch:60,MSE:0.552143\n",
      "Epoch:70,MSE:0.546036\n",
      "Epoch:80,MSE:0.541303\n",
      "Epoch:90,MSE:0.537629\n",
      "Epoch:100,MSE:0.534774\n",
      "Epoch:110,MSE:0.532551\n",
      "Epoch:120,MSE:0.530818\n",
      "Epoch:130,MSE:0.529464\n",
      "Epoch:140,MSE:0.528403\n",
      "Epoch:150,MSE:0.527572\n",
      "Epoch:160,MSE:0.526918\n",
      "Epoch:170,MSE:0.526402\n",
      "Epoch:180,MSE:0.525994\n",
      "Epoch:190,MSE:0.525671\n",
      "Epoch:200,MSE:0.525414\n",
      "Epoch:210,MSE:0.525209\n",
      "Epoch:220,MSE:0.525045\n",
      "Epoch:230,MSE:0.524914\n",
      "Epoch:240,MSE:0.524808\n",
      "Epoch:250,MSE:0.524722\n",
      "Epoch:260,MSE:0.524653\n",
      "Epoch:270,MSE:0.524596\n",
      "Epoch:280,MSE:0.524550\n",
      "Epoch:290,MSE:0.524512\n",
      "[[ 2.06855817]\n",
      " [ 0.83833158]\n",
      " [ 0.12283828]\n",
      " [-0.27739909]\n",
      " [ 0.31349571]\n",
      " [-0.00312943]\n",
      " [-0.03985773]\n",
      " [-0.86191417]\n",
      " [-0.83336156]]\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.04\n",
    "tfX=tf.constant(X_s,dtype=tf.float64,name='X')\n",
    "tfY=tf.constant(y.reshape(-1,1),dtype=tf.float64,name='y')\n",
    "w=tf.Variable(tf.random_uniform([X_s.shape[1],1],minval=-0.1,maxval=0.1,dtype=tf.float64),name='w')\n",
    "f=tf.matmul(tfX,w,name='f')\n",
    "error = f-tfY\n",
    "mse = tf.reduce_mean(tf.square(error))\n",
    "# grad = tf.gradients(mse,[w],name='grad')[0]*learning_rate\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=0.5)\n",
    "training=optimizer.minimize(mse)\n",
    "# training=tf.assign(w,w-grad)\n",
    "saver = tf.train.Saver()\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(300):\n",
    "        if i%10==0:\n",
    "            mse_result = mse.eval()\n",
    "            print('Epoch:%d,MSE:%f'%(i,mse_result))\n",
    "        sess.run(training)\n",
    "    result=w.eval()\n",
    "    saver.save(sess,\"data/moment.ckpt\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from data/moment.ckpt\n",
      "0.5244779040814854\n"
     ]
    }
   ],
   "source": [
    "loader = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    loader.restore(sess,'data/moment.ckpt')\n",
    "    sess.run(training)\n",
    "    print(mse.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholder\n",
    "\n",
    "```\n",
    "Y.eval(feed_dict={X:[[3,4,8],[8,16,2]]}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12 19 67]]\n",
      "[[ 12  19  67]\n",
      " [ 67 259   7]]\n"
     ]
    }
   ],
   "source": [
    "X=tf.placeholder(dtype=tf.int64,shape=(None,3),name='X')\n",
    "Y=X**2+tf.constant(3,dtype=tf.int64)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(Y.eval(feed_dict={X:[[3,4,8]]}))\n",
    "    print(Y.eval(feed_dict={X:[[3,4,8],[8,16,2]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:0,mse:6.193033\n",
      "index:100,mse:0.825462\n",
      "index:200,mse:1.143001\n",
      "index:300,mse:0.664882\n",
      "index:0,mse:0.740295\n",
      "index:100,mse:0.998736\n",
      "index:200,mse:0.485561\n",
      "index:300,mse:0.719115\n",
      "index:0,mse:0.617747\n",
      "index:100,mse:0.797923\n",
      "index:200,mse:0.427705\n",
      "index:300,mse:0.333508\n",
      "index:0,mse:0.348535\n",
      "index:100,mse:0.399791\n",
      "index:200,mse:0.426439\n",
      "index:300,mse:0.460142\n",
      "index:0,mse:0.464382\n",
      "index:100,mse:0.504077\n",
      "index:200,mse:0.445148\n",
      "index:300,mse:0.455720\n",
      "[[ 2.05346611]\n",
      " [ 0.87373668]\n",
      " [ 0.17409543]\n",
      " [-0.40950716]\n",
      " [ 0.40836091]\n",
      " [ 0.02019256]\n",
      " [-0.1455336 ]\n",
      " [-0.6505009 ]\n",
      " [-0.55374577]]\n"
     ]
    }
   ],
   "source": [
    "tfX=tf.placeholder(dtype=tf.float64,shape=(None,X_s.shape[1]))\n",
    "tfy=tf.placeholder(dtype=tf.float64,shape=(None,1))\n",
    "\n",
    "def fetch_data(data,label,index,length):\n",
    "    end = data.shape[0] if index+length>data.shape[0] else index+length\n",
    "    return (data[index:end,:],label[index:end,:])\n",
    "learning_rate=0.001\n",
    "momentum=0.9\n",
    "w=tf.Variable(tf.random_uniform([X_s.shape[1],1],dtype=tf.float64),name='w')\n",
    "error=tf.matmul(tfX,w)-tfy\n",
    "mse=tf.reduce_mean(tf.square(error))\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=momentum)\n",
    "training = optimizer.minimize(mse)\n",
    "epoch = 5\n",
    "loop=int(np.ceil(X_s.shape[0]/batch))\n",
    "batch_size=64\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for e in range(epoch):\n",
    "        tmp_index = np.random.permutation(np.arange(X_s.shape[0]))\n",
    "        tmp_X=X_s[tmp_index]\n",
    "        tmp_y=y[tmp_index].reshape(-1,1)\n",
    "        index = 0\n",
    "        for index in range(loop):\n",
    "            X1,y1=fetch_data(tmp_X,tmp_y,index,batch_size)\n",
    "\n",
    "            sess.run(training,feed_dict={tfX:X1,tfy:y1})\n",
    "            result = mse.eval(feed_dict={tfX:X1,tfy:y1})\n",
    "            if index % 100==0:\n",
    "                print('index:%d,mse:%f'%(index,result))\n",
    "            index+=batch_size\n",
    "    res=w.eval()\n",
    "    print(res)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,i:0,MSE:7.580889\n",
      "Epoch:0,i:100,MSE:0.889810\n",
      "Epoch:0,i:200,MSE:0.532188\n",
      "Epoch:0,i:300,MSE:0.415425\n",
      "Epoch:1,i:0,MSE:0.740444\n",
      "Epoch:1,i:100,MSE:0.825939\n",
      "Epoch:1,i:200,MSE:0.514026\n",
      "Epoch:1,i:300,MSE:0.315791\n",
      "Epoch:2,i:0,MSE:0.432092\n",
      "Epoch:2,i:100,MSE:0.477250\n",
      "Epoch:2,i:200,MSE:0.329317\n",
      "Epoch:2,i:300,MSE:0.777959\n",
      "Epoch:3,i:0,MSE:0.498997\n",
      "Epoch:3,i:100,MSE:0.503145\n",
      "Epoch:3,i:200,MSE:0.379669\n",
      "Epoch:3,i:300,MSE:0.441188\n",
      "Epoch:4,i:0,MSE:0.313797\n",
      "Epoch:4,i:100,MSE:0.470612\n",
      "Epoch:4,i:200,MSE:0.540176\n",
      "Epoch:4,i:300,MSE:0.463425\n",
      "[[ 2.0653908e+00]\n",
      " [ 8.3301979e-01]\n",
      " [ 1.2470519e-01]\n",
      " [-2.1489646e-01]\n",
      " [ 2.8438878e-01]\n",
      " [-1.8046575e-03]\n",
      " [-5.4344814e-02]\n",
      " [-8.4978980e-01]\n",
      " [-8.1136680e-01]]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now=datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir=\"tf_logs\"\n",
    "logdir=\"{}/run-{}\".format(root_logdir,now)\n",
    "\n",
    "batch=64\n",
    "epoch = 5\n",
    "loop=int(np.ceil(X_s.shape[0]/batch))\n",
    "learning_rate=0.01\n",
    "momentum=0.1\n",
    "\n",
    "tf.reset_default_graph()\n",
    "def fetch_data(index,delta,X,y):\n",
    "    start=index\n",
    "    end=np.min([start+delta,X.shape[0]-1])\n",
    "    return (X[start:end,:],y[start:end,:])\n",
    "\n",
    "tfX=tf.placeholder(tf.float32,shape=(None,X_s.shape[1]),name='X')\n",
    "tfY=tf.placeholder(tf.float32,shape=(None,1),name='y')\n",
    "tfTheta=tf.Variable(tf.random_uniform([X_s.shape[1],1],-1.0,1.0),name='theta')\n",
    "y_pred=tf.matmul(tfX,tfTheta,name='prediction')\n",
    "\n",
    "error=y_pred-tfY\n",
    "mse=tf.reduce_mean(tf.square(error),name='mse')\n",
    "\n",
    "\n",
    "optimizer=tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=momentum)\n",
    "training_obj=optimizer.minimize(mse)\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "mse_summary=tf.summary.scalar('MSE',mse)\n",
    "file_writer=tf.summary.FileWriter(logdir,tf.get_default_graph())\n",
    "\n",
    "\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for e in range(epoch):\n",
    "        tmp_index = np.random.permutation(np.arange(X_s.shape[0]))\n",
    "        tmp_X=X_s[tmp_index]\n",
    "        tmp_y=y[tmp_index].reshape(-1,1)\n",
    "        index = 0\n",
    "        for i in range(loop):\n",
    "            X_batch,y_batch=fetch_data(index,batch,tmp_X,tmp_y)\n",
    "            sess.run(training_obj,feed_dict={tfX:X_batch,tfY:y_batch})\n",
    "            if i%100==0:\n",
    "                mse_result=mse.eval(feed_dict={tfX:X_batch,tfY:y_batch})\n",
    "                print('Epoch:%d,i:%d,MSE:%f'%(e,i,mse_result))\n",
    "                saver.save(sess,'models/lm.ckpt')\n",
    "                summary_str=mse_summary.eval({tfX:X_batch,tfY:y_batch})\n",
    "                file_writer.add_summary(summary_str,i)\n",
    "            index+=batch\n",
    "    result=tfTheta.eval()\n",
    "    saver.save(sess,'models/lm_final.ckpt')\n",
    "    print(result)\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,i:0,MSE:3.948535\n",
      "Epoch:0,i:100,MSE:0.322487\n",
      "Epoch:0,i:200,MSE:0.791210\n",
      "Epoch:0,i:300,MSE:0.390781\n",
      "Epoch:1,i:0,MSE:0.477199\n",
      "Epoch:1,i:100,MSE:0.611855\n",
      "Epoch:1,i:200,MSE:0.488207\n",
      "Epoch:1,i:300,MSE:0.541656\n",
      "Epoch:2,i:0,MSE:0.605950\n",
      "Epoch:2,i:100,MSE:0.598016\n",
      "Epoch:2,i:200,MSE:0.616313\n",
      "Epoch:2,i:300,MSE:0.754215\n",
      "Epoch:3,i:0,MSE:0.592356\n",
      "Epoch:3,i:100,MSE:0.862843\n",
      "Epoch:3,i:200,MSE:0.535570\n",
      "Epoch:3,i:300,MSE:0.749535\n",
      "Epoch:4,i:0,MSE:0.472765\n",
      "Epoch:4,i:100,MSE:0.410003\n",
      "Epoch:4,i:200,MSE:0.288333\n",
      "Epoch:4,i:300,MSE:0.571181\n",
      "[[ 2.0730636 ]\n",
      " [ 0.8260067 ]\n",
      " [ 0.12336037]\n",
      " [-0.22693336]\n",
      " [ 0.29692972]\n",
      " [-0.008139  ]\n",
      " [-0.07386811]\n",
      " [-0.8867891 ]\n",
      " [-0.85331273]]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now=datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir=\"tf_logs\"\n",
    "logdir=\"{}/run-{}\".format(root_logdir,now)\n",
    "\n",
    "batch=64\n",
    "epoch = 5\n",
    "loop=int(np.ceil(X_s.shape[0]/batch))\n",
    "learning_rate=0.01\n",
    "\n",
    "tf.reset_default_graph()\n",
    "def fetch_data(index,delta,X,y):\n",
    "    start=index\n",
    "    end=np.min([start+delta,X.shape[0]-1])\n",
    "    return (X[start:end,:],y[start:end,:])\n",
    "\n",
    "tfX=tf.placeholder(tf.float32,shape=(None,X_s.shape[1]),name='X')\n",
    "tfY=tf.placeholder(tf.float32,shape=(None,1),name='y')\n",
    "tfTheta=tf.Variable(tf.random_uniform([X_s.shape[1],1],-1.0,1.0),name='theta')\n",
    "y_pred=tf.matmul(tfX,tfTheta,name='prediction')\n",
    "\n",
    "with tf.name_scope(\"loss\") as scope:\n",
    "    error=y_pred-tfY\n",
    "    mse=tf.reduce_mean(tf.square(error),name='mse')\n",
    "\n",
    "\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_obj=optimizer.minimize(mse)\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "mse_summary=tf.summary.scalar('MSE',mse)\n",
    "file_writer=tf.summary.FileWriter(logdir,tf.get_default_graph())\n",
    "\n",
    "\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for e in range(epoch):\n",
    "        tmp_index = np.random.permutation(np.arange(X_s.shape[0]))\n",
    "        tmp_X=X_s[tmp_index]\n",
    "        tmp_y=y[tmp_index].reshape(-1,1)\n",
    "        index = 0\n",
    "        for i in range(loop):\n",
    "            X_batch,y_batch=fetch_data(index,batch,tmp_X,tmp_y)\n",
    "            sess.run(training_obj,feed_dict={tfX:X_batch,tfY:y_batch})\n",
    "            if i%100==0:\n",
    "                mse_result=mse.eval(feed_dict={tfX:X_batch,tfY:y_batch})\n",
    "                print('Epoch:%d,i:%d,MSE:%f'%(e,i,mse_result))\n",
    "                saver.save(sess,'models/lm.ckpt')\n",
    "                summary_str=mse_summary.eval({tfX:X_batch,tfY:y_batch})\n",
    "                file_writer.add_summary(summary_str,i)\n",
    "            index+=batch\n",
    "    result=tfTheta.eval()\n",
    "    saver.save(sess,'models/lm_final.ckpt')\n",
    "    print(result)\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/mse\n"
     ]
    }
   ],
   "source": [
    "print(mse.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
