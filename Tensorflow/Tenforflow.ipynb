{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [TensorFlow-Examples](https://github.com/aymericdamien/TensorFlow-Examples.git)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=tf.Variable(3,name='X')\n",
    "y=tf.Variable(4,name='Y')\n",
    "f=x*x*y+y+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result=f.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = fetch_california_housing()\n",
    "housing.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,y=housing.data,housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_s=np.c_[np.ones((X.shape[0],1)),scaler.fit_transform(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfX=tf.constant(X_s,dtype=tf.float64,name='X')\n",
    "tfY=tf.constant(y.reshape(-1,1),dtype=tf.float64,name='y')\n",
    "tfXT=tf.transpose(tfX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w=tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(tfXT,tfX)),tfXT),tfY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.06855817]\n",
      " [ 0.8296193 ]\n",
      " [ 0.11875165]\n",
      " [-0.26552688]\n",
      " [ 0.30569623]\n",
      " [-0.004503  ]\n",
      " [-0.03932627]\n",
      " [-0.89988565]\n",
      " [-0.870541  ]]\n"
     ]
    }
   ],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = w.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,MSE:5.855115\n",
      "Epoch:10,MSE:1.290942\n",
      "Epoch:20,MSE:0.719839\n",
      "Epoch:30,MSE:0.634301\n",
      "Epoch:40,MSE:0.610942\n",
      "Epoch:50,MSE:0.597323\n",
      "Epoch:60,MSE:0.586557\n",
      "Epoch:70,MSE:0.577502\n",
      "Epoch:80,MSE:0.569802\n",
      "Epoch:90,MSE:0.563240\n",
      "[[ 2.06850195]\n",
      " [ 0.80083104]\n",
      " [ 0.1804282 ]\n",
      " [-0.08538963]\n",
      " [ 0.10130749]\n",
      " [ 0.0181515 ]\n",
      " [-0.04389049]\n",
      " [-0.47535519]\n",
      " [-0.43656156]]\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.1\n",
    "tfX=tf.constant(X_s,dtype=tf.float64,name='X')\n",
    "tfY=tf.constant(y.reshape(-1,1),dtype=tf.float64,name='y')\n",
    "w=tf.Variable(tf.random_uniform([X_s.shape[1],1],minval=-0.1,maxval=0.1,dtype=tf.float64),name='w')\n",
    "f=tf.matmul(tfX,w,name='f')\n",
    "error = f-tfY\n",
    "mse = tf.reduce_mean(tf.square(error))\n",
    "grad = tf.matmul(tfXT,error)/X_s.shape[0]*learning_rate\n",
    "training=tf.assign(w,w-grad)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for i in range(100):\n",
    "        if i%10==0:\n",
    "            mse_result = mse.eval()\n",
    "            print('Epoch:%d,MSE:%f'%(i,mse_result))\n",
    "        sess.run(training)\n",
    "    result=w.eval()\n",
    "print(result)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]), TensorShape([Dimension(9), Dimension(1)]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse.shape,w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.grandients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,MSE:5.716550\n",
      "Epoch:10,MSE:0.679934\n",
      "Epoch:20,MSE:0.596443\n",
      "Epoch:30,MSE:0.576620\n",
      "Epoch:40,MSE:0.562718\n",
      "Epoch:50,MSE:0.552594\n",
      "Epoch:60,MSE:0.545202\n",
      "Epoch:70,MSE:0.539793\n",
      "Epoch:80,MSE:0.535826\n",
      "Epoch:90,MSE:0.532909\n",
      "[[ 2.06855817]\n",
      " [ 0.83914167]\n",
      " [ 0.14701503]\n",
      " [-0.2339941 ]\n",
      " [ 0.25784193]\n",
      " [ 0.00565514]\n",
      " [-0.04192016]\n",
      " [-0.68491155]\n",
      " [-0.65427939]]\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.1\n",
    "tfX=tf.constant(X_s,dtype=tf.float64,name='X')\n",
    "tfY=tf.constant(y.reshape(-1,1),dtype=tf.float64,name='y')\n",
    "w=tf.Variable(tf.random_uniform([X_s.shape[1],1],minval=-0.1,maxval=0.1,dtype=tf.float64),name='w')\n",
    "f=tf.matmul(tfX,w,name='f')\n",
    "error = f-tfY\n",
    "mse = tf.reduce_mean(tf.square(error))\n",
    "grad = tf.gradients(mse,[w],name='grad')[0]*learning_rate\n",
    "training=tf.assign(w,w-grad)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for i in range(100):\n",
    "        if i%10==0:\n",
    "            mse_result = mse.eval()\n",
    "            print('Epoch:%d,MSE:%f'%(i,mse_result))\n",
    "        sess.run(training)\n",
    "    result=w.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.train.GradientDescentOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,MSE:5.209789\n",
      "Epoch:10,MSE:0.686836\n",
      "Epoch:20,MSE:0.604870\n",
      "Epoch:30,MSE:0.582892\n",
      "Epoch:40,MSE:0.567412\n",
      "Epoch:50,MSE:0.556125\n",
      "Epoch:60,MSE:0.547871\n",
      "Epoch:70,MSE:0.541820\n",
      "Epoch:80,MSE:0.537373\n",
      "Epoch:90,MSE:0.534096\n",
      "[[ 2.06855817]\n",
      " [ 0.84273668]\n",
      " [ 0.14899907]\n",
      " [-0.23833605]\n",
      " [ 0.26035477]\n",
      " [ 0.00633022]\n",
      " [-0.04216464]\n",
      " [-0.66707234]\n",
      " [-0.63674006]]\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.1\n",
    "tfX=tf.constant(X_s,dtype=tf.float64,name='X')\n",
    "tfY=tf.constant(y.reshape(-1,1),dtype=tf.float64,name='y')\n",
    "w=tf.Variable(tf.random_uniform([X_s.shape[1],1],minval=-0.1,maxval=0.1,dtype=tf.float64),name='w')\n",
    "f=tf.matmul(tfX,w,name='f')\n",
    "error = f-tfY\n",
    "mse = tf.reduce_mean(tf.square(error))\n",
    "# grad = tf.gradients(mse,[w],name='grad')[0]*learning_rate\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training=optimizer.minimize(mse)\n",
    "# training=tf.assign(w,w-grad)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(100):\n",
    "        if i%10==0:\n",
    "            mse_result = mse.eval()\n",
    "            print('Epoch:%d,MSE:%f'%(i,mse_result))\n",
    "        sess.run(training)\n",
    "    result=w.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum and model load/save\n",
    "\n",
    "```tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=1)```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,MSE:5.386290\n",
      "Epoch:10,MSE:0.731156\n",
      "Epoch:20,MSE:0.601558\n",
      "Epoch:30,MSE:0.583461\n",
      "Epoch:40,MSE:0.570233\n",
      "Epoch:50,MSE:0.560031\n",
      "Epoch:60,MSE:0.552143\n",
      "Epoch:70,MSE:0.546036\n",
      "Epoch:80,MSE:0.541303\n",
      "Epoch:90,MSE:0.537629\n",
      "Epoch:100,MSE:0.534774\n",
      "Epoch:110,MSE:0.532551\n",
      "Epoch:120,MSE:0.530818\n",
      "Epoch:130,MSE:0.529464\n",
      "Epoch:140,MSE:0.528403\n",
      "Epoch:150,MSE:0.527572\n",
      "Epoch:160,MSE:0.526918\n",
      "Epoch:170,MSE:0.526402\n",
      "Epoch:180,MSE:0.525994\n",
      "Epoch:190,MSE:0.525671\n",
      "Epoch:200,MSE:0.525414\n",
      "Epoch:210,MSE:0.525209\n",
      "Epoch:220,MSE:0.525045\n",
      "Epoch:230,MSE:0.524914\n",
      "Epoch:240,MSE:0.524808\n",
      "Epoch:250,MSE:0.524722\n",
      "Epoch:260,MSE:0.524653\n",
      "Epoch:270,MSE:0.524596\n",
      "Epoch:280,MSE:0.524550\n",
      "Epoch:290,MSE:0.524512\n",
      "[[ 2.06855817]\n",
      " [ 0.83833158]\n",
      " [ 0.12283828]\n",
      " [-0.27739909]\n",
      " [ 0.31349571]\n",
      " [-0.00312943]\n",
      " [-0.03985773]\n",
      " [-0.86191417]\n",
      " [-0.83336156]]\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.04\n",
    "tfX=tf.constant(X_s,dtype=tf.float64,name='X')\n",
    "tfY=tf.constant(y.reshape(-1,1),dtype=tf.float64,name='y')\n",
    "w=tf.Variable(tf.random_uniform([X_s.shape[1],1],minval=-0.1,maxval=0.1,dtype=tf.float64),name='w')\n",
    "f=tf.matmul(tfX,w,name='f')\n",
    "error = f-tfY\n",
    "mse = tf.reduce_mean(tf.square(error))\n",
    "# grad = tf.gradients(mse,[w],name='grad')[0]*learning_rate\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=0.5)\n",
    "training=optimizer.minimize(mse)\n",
    "# training=tf.assign(w,w-grad)\n",
    "saver = tf.train.Saver()\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(300):\n",
    "        if i%10==0:\n",
    "            mse_result = mse.eval()\n",
    "            print('Epoch:%d,MSE:%f'%(i,mse_result))\n",
    "        sess.run(training)\n",
    "    result=w.eval()\n",
    "    saver.save(sess,\"data/moment.ckpt\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from data/moment.ckpt\n",
      "0.5244779040814854\n"
     ]
    }
   ],
   "source": [
    "loader = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    loader.restore(sess,'data/moment.ckpt')\n",
    "    sess.run(training)\n",
    "    print(mse.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholder\n",
    "\n",
    "```\n",
    "Y.eval(feed_dict={X:[[3,4,8],[8,16,2]]}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12 19 67]]\n",
      "[[ 12  19  67]\n",
      " [ 67 259   7]]\n"
     ]
    }
   ],
   "source": [
    "X=tf.placeholder(dtype=tf.int64,shape=(None,3),name='X')\n",
    "Y=X**2+tf.constant(3,dtype=tf.int64)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(Y.eval(feed_dict={X:[[3,4,8]]}))\n",
    "    print(Y.eval(feed_dict={X:[[3,4,8],[8,16,2]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:0,mse:6.193033\n",
      "index:100,mse:0.825462\n",
      "index:200,mse:1.143001\n",
      "index:300,mse:0.664882\n",
      "index:0,mse:0.740295\n",
      "index:100,mse:0.998736\n",
      "index:200,mse:0.485561\n",
      "index:300,mse:0.719115\n",
      "index:0,mse:0.617747\n",
      "index:100,mse:0.797923\n",
      "index:200,mse:0.427705\n",
      "index:300,mse:0.333508\n",
      "index:0,mse:0.348535\n",
      "index:100,mse:0.399791\n",
      "index:200,mse:0.426439\n",
      "index:300,mse:0.460142\n",
      "index:0,mse:0.464382\n",
      "index:100,mse:0.504077\n",
      "index:200,mse:0.445148\n",
      "index:300,mse:0.455720\n",
      "[[ 2.05346611]\n",
      " [ 0.87373668]\n",
      " [ 0.17409543]\n",
      " [-0.40950716]\n",
      " [ 0.40836091]\n",
      " [ 0.02019256]\n",
      " [-0.1455336 ]\n",
      " [-0.6505009 ]\n",
      " [-0.55374577]]\n"
     ]
    }
   ],
   "source": [
    "tfX=tf.placeholder(dtype=tf.float64,shape=(None,X_s.shape[1]))\n",
    "tfy=tf.placeholder(dtype=tf.float64,shape=(None,1))\n",
    "\n",
    "def fetch_data(data,label,index,length):\n",
    "    end = data.shape[0] if index+length>data.shape[0] else index+length\n",
    "    return (data[index:end,:],label[index:end,:])\n",
    "learning_rate=0.001\n",
    "momentum=0.9\n",
    "w=tf.Variable(tf.random_uniform([X_s.shape[1],1],dtype=tf.float64),name='w')\n",
    "error=tf.matmul(tfX,w)-tfy\n",
    "mse=tf.reduce_mean(tf.square(error))\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=momentum)\n",
    "training = optimizer.minimize(mse)\n",
    "epoch = 5\n",
    "loop=int(np.ceil(X_s.shape[0]/batch))\n",
    "batch_size=64\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for e in range(epoch):\n",
    "        tmp_index = np.random.permutation(np.arange(X_s.shape[0]))\n",
    "        tmp_X=X_s[tmp_index]\n",
    "        tmp_y=y[tmp_index].reshape(-1,1)\n",
    "        index = 0\n",
    "        for index in range(loop):\n",
    "            X1,y1=fetch_data(tmp_X,tmp_y,index,batch_size)\n",
    "\n",
    "            sess.run(training,feed_dict={tfX:X1,tfy:y1})\n",
    "            result = mse.eval(feed_dict={tfX:X1,tfy:y1})\n",
    "            if index % 100==0:\n",
    "                print('index:%d,mse:%f'%(index,result))\n",
    "            index+=batch_size\n",
    "    res=w.eval()\n",
    "    print(res)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,i:0,MSE:7.580889\n",
      "Epoch:0,i:100,MSE:0.889810\n",
      "Epoch:0,i:200,MSE:0.532188\n",
      "Epoch:0,i:300,MSE:0.415425\n",
      "Epoch:1,i:0,MSE:0.740444\n",
      "Epoch:1,i:100,MSE:0.825939\n",
      "Epoch:1,i:200,MSE:0.514026\n",
      "Epoch:1,i:300,MSE:0.315791\n",
      "Epoch:2,i:0,MSE:0.432092\n",
      "Epoch:2,i:100,MSE:0.477250\n",
      "Epoch:2,i:200,MSE:0.329317\n",
      "Epoch:2,i:300,MSE:0.777959\n",
      "Epoch:3,i:0,MSE:0.498997\n",
      "Epoch:3,i:100,MSE:0.503145\n",
      "Epoch:3,i:200,MSE:0.379669\n",
      "Epoch:3,i:300,MSE:0.441188\n",
      "Epoch:4,i:0,MSE:0.313797\n",
      "Epoch:4,i:100,MSE:0.470612\n",
      "Epoch:4,i:200,MSE:0.540176\n",
      "Epoch:4,i:300,MSE:0.463425\n",
      "[[ 2.0653908e+00]\n",
      " [ 8.3301979e-01]\n",
      " [ 1.2470519e-01]\n",
      " [-2.1489646e-01]\n",
      " [ 2.8438878e-01]\n",
      " [-1.8046575e-03]\n",
      " [-5.4344814e-02]\n",
      " [-8.4978980e-01]\n",
      " [-8.1136680e-01]]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now=datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir=\"tf_logs\"\n",
    "logdir=\"{}/run-{}\".format(root_logdir,now)\n",
    "\n",
    "batch=64\n",
    "epoch = 5\n",
    "loop=int(np.ceil(X_s.shape[0]/batch))\n",
    "learning_rate=0.01\n",
    "momentum=0.1\n",
    "\n",
    "tf.reset_default_graph()\n",
    "def fetch_data(index,delta,X,y):\n",
    "    start=index\n",
    "    end=np.min([start+delta,X.shape[0]-1])\n",
    "    return (X[start:end,:],y[start:end,:])\n",
    "\n",
    "tfX=tf.placeholder(tf.float32,shape=(None,X_s.shape[1]),name='X')\n",
    "tfY=tf.placeholder(tf.float32,shape=(None,1),name='y')\n",
    "tfTheta=tf.Variable(tf.random_uniform([X_s.shape[1],1],-1.0,1.0),name='theta')\n",
    "y_pred=tf.matmul(tfX,tfTheta,name='prediction')\n",
    "\n",
    "error=y_pred-tfY\n",
    "mse=tf.reduce_mean(tf.square(error),name='mse')\n",
    "\n",
    "\n",
    "optimizer=tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=momentum)\n",
    "training_obj=optimizer.minimize(mse)\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "mse_summary=tf.summary.scalar('MSE',mse)\n",
    "file_writer=tf.summary.FileWriter(logdir,tf.get_default_graph())\n",
    "\n",
    "\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for e in range(epoch):\n",
    "        tmp_index = np.random.permutation(np.arange(X_s.shape[0]))\n",
    "        tmp_X=X_s[tmp_index]\n",
    "        tmp_y=y[tmp_index].reshape(-1,1)\n",
    "        index = 0\n",
    "        for i in range(loop):\n",
    "            X_batch,y_batch=fetch_data(index,batch,tmp_X,tmp_y)\n",
    "            sess.run(training_obj,feed_dict={tfX:X_batch,tfY:y_batch})\n",
    "            if i%100==0:\n",
    "                mse_result=mse.eval(feed_dict={tfX:X_batch,tfY:y_batch})\n",
    "                print('Epoch:%d,i:%d,MSE:%f'%(e,i,mse_result))\n",
    "                saver.save(sess,'models/lm.ckpt')\n",
    "                summary_str=mse_summary.eval({tfX:X_batch,tfY:y_batch})\n",
    "                file_writer.add_summary(summary_str,i)\n",
    "            index+=batch\n",
    "    result=tfTheta.eval()\n",
    "    saver.save(sess,'models/lm_final.ckpt')\n",
    "    print(result)\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,i:0,MSE:3.948535\n",
      "Epoch:0,i:100,MSE:0.322487\n",
      "Epoch:0,i:200,MSE:0.791210\n",
      "Epoch:0,i:300,MSE:0.390781\n",
      "Epoch:1,i:0,MSE:0.477199\n",
      "Epoch:1,i:100,MSE:0.611855\n",
      "Epoch:1,i:200,MSE:0.488207\n",
      "Epoch:1,i:300,MSE:0.541656\n",
      "Epoch:2,i:0,MSE:0.605950\n",
      "Epoch:2,i:100,MSE:0.598016\n",
      "Epoch:2,i:200,MSE:0.616313\n",
      "Epoch:2,i:300,MSE:0.754215\n",
      "Epoch:3,i:0,MSE:0.592356\n",
      "Epoch:3,i:100,MSE:0.862843\n",
      "Epoch:3,i:200,MSE:0.535570\n",
      "Epoch:3,i:300,MSE:0.749535\n",
      "Epoch:4,i:0,MSE:0.472765\n",
      "Epoch:4,i:100,MSE:0.410003\n",
      "Epoch:4,i:200,MSE:0.288333\n",
      "Epoch:4,i:300,MSE:0.571181\n",
      "[[ 2.0730636 ]\n",
      " [ 0.8260067 ]\n",
      " [ 0.12336037]\n",
      " [-0.22693336]\n",
      " [ 0.29692972]\n",
      " [-0.008139  ]\n",
      " [-0.07386811]\n",
      " [-0.8867891 ]\n",
      " [-0.85331273]]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now=datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir=\"tf_logs\"\n",
    "logdir=\"{}/run-{}\".format(root_logdir,now)\n",
    "\n",
    "batch=64\n",
    "epoch = 5\n",
    "loop=int(np.ceil(X_s.shape[0]/batch))\n",
    "learning_rate=0.01\n",
    "\n",
    "tf.reset_default_graph()\n",
    "def fetch_data(index,delta,X,y):\n",
    "    start=index\n",
    "    end=np.min([start+delta,X.shape[0]-1])\n",
    "    return (X[start:end,:],y[start:end,:])\n",
    "\n",
    "tfX=tf.placeholder(tf.float32,shape=(None,X_s.shape[1]),name='X')\n",
    "tfY=tf.placeholder(tf.float32,shape=(None,1),name='y')\n",
    "tfTheta=tf.Variable(tf.random_uniform([X_s.shape[1],1],-1.0,1.0),name='theta')\n",
    "y_pred=tf.matmul(tfX,tfTheta,name='prediction')\n",
    "\n",
    "with tf.name_scope(\"loss\") as scope:\n",
    "    error=y_pred-tfY\n",
    "    mse=tf.reduce_mean(tf.square(error),name='mse')\n",
    "\n",
    "\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_obj=optimizer.minimize(mse)\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "mse_summary=tf.summary.scalar('MSE',mse)\n",
    "file_writer=tf.summary.FileWriter(logdir,tf.get_default_graph())\n",
    "\n",
    "\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for e in range(epoch):\n",
    "        tmp_index = np.random.permutation(np.arange(X_s.shape[0]))\n",
    "        tmp_X=X_s[tmp_index]\n",
    "        tmp_y=y[tmp_index].reshape(-1,1)\n",
    "        index = 0\n",
    "        for i in range(loop):\n",
    "            X_batch,y_batch=fetch_data(index,batch,tmp_X,tmp_y)\n",
    "            sess.run(training_obj,feed_dict={tfX:X_batch,tfY:y_batch})\n",
    "            if i%100==0:\n",
    "                mse_result=mse.eval(feed_dict={tfX:X_batch,tfY:y_batch})\n",
    "                print('Epoch:%d,i:%d,MSE:%f'%(e,i,mse_result))\n",
    "                saver.save(sess,'models/lm.ckpt')\n",
    "                summary_str=mse_summary.eval({tfX:X_batch,tfY:y_batch})\n",
    "                file_writer.add_summary(summary_str,i)\n",
    "            index+=batch\n",
    "    result=tfTheta.eval()\n",
    "    saver.save(sess,'models/lm_final.ckpt')\n",
    "    print(result)\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/mse\n"
     ]
    }
   ],
   "source": [
    "print(mse.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-8c7e47273f8c>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "minist_data = input_data.read_data_sets('/tmp/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7fe3db51e593>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "n_layers=2\n",
    "n_h1=200\n",
    "n_h2=100\n",
    "n_h3=10\n",
    "epoch=15\n",
    "batch=64\n",
    "loop = X_train.shape[0]//batch\n",
    "learning_rate=0.01\n",
    "momentum=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_layer(input_data, nc,activation=tf.nn.relu):\n",
    "    with tf.name_scope('construct_layer'):\n",
    "        import math\n",
    "        std=2/math.sqrt(input_data.get_shape()[1].value)\n",
    "        init=tf.truncated_normal([input_data.get_shape()[1].value,nc],stddev=std)\n",
    "        W=tf.Variable(init,dtype=tf.float32,name='W')\n",
    "        b=tf.Variable(tf.zeros([1,nc]),name='b')\n",
    "        Z=tf.matmul(input_data,W)+b\n",
    "        \n",
    "        A=activation(Z) if activation else Z\n",
    "        return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=minist_data.train.images\n",
    "y_train=minist_data.train.labels.astype('int')\n",
    "X_test=minist_data.test.images\n",
    "y_test=minist_data.test.labels.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=tf.placeholder(tf.float32,shape=[None,X_train.shape[1]],name='input')\n",
    "y=tf.placeholder(tf.int32,shape=[None,],name='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with tf.name_scope('nn'):\n",
    "#     h1=tf.layers.dense(X,n_h1,activation=tf.nn.relu)\n",
    "#     h2=tf.layers.dense(h1,n_h2,activation=tf.nn.relu)\n",
    "#     logit=tf.layers.dense(h2,n_h3)\n",
    "    h1=construct_layer(X,n_h1)\n",
    "    h2=construct_layer(h1,n_h2)\n",
    "    logit=construct_layer(h2,n_h3,activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "timestamp=datetime.datetime.now().strftime(\"%y%m%d%H%M%S\")\n",
    "log_root=\"logdir\"\n",
    "log_dir=\"{}/run-{}\".format(log_root,timestamp)\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    xentropy=tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logit))\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=momentum)\n",
    "    training=optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope('eval'):\n",
    "    corr=tf.nn.in_top_k(logit,y,1)\n",
    "    accuracy=tf.reduce_mean(tf.cast(corr,tf.float32))\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "loss_summary=tf.summary.scalar('loss',loss)\n",
    "file_writer=tf.summary.FileWriter(log_dir,tf.get_default_graph())\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(epoch):\n",
    "        for j in range(loop):\n",
    "            X_batch,y_batch=minist_data.train.next_batch(batch)\n",
    "            sess.run(training,feed_dict={X:X_batch,y:y_batch})\n",
    "        saver.save(sess,'model/logit.ckpt')\n",
    "        loss_summary_record=loss_summary.eval({X:minist_data.test.images,y:minist_data.test.labels})\n",
    "        file_writer.add_summary(loss_summary_record,i)\n",
    "        print('loss:%f,acc_train:%f,acc_test:%f'%(loss.eval({X:X_batch,y:y_batch}),accuracy.eval({X:X_batch,y:y_batch}),accuracy.eval({X:minist_data.test.images,y:minist_data.test.labels})))\n",
    "    saver.save(sess,'model/logit_final.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/logit_final.ckpt\n",
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "loader = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    loader.restore(sess,'model/logit_final.ckpt')\n",
    "    res=logit.eval({X:minist_data.test.images,y:minist_data.test.labels})\n",
    "    y_pred = np.argmax(res,axis=1)\n",
    "    print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x127cfd8d0>"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_test[1].reshape(28,28),cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].reshape(-1,28,28).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
